[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":" series labs/tutorials currently development (2020-2021) two-semester graduate-level statistics sequence Psychology @ Brooklyn College CUNY. goal tutorials 1) develop deeper conceptual understanding principles statistical analysis inference; 2) develop practical skills data-analysis, using increasingly popular statistical software environment R code reproducible analyses.first set 13 labs roughly tracks “Thinking Data” (Vokey & Allen, 2018) “Answering questions data” (Crump et al., 2018); second set labs (written weekly basis Spring 2021 semester) roughly track “Experimental Design Analysis Psychology” (Abdi et al., 2009).Although primary aim create lab exercises reinforce stats concepts also train basic R coding skills data-analysis, many side goals, including showing students advantages using R markdown Github creating communicating research products. example, aside tutorials, developing R package called vertical (Vuorre & Crump, 2020), highlights advantages learning R researchers psychology. , possible, hope inject broader discussion awesome R tools use labs (time, deep-dive requires separate course…maybe coming soon browser near ).","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"Right now ’s Dec 4th, 2020; Anjali Krishnan & co-teaching stats course graduate students Master’s Experimental Psychology program. semester almost , next semester moving stats II. first time tried coordinate efforts graduate level, ’s fun.years ago, put heads together create free undergraduate textbook (Answering questions data) lab manual, covered exercises across four software environments, R, Excel, SPSS, Jamovi (Anjali’s verion ). resources exist Github repos, licensed CC 4.0, can copied, remixed, re-used license.Anjali teaching stats sequence graduate level several years, program decided expand statistics offering include additional lab hours. , year, ’m joining club writing lab curriculum every week course. now, decided gather labs written far put “fancy” new bs4_book() bookdown format.Anjali using two statistics textbooks lecture portion course. first semester mostly follows “Thinking Data” (Vokey & Allen, 2018), second semester mostly follows “Experimental Design Analysis Psychology” (Abdi et al., 2009). Coincidentally, trained John Vokey & Scott Allen University Lethbridge (worked textbook undergrad), Anjali trained Hérve Abdi UT Austin. , seems academically inherited impulse create statistics curriculum.","code":""},{"path":"preface.html","id":"for-students","chapter":"Preface","heading":"0.1 For Students","text":"student class questions ’s going class, please ask email .student interested using materials, class, don’t know begin, hope little overview helpful. think enough breadcrumbs work way course material .creating new chapters almost week Fall 2020 Spring 2021. chapter series lab exercises corresponding closely chapters textbooks use stats II (Abdi et al., 2009; Vokey & Allen, 2018). labs use R, RStudio, Github complete assignments. See instructions next Getting Started section tips installing necessary software.lab similar structure, written chapter corresponding lecture video followed generalization assignment. Lab content split conceptual sections (reinforcing statistical concept R), practical sections (showing specific tasks analyses R). start basic R coding, discuss new coding concepts needed. generalization problems end lab designed solved R code, challenge students independently apply coding concepts lab solving similar new assignment problems. time, assigned problems walkthrough videos showing example solutions case get stuck.follow materials, gain experience using R Rstudio, well writing powerful amazing R Markdown language (e.g., allowed make web-book), also become familiar using Github sharing research assets like statistical analyses produce R. Also, hope find materials useful enriching understanding statistics. Best luck!","code":""},{"path":"preface.html","id":"for-instructors","chapter":"Preface","heading":"0.2 For Instructors","text":"materials currently development, plan release CC 4.0 license. result, materials free remix re-use license.Feel free fork repo use materials see fit. like contribute development materials, feel free submit pull-request suggested changes (leave comment github issues).","code":""},{"path":"r-rstudio-github.html","id":"r-rstudio-github","chapter":"R, RStudio, & Github","heading":"R, RStudio, & Github","text":"meet first class things try home get started.","code":""},{"path":"r-rstudio-github.html","id":"install-r-and-r-studio","chapter":"R, RStudio, & Github","heading":"0.3 Install R and R Studio","text":"Download install R computer. R website https://www.r-project.orgDownload install R-studio. must download install R first installing R-studio. R-studio website https://www.rstudio.com","code":""},{"path":"r-rstudio-github.html","id":"github.com-and-github-desktop","chapter":"R, RStudio, & Github","heading":"0.4 Github.com and Github Desktop","text":"Create free github account. github website https://github.comDownload install github desktop https://desktop.github.com","code":""},{"path":"r-rstudio-github.html","id":"test-the-pipeline","chapter":"R, RStudio, & Github","heading":"0.5 Test the pipeline","text":"semester students submitting work github repositories. Follow steps test github pipeline make sure working:Create new R project (initialize git)Create new R Markdown documentPublish R project folder Github.comMake commits demonstrate local changes reflected github.com","code":""},{"path":"r-rstudio-github.html","id":"why-are-we-using-r-for-this-statistics-lab","chapter":"R, RStudio, & Github","heading":"0.6 Why are we using R for this statistics lab?","text":"quick attempt explain think totally worth learn R data-analysis, psychologists general.","code":""},{"path":"r-rstudio-github.html","id":"rstudio-run-through","chapter":"R, RStudio, & Github","heading":"0.7 RStudio run through","text":"look features RStudio.","code":""},{"path":"basic-r-programming.html","id":"basic-r-programming","chapter":"Basic R programming","heading":"Basic R programming","text":"take number different approaches using R learn statistics semester. One approaches learn basic coding/scripting R, can become entire course . video gives impression coding looks feels like R Studio, introduces basic coding concepts variables, logic, loops, functions.","code":""},{"path":"practice-problems.html","id":"practice-problems","chapter":"Practice problems","heading":"Practice problems","text":"“8/27/2020 | Last Compiled: 2020-12-09”chapter supplement students looking exercises work coding skills outside class. labs course designed develop practical data analysis skills R, conceptual knowledge statistics using R way interact statistical phenomena. assume students may new coding. Don’t worry, student course, gradually introduce coding concepts throughout course.Learning code takes time effort, can intensely frustrating beginning. learning programming first time undergraduate, advisor (John Vokey) showed computer desk told teach program…pointed large hole drywall underneath desk said, “kick wall”.Learning teach coding also hard. ’ve trying years. However, stumble across methods seem promising, /immensely helpful , like advertise . example years ago came across completely different approach learning programming website Project Euler, highly recommend. website presents series problems, usually mathematical ones, like sum first 1000 prime numbers? challenge use programming language find correct answer. submit correct answers, unlock forum post working code (many different languages).idea Project Euler learn basic programming skills trying solve concrete problems. might know syntax make computer accomplish particular goal , particular goal mind, use search figure make programming language something.problems inspired Project Euler. past classes sometimes assigned problems little guidance anything R, class sat around puzzling things couple weeks. time, listing problems, along tips videos, eventually example code problems. Although problems involve statistics, . , intended concrete enough know question asking accomplish.think worthwhile try solve problems . time, can really helpful example solutions get stuck. P.S. favorite problem snakes ladders simulation, think can learn solve problem R, well way able solve sorts data-analysis problems, give problem try solve , congrats, think ’s pretty impressive .","code":""},{"path":"practice-problems.html","id":"programming-challenges-i","chapter":"Practice problems","heading":"0.8 Programming Challenges I","text":"purpose problems, try solve ? important overarching goal learning code become justifiably confident ability write scripts solve problems. end day applying skills new problems without textbook answers, ability solve problems rests learning write new code works. abstract problem, instead requires practice writing code solve new problems. following problem sets designed primarily aim mind. Solving problems simultaneously develop ability write scripts solve new problems, well give hands exposure learning syntax R language. problems written specifically R language, solving problems another language useful strategy learning syntax another language.problems roughly ordered terms difficulty, easier problems first harder problems second. problems can solve combining foundational programming concepts already discussed. , can solved declaring variables, using logic statements, loops create algorithms solve problem. problems require writing functions, formal general way writing algorithms. Many problems can solved quickly efficiently writing lines code, using intrinsic functions already supplied R programming language. problems might consider writing different solutions explore different syntax options.","code":""},{"path":"practice-problems.html","id":"easier-problems","chapter":"Practice problems","heading":"0.9 Easier Problems","text":"simple math numbers, addition, subtraction, multiplication, divisionPut numbers variables, simple math variablesWrite code place numbers 1 100 separately variable using loop. , using seq function.Find sum integer numbers 1 100.can use sum() function vector numbersHow without using sum function? example, use loop accomplish task?Write function find sum integers two values.List odd numbers 1 100.use seq() functionHow without using seq() function? Consider using mod function %%, evaluates whether remainder dividing one number another.List prime numbers 1 1000.Generate 100 random numberscheck runif functionto look help file run ?runif console. general ?function_name show help file function R.Generate 100 random numbers within specific rangerunif can thisWrite functions give descriptive statistics vector variable storing multiple numbers. Write functions following without using R intrinsics: mean, mode, median, range, standard deviationIt’s ok use sum() length()creative see can find multiple solutions. example two ways compute mean.Count number characters string variableuse strsplit() split character vectorCount number words string variableuse strsplitCount number sentences string variableconsider splitting . characterCount number times specific character occurs string variabletable() function can help count individual occurencesHow without table function?logical test see one word found within text another string variable.example given word hello, can run test see contained test sentence?consider using %%Put current computer time milliseconds variableMeasure long piece code takes run measuring time code run, code run, taking difference find total timeMeasure long piece code takes run measuring time code run, code run, taking difference find total timeRead .txt file .csv file variableRead .txt file .csv file variablescan() general purpose text input functionread.csv() read .csv filesOutput contents variable .txt filewrite.csv()Create variable stores 20x20 matrix random numbershere’s make matrix full 0sOutput matrix txt file using commas tabs separate column values, new lines separate row valueswrite.csv()","code":"\n# syntax for writing a function\n\nfunction_name <- function(input_name){\n  #body where you modify input\n  return(name_of_output)\n}\n\n# running the function\nfunction_name(some_input)\n# four divided by two gives no remainder\n# the mod function shows 0\n4%%2\n#> [1] 0\n\n# 5 divided by two gives a remainder\n# the mod function shows 1\n5%%2\n#> [1] 1\n# using sum and length\nmean_A <- function(x){\n  return(sum(x)/length(x))\n}\n\nsome_numbers <- c(1,2,3,4,5)\nmean_A(some_numbers)\n#> [1] 3\n\n# no intrinsics\nmean_B <- function(x){\n  counter <- 0\n  total_sum <-0\n  for(i in x){\n    total_sum <- total_sum+i\n    counter<-counter+1\n  }\n  return(total_sum/counter)\n}\n\nmean_B(some_numbers)\n#> [1] 3\na <- \"adskfjhkadsjfh\"\nstrsplit(a,split=\"\")\n#> [[1]]\n#>  [1] \"a\" \"d\" \"s\" \"k\" \"f\" \"j\" \"h\" \"k\" \"a\" \"d\" \"s\" \"j\" \"f\" \"h\"\n\n# note that strsplit returns its result in a list\nb <-strsplit(a,split=\"\")\nb[[1]] # access all elements in list 1\n#>  [1] \"a\" \"d\" \"s\" \"k\" \"f\" \"j\" \"h\" \"k\" \"a\" \"d\" \"s\" \"j\" \"f\" \"h\"\nb[[1]][1] # access first element of list 1\n#> [1] \"a\"\n\n# lists can be unlisted\nd <- unlist(strsplit(a,split=\"\"))\nd  # all elements in character vector\n#>  [1] \"a\" \"d\" \"s\" \"k\" \"f\" \"j\" \"h\" \"k\" \"a\" \"d\" \"s\" \"j\" \"f\" \"h\"\nd[1] #first element\n#> [1] \"a\"\na <- \"this is a sentence\"\nstrsplit(a,split=\" \") # use a space as the splitting character\n#> [[1]]\n#> [1] \"this\"     \"is\"       \"a\"        \"sentence\"\na <- c(1,3,2,3,2,3,2,3,4,5,4,3,4,3,4,5,6,7)\ntable(a)\n#> a\n#> 1 2 3 4 5 6 7 \n#> 1 3 6 4 2 1 1\ntest_word <- \"hello\"\ntest_sentence <-\"is the word hello in this sentence\"\na <- c(1,2,3,4,5)\nb <- 5\nd <- 8\n\n# question is b in a?\nb%in%a\n#> [1] TRUE\n\n# is d in a?\nd%in%a\n#> [1] FALSE\nprint(as.numeric(Sys.time())*1000, digits=15)\n#> [1] 1607480572704.37\na <- matrix(0, ncol=20,nrow=20)"},{"path":"practice-problems.html","id":"harder-problems","chapter":"Practice problems","heading":"0.10 Harder Problems","text":"","code":""},{"path":"practice-problems.html","id":"fizzbuzz","chapter":"Practice problems","heading":"0.10.1 FizzBuzz","text":"List numbers 1 100 following constraints. number can divided three evenly, print Fizz instead number. number can divided five evenly, print Buzz instead number. Finally, number can divided three five evenly, print FizzBuzz instead number. answer look something like :1, 2, Fizz, 4, Buzz, Fizz, 7, 8, Fizz, Buzz, 11, Fizz, 13, 14, FizzBuzz, 16, 17, Fizz, 19, Buzz, Fizz, 22, 23, Fizz, Buzz, 26, Fizz, 28, 29, FizzBuzz, 31, 32, Fizz, 34, Buzz, Fizz, 37, 38, Fizz, Buzz, 41, Fizz, 43, 44, FizzBuzz, 46, 47, Fizz, 49, Buzz, Fizz, 52, 53, Fizz, Buzz, 56, Fizz, 58, 59, FizzBuzz, 61, 62, Fizz, 64, Buzz, Fizz, 67, 68, Fizz, Buzz, 71, Fizz, 73, 74, FizzBuzz, 76, 77, Fizz, 79, Buzz, Fizz, 82, 83, Fizz, Buzz, 86, Fizz, 88, 89, FizzBuzz, 91, 92, Fizz, 94, Buzz, Fizz, 97, 98, Fizz, BuzzHere bits might useful","code":"\n# a number mod three will return 0 if it divides evenly\n6%%3\n#> [1] 0\n# a number mod five will return 0 if it divides evenly\n10%%5\n#> [1] 0\n\n# examples of replacing elements of a vector\na<-c(1,2,3,4,5)\na[3]<-\"Fizz\"\na\n#> [1] \"1\"    \"2\"    \"Fizz\" \"4\"    \"5\"\n\n# notice that a starts as a numeric vector\n# but changes to an all character vector after \"Fizz\" is added"},{"path":"practice-problems.html","id":"frequency-counts","chapter":"Practice problems","heading":"0.10.2 Frequency Counts","text":"Take text input, able produce table shows counts character text. problem related earlier easy problem asking count number times single letter appears text. slightly harder problem general version: count frequencies unique characters text.’s easy way thisCan without using table? Attempt problem using data.frame. tips","code":"\na<-\"some text that has some letters\"\ntable(unlist(strsplit(a,split=\"\")))\n#> \n#>   a e h l m o r s t x \n#> 5 2 5 2 1 2 2 1 4 6 1\n# data.frame is data format that produces named columns of data\n\n# creates two vectors\nnumbers <-c(1,2,3,4,5)\nletters <-c(\"a\",\"b\",\"c\",\"d\",\"e\")\n\n# make a data.frame from two vectors\nnew_df <- data.frame(numbers,letters)\nprint(new_df)\n#>   numbers letters\n#> 1       1       a\n#> 2       2       b\n#> 3       3       c\n#> 4       4       d\n#> 5       5       e\n\n# access individual columns of dataframe\nnew_df$numbers\n#> [1] 1 2 3 4 5\nnew_df$letters\n#> [1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\n# get names of data.frame\nnames(new_df)\n#> [1] \"numbers\" \"letters\"\n\n# break the problem into steps\n# first part of problem is to identify all unique character in the string\na<-c(1,2,3,4,5,2,2,3,2,3)\nunique(a)\n#> [1] 1 2 3 4 5\nb<-\"a string with some letters\"\nunique(unlist(strsplit(b,split=\"\")))\n#>  [1] \"a\" \" \" \"s\" \"t\" \"r\" \"i\" \"n\" \"g\" \"w\" \"h\" \"o\" \"m\" \"e\" \"l\"\n\n# second part is to go through each of the unique letters in the list of unique letters, and for each count the number of times they appear in the original text\n# store the results in a data.frame with two columns, one with the letter names, and another with the counts"},{"path":"practice-problems.html","id":"test-the-random-number-generator","chapter":"Practice problems","heading":"0.10.3 Test the Random Number Generator","text":"Test random number generator flat distribution. Generate million random numbers 0 100. Count number 0s, 1s, 2s, 3s, etc. way 100. Look counts numbers determine relatively equal. example, plot counts Excel make histogram. bars close flat, number equal chance selected, random number generator working without bias.","code":"\na<-runif(100,0,100)\nhist(a)"},{"path":"practice-problems.html","id":"create-a-multiplication-table","chapter":"Practice problems","heading":"0.10.4 Create a multiplication table","text":"Generate matrix multiplication table. example, labels columns numbers 1 10, labels rows numbers 1 10. contents cells matrix correct answer multiplying column value row value.","code":"\n# you can multiply all numbers in a vector in one go\na<-c(1,2,3,4,5,6,7,8,9,10)\na*2\n#>  [1]  2  4  6  8 10 12 14 16 18 20\n\n# you can nest loops\nfor(i in 1:3){\n  for(j in 1:3){\n    print(i*j)\n  }\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 2\n#> [1] 4\n#> [1] 6\n#> [1] 3\n#> [1] 6\n#> [1] 9"},{"path":"practice-problems.html","id":"encrypt-and-decrypt-the-alphabet","chapter":"Practice problems","heading":"0.10.5 Encrypt and Decrypt the Alphabet","text":"Turn normal english text encrypted version text, able turn decrypted text back normal english text. simple encryption scramble alphabet letter corresponds new randomly chosen (unique) letter.\n- following code shows example using numbershere different approach making use factor() function","code":"\noriginal_sequence <- c(1,2,3,4,5,2,2,3,2,4,5,2)\nnumbers <- unique(original_sequence)\nscrambled_numbers <- sample(numbers)\nencryption_key <- data.frame(numbers,scrambled_numbers)\n\nencrypt_numbers <-function(input_sequence,key){\n  encrypted_sequence<-c()\n  for(i in 1:length(input_sequence)){\n    original_number <- input_sequence[i]\n    new_number <- key[key$numbers==original_number,]$scrambled_numbers\n    encrypted_sequence[i] <- new_number\n  }\n  return(encrypted_sequence)\n}\n\nencrypt_numbers(original_sequence,encryption_key)\n#>  [1] 3 5 4 1 2 5 5 4 5 1 2 5\noriginal_sequence <- c(1,2,3,4,5,2,2,3,2,4,5,2)\noriginal_sequence <- as.factor(original_sequence)\nlevels(original_sequence) # show names of levels in factor\n#> [1] \"1\" \"2\" \"3\" \"4\" \"5\"\nnew_sequence <- original_sequence # copy\nlevels(new_sequence)<-c(5,4,3,2,1) # rename the levels\nnew_sequence # all elements are now changed\n#>  [1] 5 4 3 2 1 4 4 3 4 2 1 4\n#> Levels: 5 4 3 2 1"},{"path":"practice-problems.html","id":"snakes-and-ladders","chapter":"Practice problems","heading":"0.10.6 Snakes and Ladders","text":"task write algorithm can simulate playing depicted Snakes Ladders board. assume roll dice produces random number 1 6. able simulate one played game, write loop simulate 1000 games, estimate average number dice rolls needed successfully complete game.-tip: consider simpler version problem. many times need roll dice dice rolls add 25 greater?add representaion board, change square player depending whether land ladder snake.","code":"\n# rolling a dice with sample\nsample(c(1,2,3,4,5,6),1)\n#> [1] 4\nsample(c(1,2,3,4,5,6),1)\n#> [1] 1\nsample(c(1,2,3,4,5,6),1)\n#> [1] 1\n\n# try one simulation\ntotal_sum<-0\nnumber_of_rolls<-0\nwhile(total_sum < 25){\n  number_of_rolls <- number_of_rolls+1\n  total_sum <-total_sum+sample(c(1,2,3,4,5,6),1)\n}\nnumber_of_rolls\n#> [1] 8\n\n# record the results from multiple simulations\n\nsave_rolls <- c()\nfor(sims in 1:100){\n  total_sum<-0\n  number_of_rolls<-0\n  while(total_sum < 25){\n    number_of_rolls <- number_of_rolls+1\n    total_sum <-total_sum+sample(c(1,2,3,4,5,6),1)\n  }\n  save_rolls[sims] <- number_of_rolls\n}\nmean(save_rolls)\n#> [1] 7.74"},{"path":"practice-problems.html","id":"dice-rolling-simulations","chapter":"Practice problems","heading":"0.10.7 Dice-rolling simulations","text":"Assume pair dice rolled. Using monte carlo-simulation, compute probabilities rolling 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, respectively.","code":""},{"path":"practice-problems.html","id":"monte-hall-problem","chapter":"Practice problems","heading":"0.10.8 Monte Hall problem","text":"monte-hall problem follows. contestant game show presented three closed doors. told prize behind one door, two goats behind two doors. asked choose door contains prize. making choice game show host opens one remaining two doors (chosen contestant), reveals goat. now two door remaining. contestant asked like switch choice door, keep initial choice. correct answer participant switch initial choice, choose door. increase odds winning. Demonstrate monte-carlo simulation odds winning higher participant switches participants keeps original choice.","code":""},{"path":"practice-problems.html","id":"doors-problem","chapter":"Practice problems","heading":"0.10.9 100 doors problem","text":"Problem: 100 doors row initially closed. make 100 passes doors. first time , visit every door toggle door (door closed, open ; open, close ). second time visit every 2nd door (door 2, 4, 6, etc.). third time, every 3rd door (door 3, 6, 9, etc.), etc, visit 100th door.Question: state doors last pass? open, closed?","code":""},{"path":"practice-problems.html","id":"bottles-of-beer-problem","chapter":"Practice problems","heading":"0.10.10 99 Bottles of Beer Problem","text":"puzzle, write code print entire “99 bottles beer wall”\" song. know song, lyrics follow form:X bottles beer wall X bottles beer Take one , pass around X-1 bottles beer wallWhere X X-1 replaced numbers course, 99 way 0.","code":""},{"path":"practice-problems.html","id":"random-tic-tac-toe","chapter":"Practice problems","heading":"0.10.11 Random Tic-Tac-Toe","text":"Imagine two players make completely random choices playing tic-tac-toe. game either end draw one two players win. Create monte-carlo simulation “random” version tic-tac-toe. 10,000 simulations, proportion time game won versus drawn?","code":""},{"path":"coding-reference.html","id":"coding-reference","chapter":"Coding Reference","heading":"Coding Reference","text":"page contains minimal explanations examples common coding patterns base R tidyverse. Students can make content requests contribute reference page, just leave message github issues course repository.","code":""},{"path":"coding-reference.html","id":"base-r","chapter":"Coding Reference","heading":"0.11 Base R","text":"Base R refers intrinsics capabilities R come fresh installation R. additional libraries needed.","code":""},{"path":"coding-reference.html","id":"variables","chapter":"Coding Reference","heading":"0.12 Variables","text":"variable name. <- assignment operator. example, 1 assigned object named .Variables classes describe contents.Classes allow disallow commands. example, can’t add numeric character:Classes can converted:","code":"\na <- 1\nx <- 1\nclass(x)\n#> [1] \"numeric\"\n\ny <- \"1\"\nclass(y)\n#> [1] \"character\"\n\nz <- TRUE\nclass(z)\n#> [1] \"logical\"\nx+y\n#> Error in x + y: non-numeric argument to binary operator\ny <- as.numeric(y)\nx+y\n#> [1] 2"},{"path":"coding-reference.html","id":"vectors","chapter":"Coding Reference","heading":"0.12.1 Vectors","text":"Vectors 1-dimensional objects name, can hold multiple elements class. number elements vector vector length. Manipulating vectors involves creating , storing, retrieving, changing elements inside vector.","code":""},{"path":"coding-reference.html","id":"vector-creation","chapter":"Coding Reference","heading":"0.12.1.1 Vector Creation","text":"multiple ways create vectorlength() returns number elements vector","code":"\na <- c() # create a NULL vector\na\n#> NULL\n\na <- 1:5 # assign a sequence to a name\na\n#> [1] 1 2 3 4 5\n\na <- c(1,2,3,4,5) # assign a vector made with combine c()\na\n#> [1] 1 2 3 4 5\n\n#pre-assign an empty vector\na <- vector(mode = \"numeric\", length=10)\na\n#>  [1] 0 0 0 0 0 0 0 0 0 0\n\na <- vector(mode = \"integer\", length=10)\na\n#>  [1] 0 0 0 0 0 0 0 0 0 0\n\na <- vector(mode = \"logical\", length=10)\na\n#>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\na <- vector(mode = \"character\", length=10)\na\n#>  [1] \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\" \"\"\na < c(1,4,5)\n#>  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\nlength(a)\n#> [1] 10"},{"path":"coding-reference.html","id":"vector-combination","chapter":"Coding Reference","heading":"0.12.1.2 Vector Combination","text":"possible combine existing vectors together make new vector using c().However, attempt combine vectors different classes, R throw error, coerce (convert) one vectors class .","code":"\nx <- 1:5\ny <- 6:10\n\nx\n#> [1] 1 2 3 4 5\ny\n#> [1]  6  7  8  9 10\n\nz <- c(x,y)\nz\n#>  [1]  1  2  3  4  5  6  7  8  9 10\nx <- 1:5\ny <- c(\"a\",\"b\",\"c\",\"d\",\"e\")\n\nx\n#> [1] 1 2 3 4 5\ny\n#> [1] \"a\" \"b\" \"c\" \"d\" \"e\"\n\nz <- c(x,y)\nz\n#>  [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"a\" \"b\" \"c\" \"d\" \"e\""},{"path":"coding-reference.html","id":"vector-indexing","chapter":"Coding Reference","heading":"0.12.1.3 Vector Indexing","text":"Vector indexing process isolating specific positions elements vector. Vector indexing uses [] notation.general syntax vector_name[positions], vector_name name vector, positions vector positions index.Logical vectors can indicate positions. case, elements TRUE positions returned","code":"\na <- c(23,34,45,56,67,78,89)\n\na[1] # returns the element in position 1\n#> [1] 23\n\na[1:3] # returns elements in positions 1 to 3\n#> [1] 23 34 45\n\na[c(4,5,6)]\n#> [1] 56 67 78\n\na[c(1,1,1)]\n#> [1] 23 23 23\na <- c(45,56,78)\n\na[c(TRUE, FALSE, FALSE)]\n#> [1] 45\n\na[c(FALSE, TRUE, FALSE)]\n#> [1] 56\n\na[c(FALSE, FALSE, TRUE)]\n#> [1] 78"},{"path":"coding-reference.html","id":"vector-indexing-and-assignment","chapter":"Coding Reference","heading":"0.12.1.4 Vector indexing and assignment","text":"Vector indexing can also used assign new elements indexed positions.","code":"\na <- c(45,56,78)\na\n#> [1] 45 56 78\n\na[3] <- 100\na\n#> [1]  45  56 100\n\na[1:3] <- \"Hello\"\na\n#> [1] \"Hello\" \"Hello\" \"Hello\""},{"path":"coding-reference.html","id":"logical-indexing","chapter":"Coding Reference","heading":"0.12.1.5 Logical indexing","text":"Vectors can indexing using logical comparisons (see section logic explanation examples logical comparisons).","code":"\na <- c(1,3,2,4,3,4)\n\na == 4 # create logical vector of positions containing 4\n#> [1] FALSE FALSE FALSE  TRUE FALSE  TRUE\n\n# inserting the above into a[] finds the elements equal to 4\na[a == 4] # elements equal to 4\n#> [1] 4 4\n\na[a < 4] # elements less than 4\n#> [1] 1 3 2 3\n\na[a <= 4] # elements less than or equal to 4\n#> [1] 1 3 2 4 3 4\n\na[a != 1] # elements not equal to 1\n#> [1] 3 2 4 3 4"},{"path":"coding-reference.html","id":"data.frame","chapter":"Coding Reference","heading":"0.12.2 Data.frame","text":"Data.frames 2-d storage objects, like table (excel sheet), columns rows.","code":"\na <- data.frame() # make an empty data.frame\na\n#> data frame with 0 columns and 0 rows\nclass(a)\n#> [1] \"data.frame\""},{"path":"coding-reference.html","id":"data.frame-creation","chapter":"Coding Reference","heading":"0.12.2.1 Data.frame creation","text":"common method create data.frame involves adding existing vectors together. Data.frames often also created loading data files 2-d tables. See also section using dplyr manipulate data dataframes. Data.frames also similar data.tables, tibbles, can usually interchanged.dim() returns number rows columns data.frame","code":"\nx <- c(1,2,3)\ny <- c(\"a\",\"b\",\"c\")\nz <- c(TRUE, TRUE,TRUE)\n\na <- data.frame(x,y,z)\na\n#>   x y    z\n#> 1 1 a TRUE\n#> 2 2 b TRUE\n#> 3 3 c TRUE\ndim(a)\n#> [1] 3 3"},{"path":"coding-reference.html","id":"indexing-by-column-name","chapter":"Coding Reference","heading":"0.12.2.2 Indexing by column name","text":"column data.frame name, can accessed using $ syntax:","code":"\nnames(a)\n#> [1] \"x\" \"y\" \"z\"\n\na$x\n#> [1] 1 2 3\n\na$y\n#> [1] \"a\" \"b\" \"c\"\n\na$z\n#> [1] TRUE TRUE TRUE\n\n#re-name by assigning a new vector \nnames(a) <- c(\"new_x\",\"Why\",\"Zee\")\na\n#>   new_x Why  Zee\n#> 1     1   a TRUE\n#> 2     2   b TRUE\n#> 3     3   c TRUE\n\na$new_x\n#> [1] 1 2 3\na$Why\n#> [1] \"a\" \"b\" \"c\"\na$Zee\n#> [1] TRUE TRUE TRUE"},{"path":"coding-reference.html","id":"indexing-with-rowscolumns","chapter":"Coding Reference","heading":"0.12.2.3 Indexing with [rows,columns]","text":"Data.frames rows columns, can indexed using [rows,columns] notation, rows vector row numbers, columns vector column numbers","code":"\na\n#>   new_x Why  Zee\n#> 1     1   a TRUE\n#> 2     2   b TRUE\n#> 3     3   c TRUE\n\na[1,] # row 1\n#>   new_x Why  Zee\n#> 1     1   a TRUE\n\na[,1] # column 1\n#> [1] 1 2 3\n\na[1:2,] # rows 1 to 2\n#>   new_x Why  Zee\n#> 1     1   a TRUE\n#> 2     2   b TRUE\n\na[,1:2] # columns 1 to 2\n#>   new_x Why\n#> 1     1   a\n#> 2     2   b\n#> 3     3   c\n\na[1:2,1:2] #rows 1 to 2 and columns 1 to 2\n#>   new_x Why\n#> 1     1   a\n#> 2     2   b\n\na[1:2,'new_x'] # Column names can be used\n#> [1] 1 2"},{"path":"coding-reference.html","id":"row-and-column-binding","chapter":"Coding Reference","heading":"0.12.2.4 row and column binding","text":"possible add rows using rbind(), add columns using cbind().","code":"\n# row bind a copy of a to itself\na\n#>   new_x Why  Zee\n#> 1     1   a TRUE\n#> 2     2   b TRUE\n#> 3     3   c TRUE\na <- rbind(a,a)\ndim(a)\n#> [1] 6 3\n\n# create a new vector, add it as a new column\nmy_new <- c(1,4,3,2,4,5)\na <- cbind(a,my_new)\na\n#>   new_x Why  Zee my_new\n#> 1     1   a TRUE      1\n#> 2     2   b TRUE      4\n#> 3     3   c TRUE      3\n#> 4     1   a TRUE      2\n#> 5     2   b TRUE      4\n#> 6     3   c TRUE      5"},{"path":"coding-reference.html","id":"indexing-and-assignment","chapter":"Coding Reference","heading":"0.12.2.5 Indexing and assignment","text":"elements data.frame can re-assigned your_dataframe[row:position] <- new stuff. generally necessary new elements class original elements","code":"\na\n#>   new_x Why  Zee my_new\n#> 1     1   a TRUE      1\n#> 2     2   b TRUE      4\n#> 3     3   c TRUE      3\n#> 4     1   a TRUE      2\n#> 5     2   b TRUE      4\n#> 6     3   c TRUE      5\n\na[,1] <- 5 #assign column 1 all 5s\n\na$Why <- c(\"new\",\"words\",\"are\",\"going\",\"in\",\"here\")\na\n#>   new_x   Why  Zee my_new\n#> 1     5   new TRUE      1\n#> 2     5 words TRUE      4\n#> 3     5   are TRUE      3\n#> 4     5 going TRUE      2\n#> 5     5    in TRUE      4\n#> 6     5  here TRUE      5\n\na[6,3] <- FALSE # row 6, column 3\na\n#>   new_x   Why   Zee my_new\n#> 1     5   new  TRUE      1\n#> 2     5 words  TRUE      4\n#> 3     5   are  TRUE      3\n#> 4     5 going  TRUE      2\n#> 5     5    in  TRUE      4\n#> 6     5  here FALSE      5"},{"path":"coding-reference.html","id":"logical-indexing-1","chapter":"Coding Reference","heading":"0.12.2.6 Logical indexing","text":"also possible index data.frame logical comparisons. example, following returns rows value column my_new equals 4","code":"\na[a$my_new == 4,]\n#>   new_x   Why  Zee my_new\n#> 2     5 words TRUE      4\n#> 5     5    in TRUE      4"},{"path":"coding-reference.html","id":"lists","chapter":"Coding Reference","heading":"0.12.3 Lists","text":"Lists objects can store arbitrary elements class, including vectors, dataframes, even lists. Lists commonly used store results model, especially model returns many different kinds results different formats.create list three elements, scalar, vector, dataframe.","code":"\nx <- 1\ny <- c(1,2,3,4,5)\nz <- data.frame(a= 1:5, b=1:5, c=1:5)\nmy_list <- list(x, y, z)\n\nmy_list\n#> [[1]]\n#> [1] 1\n#> \n#> [[2]]\n#> [1] 1 2 3 4 5\n#> \n#> [[3]]\n#>   a b c\n#> 1 1 1 1\n#> 2 2 2 2\n#> 3 3 3 3\n#> 4 4 4 4\n#> 5 5 5 5"},{"path":"coding-reference.html","id":"list-indexing","chapter":"Coding Reference","heading":"0.12.3.1 List indexing","text":"Access elements list using [[]]","code":"\nmy_list[[1]]\n#> [1] 1\n\nmy_list[[2]]\n#> [1] 1 2 3 4 5\n\nmy_list[[3]]\n#>   a b c\n#> 1 1 1 1\n#> 2 2 2 2\n#> 3 3 3 3\n#> 4 4 4 4\n#> 5 5 5 5"},{"path":"coding-reference.html","id":"named-elements","chapter":"Coding Reference","heading":"0.12.3.2 Named elements","text":"Elements list can given names, indexed name:","code":"\nx <- 1\ny <- c(1,2,3,4,5)\nz <- data.frame(a= 1:5, b=1:5, c=1:5)\nmy_list <- list(ex = x, why = y,zee=  z)\n\nmy_list\n#> $ex\n#> [1] 1\n#> \n#> $why\n#> [1] 1 2 3 4 5\n#> \n#> $zee\n#>   a b c\n#> 1 1 1 1\n#> 2 2 2 2\n#> 3 3 3 3\n#> 4 4 4 4\n#> 5 5 5 5\n\nmy_list$ex\n#> [1] 1\nmy_list$why\n#> [1] 1 2 3 4 5\nmy_list$zee\n#>   a b c\n#> 1 1 1 1\n#> 2 2 2 2\n#> 3 3 3 3\n#> 4 4 4 4\n#> 5 5 5 5\n\nmy_list[[\"ex\"]]\n#> [1] 1\nmy_list[[\"why\"]]\n#> [1] 1 2 3 4 5\nmy_list[[\"zee\"]]\n#>   a b c\n#> 1 1 1 1\n#> 2 2 2 2\n#> 3 3 3 3\n#> 4 4 4 4\n#> 5 5 5 5"},{"path":"coding-reference.html","id":"addremove-elements-in-lists","chapter":"Coding Reference","heading":"0.12.3.3 Add/Remove elements in lists","text":"possible assign new names elements list, e.g.:","code":"\nmy_list[[\"new_thing\"]] <- 12345\n\nmy_list\n#> $ex\n#> [1] 1\n#> \n#> $why\n#> [1] 1 2 3 4 5\n#> \n#> $zee\n#>   a b c\n#> 1 1 1 1\n#> 2 2 2 2\n#> 3 3 3 3\n#> 4 4 4 4\n#> 5 5 5 5\n#> \n#> $new_thing\n#> [1] 12345\n\n#set an element to NULL removes it\nmy_list[[\"zee\"]] <- NULL\n\nmy_list\n#> $ex\n#> [1] 1\n#> \n#> $why\n#> [1] 1 2 3 4 5\n#> \n#> $new_thing\n#> [1] 12345"},{"path":"coding-reference.html","id":"logic","chapter":"Coding Reference","heading":"0.13 Logic","text":"Logic statements used compare two things, two sets things. output comparison TRUE FALSE statment. many things compared , output many TRUE FALSE statements comparison","code":""},{"path":"coding-reference.html","id":"equal-to","chapter":"Coding Reference","heading":"0.13.1 equal to ==","text":"","code":"\n1==1 # is 1 equal to 1?\n#> [1] TRUE\n1==2 # is 1 equal to 2?\n#> [1] FALSE\n\nc(1,2,3) == c(2,1,3) # compares each element with each element\n#> [1] FALSE FALSE  TRUE\n1 == c(2,1,3)\n#> [1] FALSE  TRUE FALSE"},{"path":"coding-reference.html","id":"not-equal-to","chapter":"Coding Reference","heading":"0.13.2 not equal to !=","text":"","code":"\n1!=1 # is 1 equal to 1?\n#> [1] FALSE\n1!=2 # is 1 equal to 2?\n#> [1] TRUE\n\nc(1,2,3) != c(2,1,3) # compares each element with each element\n#> [1]  TRUE  TRUE FALSE\n1 != c(2,1,3)\n#> [1]  TRUE FALSE  TRUE"},{"path":"coding-reference.html","id":"greater-than-less-than","chapter":"Coding Reference","heading":"0.13.3 Greater than/ less than","text":"","code":"\n\n1 > 1 # is 1 greater than 1?\n#> [1] FALSE\n5 > 1 # is 5 greater than 1?\n#> [1] TRUE\n3 < 2 # is 3 less than 2?\n#> [1] FALSE\n3 < 1 # is 3 less than 1?\n#> [1] FALSE\n\nc(1,2,3) > c(2,1,3) # ask the question element by element\n#> [1] FALSE  TRUE FALSE\nc(1,2,3) < c(2,1,3)\n#> [1]  TRUE FALSE FALSE\n\n2 > c(1,2,3) # is greater than each of the numbers\n#> [1]  TRUE FALSE FALSE"},{"path":"coding-reference.html","id":"section","chapter":"Coding Reference","heading":"0.13.4 >= <=","text":"something greater equal something else","code":"\n1 >= 1 # is 1 greater than 1?\n#> [1] TRUE\n5 >= 1 # is 5 greater than 1?\n#> [1] TRUE\n3 <= 2 # is 3 less than 2?\n#> [1] FALSE\n3 <= 1 # is 3 less than 1?\n#> [1] FALSE\n\nc(1,2,3) >= c(2,1,3) # ask the question element by element\n#> [1] FALSE  TRUE  TRUE\nc(1,2,3) <= c(2,1,3)\n#> [1]  TRUE FALSE  TRUE\n\n2 >= c(1,2,3) # is greater than each of the numbers\n#> [1]  TRUE  TRUE FALSE"},{"path":"coding-reference.html","id":"and","chapter":"Coding Reference","heading":"0.13.5 AND","text":"ampersand & used , allows use evaluate whether two properties TRUE.","code":"\n# is 16 divisible by 4 AND 8\n16%%4 == 0 & 16%%8 ==0\n#> [1] TRUE\n\n# is 16 divisible by 4 AND 3\n16%%4 == 0 & 16%%3 ==0\n#> [1] FALSE\n\n# is 16 divisible by 8 and 4 and 2\n16%%4 == 0 & 16%%8 ==0 & 16%%2 ==0\n#> [1] TRUE"},{"path":"coding-reference.html","id":"or","chapter":"Coding Reference","heading":"0.13.6 OR","text":"| used , allows use evaluate least one properties TRUE.","code":"\n# is 16 divisible by 4 OR 8\n16%%4 == 0 | 16%%8 ==0\n#> [1] TRUE\n\n# is 16 divisible by 4 OR 3\n# it is divisible by 4, so the answer is TRUE\n# because at least one of the comparisons is TRUE\n16%%4 == 0 | 16%%3 ==0\n#> [1] TRUE"},{"path":"coding-reference.html","id":"true-false","chapter":"Coding Reference","heading":"0.13.7 TRUE FALSE","text":"R returns values TRUE FALSE, return logical variable. also treats TRUE 1, FALSE 0. example see possible sum logical variable multiple TRUE FALSE entries.","code":"\nc(1,2,3) == c(1,2,3)\n#> [1] TRUE TRUE TRUE\nsum(c(1,2,3) == c(1,2,3))\n#> [1] 3\n\nc(1,2,3) == c(2,1,3)\n#> [1] FALSE FALSE  TRUE\nsum(c(1,2,3) == c(2,1,3))\n#> [1] 1"},{"path":"coding-reference.html","id":"if-else","chapter":"Coding Reference","heading":"0.14 IF ELSE","text":"roller-coaster operator checks people taller line see can ride coaster. ELSE control structure. person taller line, can go ride; ELSE (otherwise) person can go ride.words, situation X, something; ELSE (situation X), something different.ELSE statements let us specify conditions specific actions taken. Generally, ELSE statements used inside loops (, , repeat loops), step iteration loop, want check something, something.Consider :Normally find ELSE loop like :can multiple conditions statements. See next section loops info using loops.","code":"\na <- 1 # define a to be a 1\nif(a==1){  \n  print(a) # this is what happens if a==1\n} else {\n  print(\"A is not 1\") # this is what happens if a is not 1\n}\n#> [1] 1\n\n\na <- 2 # define a to be a 1\nif(a==1){  \n  print(a) # this is what happens if a==1\n} else {\n  print(\"A is not 1\") # this is what happens if a is not 1\n}\n#> [1] \"A is not 1\"\na <- c(1,0,1,0,0,0,1) # make a variable contain 1s and 0s\n\n# write a loop to check each element in the variable\n# and do different things depending on the element\n\nfor(i in a){\n  if(i == 1){\n    print(\"I'm a 1\") # what to do when i is 1\n  } else {\n    print(\"I'm not a 1\") # what to do when i is not 1\n  }\n}\n#> [1] \"I'm a 1\"\n#> [1] \"I'm not a 1\"\n#> [1] \"I'm a 1\"\n#> [1] \"I'm not a 1\"\n#> [1] \"I'm not a 1\"\n#> [1] \"I'm not a 1\"\n#> [1] \"I'm a 1\"\na <- c(1,2,3,1,2,0,1) # make a variable contain 1s and 0s\n\n# write a loop to check each element in the variable\n# and do different things depending on the element\n\nfor(i in a){\n  if(i == 1){\n    print(\"I'm a 1\") # what to do when i is 1\n  } else if (i==2){\n    print(\"I'm a 2\") # what to do when i is 2\n  } else if (i==3){\n    print(\"I'm a 3\") # what to do when i is 3\n  } else {\n    print(\"I'm not any of the above\") #what to do when none are true\n  }\n}\n#> [1] \"I'm a 1\"\n#> [1] \"I'm a 2\"\n#> [1] \"I'm a 3\"\n#> [1] \"I'm a 1\"\n#> [1] \"I'm a 2\"\n#> [1] \"I'm not any of the above\"\n#> [1] \"I'm a 1\""},{"path":"coding-reference.html","id":"loops","chapter":"Coding Reference","heading":"0.15 Loops","text":"Check R help Control Flow ?Control.(){}\n(loop control){something iteration}Loop control defined parentheses. name iterator placed left (can assigned name want, need declared advance). execution loop, iterator takes values inside vector placed right side . Specifically, following happening.Loop steps:\n1. iterator <- vector[1]\n2. iterator <- vector[2]\n3. iterator <- vector[3]\n4. etc.loop automatically stop reaches last item vector. loop can stopped using break command.","code":"\nfor(iterator in vector){\n  #do something\n}\n# Make a loop do something 5 times\n# i is the iterator\n# 1:5 creates a vector with 5 numbers in it, 1, 2, 3, 4, 5\n# the loop will run 5 times, because there are five things to assign to i\nfor(i in 1:5){\n  print(\"hello\")\n}\n#> [1] \"hello\"\n#> [1] \"hello\"\n#> [1] \"hello\"\n#> [1] \"hello\"\n#> [1] \"hello\"\n# show the value of i each step of the loop\nfor(i in 1:5){\n  print(i)\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n# define the vector to loop over in advance\nx <- 1:5\nfor(i in x){\n  print(i)\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n# Reminder that i becomes the next value in the vector\n# your vector can have any order \nmy_sequence <- c(1,5,2,3,4)\nfor(i in my_sequence){\n  print(i)\n}\n#> [1] 1\n#> [1] 5\n#> [1] 2\n#> [1] 3\n#> [1] 4\n# index vector does not need to be numbers\nmy_things <- c(\"A\",\"B\",\"C\",\"D\")\nfor(i in my_things){\n  print(i)\n}\n#> [1] \"A\"\n#> [1] \"B\"\n#> [1] \"C\"\n#> [1] \"D\""},{"path":"coding-reference.html","id":"breaking-a-loop","chapter":"Coding Reference","heading":"0.15.1 Breaking a loop","text":"break stops loop. Used logical statements define conditions necessary cause break.","code":"\nfor(i in 1:10){\n  if(i <5){\n    print(i)\n  } else{\n    break\n  }\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4"},{"path":"coding-reference.html","id":"while-loops","chapter":"Coding Reference","heading":"0.15.2 While loops","text":"loops run logical condition met. iterator, just logic statement needs met.one prints less 6. soon becomes “less 6”, loop stops. Critically, inside loop, value increases iteration.","code":"\ni <- 1 # create an variable\nwhile (i < 6) {\n  print(i)\n  i = i+1 #add one eachs step of the loop\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5"},{"path":"coding-reference.html","id":"repeat-loops","chapter":"Coding Reference","heading":"0.15.3 Repeat loops","text":"Similar , let’s things condition met.","code":"\ni<-0\nrepeat{\n  i<-i+1\n  print(i)\n  if(i==5){\n    break\n  }\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5"},{"path":"coding-reference.html","id":"examples","chapter":"Coding Reference","heading":"0.15.4 Examples","text":"Braces needed one lineUsing value iterator assign values systematically another variable.Make counter, need oneNesting loopsbreak exits immediate loop","code":"\nfor(i in 1:5) print(i)\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n# put 1 into the first five positions of x\nx <- c() # create empty vector\nfor(i in 1:5){\n  x[i] <- 1  # assign 1 to the ith slot in x\n}\nx\n#> [1] 1 1 1 1 1\n\n# put the numbers 1-5 in the first 5 positions of x\nx <-c()\nfor(i in 1:5){\n  x[i] <- i\n}\nx\n#> [1] 1 2 3 4 5\na <- c(1,4,3,5,7,6,8,2)\nodd <- c()\ncounter <- 0\nfor(i in a){  # i will the values of a in each position\n  counter <- counter+1\n  if(i%%2 != 0){\n    odd[counter] <- \"odd\"\n  } else {\n    odd[counter] <- \"even\"\n  }\n}\nodd\n#> [1] \"odd\"  \"even\" \"odd\"  \"odd\"  \"odd\"  \"even\" \"even\" \"even\"\n\n# An alternative strategy\n\na <- c(1,4,3,5,7,6,8,2)\nodd <- c()\n# 1:length(a) creates a sequence from 1 to length\nfor(i in 1:length(a)){  \n  if(a[i]%%2 != 0){\n    odd[i] <- \"odd\"\n  } else {\n    odd[i] <- \"even\"\n  }\n}\nodd\n#> [1] \"odd\"  \"even\" \"odd\"  \"odd\"  \"odd\"  \"even\" \"even\" \"even\"\n\nfor(i in 1:5){\n  for(j in 1:5){\n   print(c(i,j))\n  }\n}\n#> [1] 1 1\n#> [1] 1 2\n#> [1] 1 3\n#> [1] 1 4\n#> [1] 1 5\n#> [1] 2 1\n#> [1] 2 2\n#> [1] 2 3\n#> [1] 2 4\n#> [1] 2 5\n#> [1] 3 1\n#> [1] 3 2\n#> [1] 3 3\n#> [1] 3 4\n#> [1] 3 5\n#> [1] 4 1\n#> [1] 4 2\n#> [1] 4 3\n#> [1] 4 4\n#> [1] 4 5\n#> [1] 5 1\n#> [1] 5 2\n#> [1] 5 3\n#> [1] 5 4\n#> [1] 5 5\n\n# example of using nested loops to fill the contents\n# of a matrix\n\nmy_matrix <- matrix(0,ncol=5,nrow=5)\nfor(i in 1:5){\n  for(j in 1:5){\n   my_matrix[i,j] <- i*j\n  }\n}\nmy_matrix\n#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]    1    2    3    4    5\n#> [2,]    2    4    6    8   10\n#> [3,]    3    6    9   12   15\n#> [4,]    4    8   12   16   20\n#> [5,]    5   10   15   20   25\n# the inside loop stops when i+j is greater than 5\n# the outside loop keeps going\n\nsum_of_i_j <- c()\ncounter <- 0\nfor(i in 1:5){\n  for(j in 1:5){\n    counter <- counter+1\n    sum_of_i_j[counter] <- i+j\n    if(i+j > 5){\n      break\n    }\n  }\n}\nsum_of_i_j\n#>  [1] 2 3 4 5 6 3 4 5 6 4 5 6 5 6 6"},{"path":"coding-reference.html","id":"functions","chapter":"Coding Reference","heading":"0.16 Functions","text":"section discusses syntax writing custom functions R.","code":""},{"path":"coding-reference.html","id":"function-syntax","chapter":"Coding Reference","heading":"0.16.1 function syntax","text":"","code":"\nfunction_name <- function(input1,input2){\n  #code here\n  return(something)\n}"},{"path":"coding-reference.html","id":"example-functions","chapter":"Coding Reference","heading":"0.16.2 example functions","text":"function input (). Whenever run function, simply return whatever placed inside return statement.function simply takes input, returns input without modifying .function takes input, creates internal variable called temp assigns input+1. contents temp returned. Note , checking input, return erro input character (can’t add one character R)function adds input checking. add one input numeric type. Otheriwse, use stop() return error message consoleA function three inputs","code":"\n# define the function\nprint_hello_world <- function(){\n  return(print(\"hello world\"))\n}\n\n# use the function\nprint_hello_world()\n#> [1] \"hello world\"\nreturn_input <- function(input){\n  return(input)\n}\n\n# the variable input is assigned a 1\n# then we return(input), which will result in a 1\n# because the function internally assigns 1 to the input\nreturn_input(1)\n#> [1] 1\n\na <- \"something\"\nreturn_input(a)\n#> [1] \"something\"\nadd_one <- function(input){\n  temp <- input+1\n  return(temp)\n}\n\nadd_one(1)\n#> [1] 2\nadd_one(\"a\")\n#> Error in input + 1: non-numeric argument to binary operator\nadd_one <- function(input){\n  if(class(input) == \"numeric\"){\n    temp <- input+1\n    return(temp)\n  } else {\n    return(stop(\"input must be numeric\"))\n  }\n}\n\nadd_one(1)\n#> [1] 2\nadd_one(\"a\")\n#> Error in add_one(\"a\"): input must be numeric\nadd_multiply <- function(input, x_plus,x_times){\n  temp <- (input+x_plus)*x_times\n  return(temp)\n}\n\n# input is 1\n# x_plus <- 2\n# x_times <- 3\n# will return (1+2)*3 = 9\nadd_multiply(1,2,3)\n#> [1] 9"},{"path":"coding-reference.html","id":"tidyverse","chapter":"Coding Reference","heading":"0.17 Tidyverse","text":"tidyverse set popular R packages convenient many aspects data-analysis. tidyverse packages can installed one go:","code":"\ninstall.packages(\"tidyverse\")"},{"path":"coding-reference.html","id":"dplyr","chapter":"Coding Reference","heading":"0.18 dplyr","text":"dplyr package several useful functions manipulating summarizing data.frames. illustrate dplyr functionality first create small fake data.frame. link dplyr cheatsheet","code":"\nsubjects <- rep(1:10)\ngrades <- rnorm(n = 10, mean = 65, sd = 5)\nage <- sample(18:20,10,replace=TRUE)\nlikes_chocolate <- sample(c(TRUE,FALSE), 10, replace=TRUE)\nfavorite_color <- sample(c(\"r\",\"o\",\"y\",\"g\",\"b\",\"i\",\"v\"), 10, replace=TRUE)\n\nfake_data <- data.frame(subjects,\n                        grades,\n                        age,\n                        likes_chocolate,\n                        favorite_color)\n\nknitr::kable(head(fake_data))"},{"path":"coding-reference.html","id":"group_by-and-summarize","chapter":"Coding Reference","heading":"0.18.1 group_by and summarize","text":"group_by() allows specify columns split groups analysis, groups levels column (e.g., unique entries column)summarize() conducts analysis group identified group_by step. analysis defined variable names, supplying function computes value given name measurement variable.","code":"\nlibrary(dplyr)\n\nfake_data %>%\n  group_by(likes_chocolate) %>%\n  summarize(mean_grade = mean(grades),\n            sd_grad = sd(grades))\n#> # A tibble: 2 x 3\n#>   likes_chocolate mean_grade sd_grad\n#>   <lgl>                <dbl>   <dbl>\n#> 1 FALSE                 66.5    6.59\n#> 2 TRUE                  67.8    4.81\n\nfake_data %>%\n  group_by(likes_chocolate,age) %>%\n  summarize(mean_grade = mean(grades),\n            sd_grad = sd(grades))\n#> # A tibble: 5 x 4\n#> # Groups:   likes_chocolate [2]\n#>   likes_chocolate   age mean_grade sd_grad\n#>   <lgl>           <int>      <dbl>   <dbl>\n#> 1 FALSE              18       58.8   NA   \n#> 2 FALSE              19       68.4    5.78\n#> 3 TRUE               18       65.5    5.04\n#> 4 TRUE               19       65.1   NA   \n#> 5 TRUE               20       71.4    4.75"},{"path":"coding-reference.html","id":"filter","chapter":"Coding Reference","heading":"0.18.2 filter","text":"Filter rows depending logical comparisons","code":"\nfake_data %>%\n  filter(grades < 65)\n#>   subjects   grades age likes_chocolate favorite_color\n#> 1        2 63.57233  19           FALSE              y\n#> 2        3 61.90138  18            TRUE              o\n#> 3        5 58.80694  18           FALSE              r\n#> 4        8 63.26356  19           FALSE              y\n\nfake_data %>%\n  filter(grades < 65,\n         likes_chocolate == TRUE)\n#>   subjects   grades age likes_chocolate favorite_color\n#> 1        3 61.90138  18            TRUE              o"},{"path":"coding-reference.html","id":"select","chapter":"Coding Reference","heading":"0.18.3 select","text":"Select specific columns","code":"\nfake_data %>%\n  select(grades)\n#>      grades\n#> 1  69.03042\n#> 2  63.57233\n#> 3  61.90138\n#> 4  74.80167\n#> 5  58.80694\n#> 6  68.09122\n#> 7  73.86248\n#> 8  63.26356\n#> 9  72.93247\n#> 10 65.12974\n\nfake_data %>%\n  select(grades,likes_chocolate)\n#>      grades likes_chocolate\n#> 1  69.03042            TRUE\n#> 2  63.57233           FALSE\n#> 3  61.90138            TRUE\n#> 4  74.80167            TRUE\n#> 5  58.80694           FALSE\n#> 6  68.09122            TRUE\n#> 7  73.86248           FALSE\n#> 8  63.26356           FALSE\n#> 9  72.93247           FALSE\n#> 10 65.12974            TRUE"},{"path":"coding-reference.html","id":"mutate","chapter":"Coding Reference","heading":"0.18.4 mutate","text":"mutate() can add column","code":"\nfake_data <- fake_data %>%\n  mutate(new_thing = 0)\n\nfake_data\n#>    subjects   grades age likes_chocolate favorite_color new_thing\n#> 1         1 69.03042  18            TRUE              g         0\n#> 2         2 63.57233  19           FALSE              y         0\n#> 3         3 61.90138  18            TRUE              o         0\n#> 4         4 74.80167  20            TRUE              y         0\n#> 5         5 58.80694  18           FALSE              r         0\n#> 6         6 68.09122  20            TRUE              v         0\n#> 7         7 73.86248  19           FALSE              b         0\n#> 8         8 63.26356  19           FALSE              y         0\n#> 9         9 72.93247  19           FALSE              y         0\n#> 10       10 65.12974  19            TRUE              y         0"},{"path":"coding-reference.html","id":"ggplot2","chapter":"Coding Reference","heading":"0.19 ggplot2","text":"ggplot2 library created Hadley Wickham plotting graphing results, refers “grammar graphics”, standardized syntax organization graphing.","code":""},{"path":"coding-reference.html","id":"ggplot2-additional-resources","chapter":"Coding Reference","heading":"0.19.1 ggplot2 additional resources","text":"https://ggplot2.tidyverse.orghttps://r4ds..co.nz/data-visualisation.htmlhttps://ggplot2-book.orghttp://r-statistics.co/ggplot2-Tutorial--R.htmlhttps://datacarpentry.org/R-ecology-lesson/04-visualization-ggplot2.html","code":""},{"path":"coding-reference.html","id":"add-on-packages","chapter":"Coding Reference","heading":"0.19.1.1 Add-on packages","text":"https://www.ggplot2-exts.org repository 50+ add packages ggplot2https://gganimate.com\nallows create animated .gifs ggplots\nmade bunch animated gifs statistics textbook. along code https://crumplab.github.io/statistics/gifs.html\nallows create animated .gifs ggplotsI made bunch animated gifs statistics textbook. along code https://crumplab.github.io/statistics/gifs.htmlggrepel allows repel overlapping text labels away .esquisse GUI (graphic user interface) allows make ggplot graphs using drag-drop, clickable optionsggedit similar , clickable editing ggplot graphsplotly package similar ggplot, makes whole variety graphs, mainly use websites. Allows interactive graphs.\nexample, used plotly publications website, hover dots, info pops https://crumplab.github.io/Publications.html.\nexample, used plotly publications website, hover dots, info pops https://crumplab.github.io/Publications.html.ggpubr (install CRAN), many useful things, including ggarrange function allows knit multiple plots togetherggthemes extra themes, scales, geoms","code":""},{"path":"coding-reference.html","id":"example-code","chapter":"Coding Reference","heading":"0.19.2 Example code","text":"Remember load ggplot2 library use ggplot2.","code":"\nlibrary(ggplot2)"},{"path":"coding-reference.html","id":"scatterplot","chapter":"Coding Reference","heading":"0.19.3 Scatterplot","text":"","code":"\n# Create dataframe\na <- c(1,2,3,2,3,4,5,4)\nb <- c(4,3,4,3,2,1,2,3)\nplot_df <- data.frame(a,b)\n\n# basic scatterplot\nggplot(plot_df, aes(x=a,y=b))+\n  geom_point()\n\n# customize, add regression line\nggplot(plot_df, aes(x=a,y=b))+\n  geom_point(size=2)+\n  geom_smooth(method=lm)+\n  coord_cartesian(xlim=c(0,7),ylim=c(0,10))+\n  xlab(\"x-axis label\")+\n  ylab(\"y-axis label\")+\n  ggtitle(\"I made a scatterplot\")+\n  theme_classic(base_size=12)+\n  theme(plot.title = element_text(hjust = 0.5))"},{"path":"coding-reference.html","id":"bar-graph","chapter":"Coding Reference","heading":"0.19.4 bar graph","text":"1 factor2 factor3 factor","code":"\n#Create a dataframe\nfactor_one <- as.factor(c(\"A\",\"B\",\"C\"))\ndv_means <- c(20,30,40)\ndv_SEs   <- c(4,3.4,4)\nplot_df <- data.frame(factor_one,\n                      dv_means,\n                      dv_SEs)\n\n# basic bar graph\n\nggplot(plot_df, aes(x=factor_one,y=dv_means))+\n  geom_bar(stat=\"identity\")\n\n# adding error bars, customizing\n\nggplot(plot_df, aes(x=factor_one,y=dv_means))+\n  geom_bar(stat=\"identity\")+\n  geom_errorbar(aes(ymin=dv_means-dv_SEs,\n                    ymax=dv_means+dv_SEs),\n                width=.2)+\n  coord_cartesian(ylim=c(0,100))+\n  xlab(\"x-axis label\")+\n  ylab(\"y-axis label\")+\n  ggtitle(\"I made a bar graph\")+\n  theme_classic(base_size=12)+\n  theme(plot.title = element_text(hjust = 0.5))\n#Create a dataframe\nfactor_one <- rep(as.factor(c(\"A\",\"B\",\"C\")),2)\nfactor_two <- rep(as.factor(c(\"IIA\",\"IIB\")),3)\ndv_means <- c(20,30,40,20,40,40)\ndv_SEs   <- c(4,3.4,4,3,2,4)\nplot_df <- data.frame(factor_one,\n                      factor_two,\n                      dv_means,\n                      dv_SEs)\n\n# basic bar graph\n\nggplot(plot_df, aes(x=factor_one,y=dv_means,\n                    group=factor_two,\n                    color=factor_two))+\n  geom_bar(stat=\"identity\", position=\"dodge\")\n\n# adding error bars, customizing\n\nggplot(plot_df, aes(x=factor_one,y=dv_means,\n                    group=factor_two,\n                    color=factor_two,\n                    fill=factor_two))+\n  geom_bar(stat=\"identity\", position=\"dodge\")+\n  geom_errorbar(aes(ymin=dv_means-dv_SEs,\n                    ymax=dv_means+dv_SEs),\n                position=position_dodge(width=0.9),\n                width=.2,\n                color=\"black\")+\n  coord_cartesian(ylim=c(0,100))+\n  xlab(\"x-axis label\")+\n  ylab(\"y-axis label\")+\n  ggtitle(\"Bar graph 2 factors\")+\n  theme_classic(base_size=12)+\n  theme(plot.title = element_text(hjust = 0.5))\n#Create a dataframe\nfactor_one <- rep(rep(as.factor(c(\"A\",\"B\",\"C\")),2),2)\nfactor_two <- rep(rep(as.factor(c(\"IIA\",\"IIB\")),3),2)\nfactor_three <- rep(as.factor(c(\"IIIA\",\"IIIB\")),each=6)\ndv_means <- c(20,30,40,20,40,40,\n              10,20,50,50,10,10)\ndv_SEs   <- c(4,3.4,4,3,2,4,\n              1,2,1,2,3,2)\nplot_df <- data.frame(factor_one,\n                      factor_two,\n                      factor_three,\n                      dv_means,\n                      dv_SEs)\n\n# basic bar graph\n\nggplot(plot_df, aes(x=factor_one,y=dv_means,\n                    group=factor_two,\n                    color=factor_two))+\n  geom_bar(stat=\"identity\", position=\"dodge\")+\n  facet_wrap(~factor_three)"},{"path":"coding-reference.html","id":"line-graph","chapter":"Coding Reference","heading":"0.19.5 Line Graph","text":"1 factor2 factor","code":"\n#Create a dataframe\nfactor_one <- as.factor(c(\"A\",\"B\",\"C\"))\ndv_means <- c(20,30,40)\ndv_SEs   <- c(4,3.4,4)\nplot_df <- data.frame(factor_one,\n                      dv_means,\n                      dv_SEs)\n\n# basic line graph\n\nggplot(plot_df, aes(x=factor_one,y=dv_means, group=1))+\n  geom_point()+\n  geom_line()\n\n# adding error bars, customizing\n\nggplot(plot_df, aes(x=factor_one,y=dv_means, group=1))+\n  geom_point()+\n  geom_line()+\n  geom_errorbar(aes(ymin=dv_means-dv_SEs,\n                    ymax=dv_means+dv_SEs),\n                width=.2)+\n  coord_cartesian(ylim=c(0,100))+\n  xlab(\"x-axis label\")+\n  ylab(\"y-axis label\")+\n  ggtitle(\"I made a line graph\")+\n  theme_classic(base_size=12)+\n  theme(plot.title = element_text(hjust = 0.5))\n#Create a dataframe\nfactor_one <- rep(as.factor(c(\"A\",\"B\",\"C\")),2)\nfactor_two <- rep(as.factor(c(\"IIA\",\"IIB\")),3)\ndv_means <- c(20,30,40,20,40,40)\ndv_SEs   <- c(4,3.4,4,3,2,4)\nplot_df <- data.frame(factor_one,\n                      factor_two,\n                      dv_means,\n                      dv_SEs)\n\n# basic line graph\n\nggplot(plot_df, aes(x=factor_one,y=dv_means,\n                    group=factor_two,\n                    color=factor_two,\n                    linetype=factor_two))+\n  geom_point()+\n  geom_line()"},{"path":"coding-reference.html","id":"histogram","chapter":"Coding Reference","heading":"0.19.6 Histogram","text":"base R","code":"\na<-rnorm(100,0,1)\nhist(a)\nscore <- rnorm(100,0,1)\nn <- 1:100\nplot_df <- data.frame(score,n)\n\nggplot(plot_df, aes(x=score))+\n  geom_histogram(bins=10,\n                 color=\"white\")"},{"path":"coding-reference.html","id":"knitr","chapter":"Coding Reference","heading":"0.20 knitr","text":"knitr package used compile R markdown documents formats html (webpages) pdf.","code":""},{"path":"coding-reference.html","id":"knitting-to-pdf","chapter":"Coding Reference","heading":"0.20.1 knitting to pdf","text":"latex installation required order knit pdf. Latex also free cross-platform, however complete installation can quite large.think advice Frederick Aust (author papaja package) installing latex worth following:https://crsh.github.io/papaja_man/introduction.html#getting-startedBasically, advice install complete tex distribution (follow links), use tinytex package R. tinytex package sufficient knitting pdf duties.Install tinytex library:Run command installing library","code":"install.packages(\"tinytex\")tinytex::install_tex()"},{"path":"coding-reference.html","id":"knitr-options","chapter":"Coding Reference","heading":"0.20.2 knitr options","text":"create new R Markdown document see following code chunk underneath yaml, beginning document. usually looks like :chunk named setup, printed output, controls global setup options whole document. option set applies remaining code chunks create. ’s way setting defaults.helpful defaults can add. turn option TRUE, turn FALSE.echo=TRUE sets default print remaining code blocks output, FALSE sets default print code blockswarning = FALSE turns printing warningsmessage = FALSE turns printing messages, commonly occur load package, receive message package loadedeval = FALSE sets default evaluate code chunk R Code. run code block, code block still print echo=TRUEerror=TRUE normally knit fails error code. set error=TRUE knit complete, return error message code blocks errors.","code":"```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n``````{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE,\n                      warning = FALSE,\n                      message = FALSE, \n                      eval = FALSE,\n                      error = TRUE)\n```"},{"path":"coding-reference.html","id":"knitr-figure-output-defaults","chapter":"Coding Reference","heading":"0.20.3 knitr figure output defaults","text":"following setup options useful figure output.fig.width = 3 sets default width inches figuresfig.height = 3 sets default height inches figuresfig.path = \"myfigs/\" defines folder figure files saved. relative current working directoydev = c(\"pdf\", \"png\") tells knitr output .png, .pdf versions figure. .pdf contains vector graphics, meaning figure can resized without pixelization.","code":"```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE,\n                      fig.width = 3,\n                      fig.height = 3,\n                      fig.path = \"myfigs/\",\n                      dev = c(\"pdf\", \"png\"))\n```"},{"path":"coding-reference.html","id":"figure-output-per-code-block","chapter":"Coding Reference","heading":"0.20.4 figure output per code block","text":"can set options remaining code blocks individually. overrule default options specify setup chunk.","code":"```{r figurename, fig.width =5, fig.height =7}\n\n# some code that generates a figure\n\n```"},{"path":"coding-reference.html","id":"tables","chapter":"Coding Reference","heading":"0.21 tables","text":"several useful (incredible even) packages making tables R. :knitr package ’s kable function (Create tables Latex, HTML, Markdown)xtable package, lots functions tables. xtable examples xtablekableExtra lots additional table functionalitytangram grammar tables approachpapaja apa-style tables","code":""},{"path":"coding-reference.html","id":"important-table-info","chapter":"Coding Reference","heading":"0.21.1 Important table info","text":"Two things note, tables can difficult, different output formats.Tables R can difficult. example, comfortable making tables Excel, R much difficult comparison. Excel, easy enter information cell, merge cells, add kind formatting want anywhere, just clicking around making changes. R, every detail table specified script. table packages make simple tables easy (hurray!), make complicated tables possible (also good), necessarilly easy.Tables R can difficult. example, comfortable making tables Excel, R much difficult comparison. Excel, easy enter information cell, merge cells, add kind formatting want anywhere, just clicking around making changes. R, every detail table specified script. table packages make simple tables easy (hurray!), make complicated tables possible (also good), necessarilly easy.R can output tables many formats including HTML web, Latex .pdf, formats (e.g., word, markdown). Sometimes (depending functions using) run issues outputting tables different formats. , take steps ensure outputting table format want.R can output tables many formats including HTML web, Latex .pdf, formats (e.g., word, markdown). Sometimes (depending functions using) run issues outputting tables different formats. , take steps ensure outputting table format want.","code":""},{"path":"coding-reference.html","id":"knitrkable","chapter":"Coding Reference","heading":"0.21.2 knitr::kable","text":"kable() function inside knitr package. use need load knitr library, can use knitr::kable(), tells R find kable inside knitr package haven’t loaded knitr using library(knitr).kable() great quickly rendering data frames nice tables without much hassle.","code":"\ndf <- data.frame(A=1,\n                 B=2,\n                 C=3,\n                 D=4)\nknitr::kable(df)"},{"path":"coding-reference.html","id":"xtable","chapter":"Coding Reference","heading":"0.21.3 xtable","text":"Look xtable examples document info. https://cran.r-project.org/web/packages/xtable/vignettes/xtableGallery.pdf","code":"\nlibrary(xtable) # load xtable\ndata(tli) # loads a sample data frame\n\n# conduct an ANOVA\n fm1 <- aov(tlimth ~ sex + ethnicty + grade + disadvg, data = tli)\n \n# print the table for HTML using xtable and kable together\nknitr::kable(xtable(fm1))\n\n# Note this will print a table in latex for .pdf\n# xtable(fm1)"},{"path":"coding-reference.html","id":"kableextra","chapter":"Coding Reference","heading":"0.21.4 kableExtra","text":"many great things kableExtra. One great thing kableExtra unique table options html formatting .pdf latex. example, interactive tables possible html, .pdf. Another great thing ability add rows headers top . example, data.frames R one row headers columns, kableExtra can add top.HTML info kableExtraLatex info (pdf) kableExtra","code":"\nlibrary(kableExtra)\ndf <- data.frame(A=1,\n                 B=2,\n                 C=3,\n                 D=4)\nkable(df) %>%\n  kable_styling(\"striped\") %>%\n  add_header_above(c(\"Group 1\" = 2, \"Group 2\" = 2))"},{"path":"coding-reference.html","id":"tangram","chapter":"Coding Reference","heading":"0.21.5 tangram","text":"package implements grammar tables. Similar concept behind ggplot2, implements grammar graphics figures.tangram githubtangram html examples","code":""},{"path":"coding-reference.html","id":"papaja","chapter":"Coding Reference","heading":"0.22 papaja","text":"papaja package rendering APA-style manuscripts pdf using R Markdown. learn papaja class. One feature papaja supports APA-style tables.papaja documentationpapaja APA tables","code":""},{"path":"coding-reference.html","id":"installing-papaja","chapter":"Coding Reference","heading":"0.22.1 Installing papaja","text":"papaja requires latex installation order compile .Rmd documents pdf. papaja documentation provides guidance installing latex papaja, see getting started section.can also watch video, goes steps :","code":"\n## install tinytex\nif(!\"tinytex\" %in% rownames(installed.packages())) install.packages(\"tinytex\")\n\n## initialize tinytex\ntinytex::install_tinytex()\n\n# Install devtools package if necessary\nif(!\"devtools\" %in% rownames(installed.packages())) install.packages(\"devtools\")\n\n# Install the stable development verions from GitHub\ndevtools::install_github(\"crsh/papaja\")"},{"path":"coding-reference.html","id":"vectorized-approaches","chapter":"Coding Reference","heading":"0.23 Vectorized approaches","text":"Loops common tool something many times. R can accomplish goal “something many times” without loops, using vectorized approach.","code":""},{"path":"coding-reference.html","id":"basic-examples","chapter":"Coding Reference","heading":"0.23.1 Basic examples","text":"Let’s take close look basic differences using loop, using R’s vectorized approachConsider problem adding single number numbers vector.adding two vectors together, add first two numbers together, second two numbers etc.comparing identity elements two vectors see ?","code":"\nnums <- c(1,2,3,4)\n\n# vectorized approach\n# R automatically adds 1 to all of the numbers\nnums+1\n#> [1] 2 3 4 5\n\n# loop approach\n# much longer to write out\nfor(i in 1:length(nums)){\n  nums[i] <- nums[i]+1\n}\nnums\n#> [1] 2 3 4 5\nA <- c(1,2,3,4)\nB <- c(1,2,3,4)\n\n# vectorized approach\nA+B\n#> [1] 2 4 6 8\n\n# loop approach\nthe_sum <-c()\nfor(i in 1:length(A)){\n  the_sum[i] <- A[i]+B[i]\n}\nthe_sum\n#> [1] 2 4 6 8\nA <- c(\"c\",\"e\",\"f\",\"g\")\nB <- c(\"d\",\"e\",\"f\",\"g\")\n\n#vectorized approach\nA==B\n#> [1] FALSE  TRUE  TRUE  TRUE\n\n# loop approach\ncompared <-c()\nfor(i in 1:length(A)){\n  if(A[i]==B[i]){\n    compared[i] <- TRUE\n  } else {\n    compared[i] <- FALSE\n  }\n}\ncompared\n#> [1] FALSE  TRUE  TRUE  TRUE"},{"path":"coding-reference.html","id":"replicate","chapter":"Coding Reference","heading":"0.23.2 Replicate","text":"replicate(n, expr) allows repeat function many times, return answer vectorThe next example shows write function something, use function inside replicate repeat function many times.example, write function run one-sample t-test random sample drawn normal distribution","code":"\n# returns 1 randomly sampled number from 1 to 10\nsample(1:10,1)\n#> [1] 1\n\n# let's repeat the above 10 times using replicate\nreplicate(10,sample(1:10,1))\n#>  [1]  5  1  9  1  7  4  2 10  2  8\nttest_result <- function(){\n  sample <- rnorm(10,0,1)\n  t_out <- t.test(sample, mu=0)\n  return(t_out$statistic)\n}\n\n# get 10 t-values from repeating the above 10 times\nreplicate(10, ttest_result() )\n#>          t          t          t          t          t          t          t \n#>  0.7462134  0.1265805  1.6177355  0.3190185 -0.3212202 -0.1425219  0.6180752 \n#>          t          t          t \n#> -0.2880227  0.2400779 -0.3862252"},{"path":"coding-reference.html","id":"apply-family","chapter":"Coding Reference","heading":"0.23.3 apply family","text":"apply family functions can used “apply” function across elements object. general overview can found hereSome apply functions include: apply(), lapply, sapply.","code":""},{"path":"coding-reference.html","id":"lapply-and-sapply","chapter":"Coding Reference","heading":"0.23.4 lapply and sapply","text":"part definition lapply help file:lapply returns list length X, element result applying FUN corresponding element X.Let’s see examples:Let’s apply function elements vector. keep things simple, function add 1 numberAn alternative syntax lapply sapply let’s define function want apply inside lapply sapply function.case, element vector some_numbers become x value function.","code":"\nsome_numbers <- c(1,2,3,4)\n\nadd_one <- function(x){\n  return(x+1)\n}\n\n# returns a list, containing the answers\nlapply(some_numbers, add_one)\n#> [[1]]\n#> [1] 2\n#> \n#> [[2]]\n#> [1] 3\n#> \n#> [[3]]\n#> [1] 4\n#> \n#> [[4]]\n#> [1] 5\n\n# unlists the list\nunlist(lapply(some_numbers,add_one))\n#> [1] 2 3 4 5\n\n# sapply does the unlisting for you\nsapply(some_numbers, add_one)\n#> [1] 2 3 4 5\nsome_numbers <- c(1,2,3,4)\n\nlapply(some_numbers, FUN = function(x){x+1})\n#> [[1]]\n#> [1] 2\n#> \n#> [[2]]\n#> [1] 3\n#> \n#> [[3]]\n#> [1] 4\n#> \n#> [[4]]\n#> [1] 5\nsapply(some_numbers, FUN = function(x){x+1})\n#> [1] 2 3 4 5"},{"path":"coding-reference.html","id":"apply","chapter":"Coding Reference","heading":"0.23.5 apply","text":"apply function can used 2-dimensional data, allows apply function across rows columns data.Let’s say 5x5 matrix random numbers. Let’s find sum rowThe sum columnLet’s say matrix storing 3 samples. sample 10 numbers. sample stored column, row represents observation.Let’s use apply conduct 10 one-sample t-tests, one column. example, can pass mu=0 parameter t.test function. However, return entire ouput t-test list.wanted return t-values, rather whole output?might try , doesn’t workSo, write custom function","code":"\nrandom_matrix <- matrix(sample(1:10,25, replace=TRUE),ncol=5)\n\n# applies the sum function to each row\n# 1 tells apply to go across rows\napply(random_matrix,1,sum)\n#> [1] 24 24 35 16 26\n# applies the sum function to each column\n# 2 tells apply to go across columns\napply(random_matrix, 2, sum)\n#> [1] 22 20 28 18 37\nsample_matrix <- matrix(rnorm(30,0,1),ncol=3)\napply(sample_matrix,2,t.test, mu=0)\n#> [[1]]\n#> \n#>  One Sample t-test\n#> \n#> data:  newX[, i]\n#> t = -0.15555, df = 9, p-value = 0.8798\n#> alternative hypothesis: true mean is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.6103617  0.5318253\n#> sample estimates:\n#>  mean of x \n#> -0.0392682 \n#> \n#> \n#> [[2]]\n#> \n#>  One Sample t-test\n#> \n#> data:  newX[, i]\n#> t = -0.66068, df = 9, p-value = 0.5254\n#> alternative hypothesis: true mean is not equal to 0\n#> 95 percent confidence interval:\n#>  -1.1479343  0.6289721\n#> sample estimates:\n#>  mean of x \n#> -0.2594811 \n#> \n#> \n#> [[3]]\n#> \n#>  One Sample t-test\n#> \n#> data:  newX[, i]\n#> t = -2.6149, df = 9, p-value = 0.02804\n#> alternative hypothesis: true mean is not equal to 0\n#> 95 percent confidence interval:\n#>  -1.10948184 -0.08024462\n#> sample estimates:\n#>  mean of x \n#> -0.5948632\napply(sample_matrix,2,t.test$statistic, mu=0)\n#> Error in t.test$statistic: object of type 'closure' is not subsettable\napply(sample_matrix, 2, \n      FUN = function(x){\n        t_out <- t.test(x,mu=0)\n        return(t_out$statistic)\n      })\n#> [1] -0.1555452 -0.6606843 -2.6148959"},{"path":"textbooks-and-other-resources.html","id":"textbooks-and-other-resources","chapter":"Textbooks and Other Resources","heading":"Textbooks and Other Resources","text":"(yet…maybe one day knows) complete statistics textbook statistics R. series weekly exercises used labs statistics courses psychology students. aimed initiating novice students learning programming environment statistics like R, also using R teaching tool aid conceptual understanding statistics.","code":""},{"path":"textbooks-and-other-resources.html","id":"statistics-textbooks-we-are-using","chapter":"Textbooks and Other Resources","heading":"0.24 Statistics textbooks we are using","text":"Students taking course Brooklyn College also taking separate series bi-weekly lectures, arrive lab discussions digested readings. beginning lab refer readings assigned students, come three different textbooks:Vokey & Allen (2018), pdf available onlineAbdi et al. (2009), portions may downloadable google scholar, otherwise try find printed copy somewhere.Crump et al. (2018), https://crumplab.github.io/statistics/, lab manual R https://crumplab.github.io/statisticsLab/","code":""},{"path":"textbooks-and-other-resources.html","id":"other-online-textbooks","chapter":"Textbooks and Other Resources","heading":"0.25 Other online textbooks","text":"increasing numbers excellent, free, online resources learning statistics R, :Danielle Navarro’s Learning Statistics R website learning R R Psychological ScienceRussell Poldracks’s Statistical Thinking 21st CenturyMartin Speekenbrink’s Statistics: data analysis modelling, companion R book R companion Statistics: data analysis modellingInto python instead? Check Todd Gureckis’ Lab Cognition PerceptionLooking stats videos, check Erin Buchanan’s STATISTICS DOOM! youtube: https://www.youtube.com/channel/UCMdihazndR0f9XBoSXWqnYg","code":""},{"path":"textbooks-and-other-resources.html","id":"a-longer-list","chapter":"Textbooks and Other Resources","heading":"0.26 A longeR list","text":"Hadley Wickham written several fantastic free booksv keep coming back time, R Data Science, ggplot 2: elegant graphics data analyis, Advanced R, R packages.R markdown knitr core libraries using R create sorts reproducible documents pdfs websites. excellent resources:\nhttps://bookdown.org/yihui/rmarkdown/\nhttps://bookdown.org/yihui/rmarkdown-cookbook/\nhttps://bookdown.org/yihui/rmarkdown/https://bookdown.org/yihui/rmarkdown-cookbook/Github got ? Jenny Bryan pick https://happygitwithr.comGoogling R questions can often turn example someone solving issue closely related one. example, can copy error messages google , ask “X R”.Stackoverflow great, Google often take someone already asked question, someone else answered, usually many people answered question many ways.Danielle Navarro recently made website introducing R, ’s great, check (also made using R markdown process): http://compcogscisydney.org/psyr/Check slightly older programming book also introduces R https://crumplab.github.io/programmingforpsych/, actually don’t , ’s old now worth .Another solid accessible resource psyc stats using R https://ademos.people.uic.edu/index.html.https://cran.r-project.org/doc/contrib/Short-refcard.pdf link takes reference card, shows big long list intrinsic r functions.really great really long list resources R! https://paulvanderlaken.com/2017/08/10/r-resources-cheatsheets-tutorials-books/’s bunch R markdown tricks right https://holtzy.github.io/Pimp--rmd/.","code":""},{"path":"r-basics.html","id":"r-basics","chapter":"1 R Basics","heading":"1 R Basics","text":"“8/27/2020 | Last Compiled: 2020-12-09”","code":""},{"path":"r-basics.html","id":"reading-and-walkthrough-video","chapter":"1 R Basics","heading":"1.1 Reading and walkthrough video","text":"Vokey & Allen (2018), Chapter 1, available online : http://people.uleth.ca/~vokey/pdf/thinking.pdf.","code":""},{"path":"r-basics.html","id":"overview","chapter":"1 R Basics","heading":"1.2 Overview","text":"labs course designed give students exposure free open-source statistical programming language R. assumption students may zero prior experience scripting, coding, computer programming. semester use R tool data-analysis, tool sharpen understanding statistical concepts.starting lab follow getting started instructions install R, R-studio, create Github.com account, download github Desktop; , make sure test github pipeline. Throughout semester posting assignments Github.com, submitting links repositories blackboard.","code":""},{"path":"r-basics.html","id":"problem-1-summing-1-to-100","chapter":"1 R Basics","heading":"1.3 Problem 1: Summing 1 to 100","text":"Vokey & Allen (2018) tell story teacher giving challenging students add numbers 1 100. supposed stump one students, young Gauss. Apparently, , Gauss quickly wrote sum 5050.Gauss didn’t R, , can solve problem quickly :Use R find sum sequence numbers 1 100:Using sum(), simple fast solve Gauss’s problem R. easily find sums changing 1 100There many details going behind scenes R allow sum() function work. One detail get R create sequence numbers, another take action like adding numbers sequence. Two major concepts variables storing information (like sequences numbers), functions take actions transform input (number sequence) desired output (sum number sequence).","code":"\nsum(1:100)\n#> [1] 5050\nsum(5:10)\n#> [1] 45\nsum(100:200)\n#> [1] 15150"},{"path":"r-basics.html","id":"r-basics-background","chapter":"1 R Basics","heading":"1.4 R Basics Background","text":"","code":""},{"path":"r-basics.html","id":"creating-sequences-of-numbers-in-r","chapter":"1 R Basics","heading":"1.4.1 Creating sequences of numbers in R","text":"multiple ways create number sequences R. sequence integers can generated x:y, x starting value, y ending value.","code":"\n1:5\n#> [1] 1 2 3 4 5\n1:10\n#>  [1]  1  2  3  4  5  6  7  8  9 10\n5:-5\n#>  [1]  5  4  3  2  1  0 -1 -2 -3 -4 -5"},{"path":"r-basics.html","id":"seq","chapter":"1 R Basics","heading":"1.4.2 seq()","text":"Sequences incremented constant value can created using seq() function. Look “help” R function typing ?name_of_function consoleR comes pre-packaged many functions like seq(), can write functions, download libraries functions people written extend base functionality R. look closely functions throughout semester.R function usually three components. 1) receive kind input, 2) “something”, 3) return kind output. R, use functions writing name function parentheses name(). function takes inputs, define inputs inside parentheses name(x=1). Functions can multiple inputs, separated commas.Let’s take look using seq() function generate sequences numbers.","code":"\n?seq\n#lines beginning with # are comments and not run\n\n#seq(from, to)\nseq(from = 1, to = 5)\n#> [1] 1 2 3 4 5\nseq(1, 5)\n#> [1] 1 2 3 4 5\n\n#seq(from, to, by= )\nseq(from = 1, to = 5, by = 2)\n#> [1] 1 3 5\nseq(1, 5, .5)\n#> [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\nseq(1, 10, 2)\n#> [1] 1 3 5 7 9\n\n#seq(from, to, length.out= )\nseq(from = 1, to = 2, length.out =5)\n#> [1] 1.00 1.25 1.50 1.75 2.00\n\nseq(5)\n#> [1] 1 2 3 4 5"},{"path":"r-basics.html","id":"problem-2-summing-any-constant-series","chapter":"1 R Basics","heading":"1.5 Problem 2: Summing any constant series","text":"Now seen sum() seq() functions, able use find sum constant series.example, find sum series 100 200, going five.also possible write analytic formula R, compare results, remember :\\(X_1 + X_2 + \\ldots + X_n = (\\frac{X_n-X_1}{c}+1)(\\frac{X_1+X_n}{2})\\)\\(X_1\\) starting value, \\(X_n\\) ending value \\(c\\) constant step value.example writing formula R. create variables names X1, Xn, step, assign (<-) value want. compute formula. give value previous example, sequence.","code":"\nsum( seq(100,200,5) )\n#> [1] 3150\nX1 <- 100\nXn <- 200\nstep <- 5\n\n(((Xn - X1)/step) + 1) * ((X1 + Xn)/2)\n#> [1] 3150\n\n( ( (Xn-X1)/step ) + 1 ) * ( (X1+Xn)/2 )\n#> [1] 3150"},{"path":"r-basics.html","id":"vectors-1","chapter":"1 R Basics","heading":"1.6 Vectors","text":"","code":""},{"path":"r-basics.html","id":"the-gaussian-trick","chapter":"1 R Basics","heading":"1.6.1 The Gaussian trick","text":"Remember Gauss added numbers 1 100 imagining two number lines:noted sum columns always added 101 (e.g., 1+100 = 101, 2+99 = 101, etc.). possible demonstrate R can directly add number lines:time created sequence numbers (e.g., 1 100) creating object called numeric vector R. Vectors can store multiple numbers.Vectors kind variable R. Vectors can names, can saved, can manipulated. Let’s take quick look vectors:name new vector. <- called assignment operator. 1:5 creates vector length 5, containing sequence numbers 1 5. plain language, “assign” object right (1:5), “name” written left side <-. words, put numbers 1 5 something called .create variable like , name appear global environment (top right environment tab). variable created first time (executing code console), becomes registered saved computer’s memory current R session.want double-check variable exists memory, enter name console, press enter:can clear (remove) variable using rm(). , can clear entire global environment using Session > Clear Workspace... RStudio menu.can also check class variable R using class() function. Let’s create two vectors check classes. vector contains integer class, b vector contains numeric class decimal values.","code":"\n1:100\n#>   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n#>  [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n#>  [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n#>  [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n#>  [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n#>  [91]  91  92  93  94  95  96  97  98  99 100\n100:1\n#>   [1] 100  99  98  97  96  95  94  93  92  91  90  89  88  87  86  85  84  83\n#>  [19]  82  81  80  79  78  77  76  75  74  73  72  71  70  69  68  67  66  65\n#>  [37]  64  63  62  61  60  59  58  57  56  55  54  53  52  51  50  49  48  47\n#>  [55]  46  45  44  43  42  41  40  39  38  37  36  35  34  33  32  31  30  29\n#>  [73]  28  27  26  25  24  23  22  21  20  19  18  17  16  15  14  13  12  11\n#>  [91]  10   9   8   7   6   5   4   3   2   1\n1:100 + 100:1\n#>   [1] 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101\n#>  [19] 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101\n#>  [37] 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101\n#>  [55] 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101\n#>  [73] 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101 101\n#>  [91] 101 101 101 101 101 101 101 101 101 101\n#creates a variable a\na <- 1:5\na\n#> [1] 1 2 3 4 5\nrm(a)\na <- 1:10\nclass(a)\n#> [1] \"integer\"\n\nb <- seq(1,2,.25)\nclass(b)\n#> [1] \"numeric\""},{"path":"r-basics.html","id":"c","chapter":"1 R Basics","heading":"1.6.2 c()","text":"also possible create vectors contain characters, rather numbers. illustrate example character vector, introduce one basic R function c(), short “combine”.Vectors like trains, slots (train cars) can contain things, like passengers, oil coal. Trains can number train cars, just like vector can length (number slots).Importantly, train cars need connected together form whole train. Similarly, R, make vector need concatenate connect individual slots vector together. c() function . combines individual units together form vector.use c(), insert individual items separated commas parentheses. insert characters, wrap character (string characters) quotations.elements commas like individual train cars, c() function connects elements together single entity comprised multiple units, like train, called vector.","code":"\n?c\nletters <- c(\"a\",\"b\",\"c\")\nnumbers <- c(1,2,3)\nnumbers_as_chars <- c(\"1\",\"2\",\"3\")\nwords <- c(\"this\",\"is\",\"a\",\"vector\",\"of\",\"strings\")"},{"path":"r-basics.html","id":"length","chapter":"1 R Basics","heading":"1.6.3 length()","text":"Just like train specific number cars, vector specific number slots. called length vector. R length() function reports length vector.","code":"\nlength(letters)\n#> [1] 3\nlength(words)\n#> [1] 6"},{"path":"r-basics.html","id":"more-on-combining","chapter":"1 R Basics","heading":"1.6.4 More on combining","text":"c() function flexible can combine sorts elements, including vectors variables.Remember vectors different classes depending kind elements inside vector. important, R requires elements vector class.possible combine vectors start different classes, R may give error, convert one class another. go back train car analogy, R doesn’t like trains different kinds cars…wants whole train passenger cars, whole train oil tankers.","code":"\nsome_numbers <- c(1, 2, 3, 1:5)\n\nsome_characters <- c(letters, words)\nclass(c(1,2,3))\n#> [1] \"numeric\"\nclass(c(\"A\",\"B\",\"C\"))\n#> [1] \"character\"\nclass(c(TRUE,FALSE,TRUE))\n#> [1] \"logical\"\n# the numbers are converted to characters\nc(1,2,3,\"a\",\"b\",\"c\")\n#> [1] \"1\" \"2\" \"3\" \"a\" \"b\" \"c\""},{"path":"r-basics.html","id":"indexing-a-vector","chapter":"1 R Basics","heading":"1.6.5 Indexing a vector","text":"Vector indexing iallows elements inspected changed. like train, inspect contents cars 3 5, unload car 7 put something else .Square bracket [] notation indexes vector, variable_name[x]; , x another vector specifying indexed slots.following examples use [] index specific elements vector . outcome elements specified inside square brackets printed console.also possible assign new values specific elements vector:","code":"\na <- c(1,6,3,2,8,9) # make a vector\na[1] # first element\n#> [1] 1\na[2] # second element\n#> [1] 6\na[1:3] # 1st to 3rd elements\n#> [1] 1 6 3\na[c(1,5)] # elements 1 and 5\n#> [1] 1 8\n# assign 100 to the first slot of a\na[1] <- 100\na\n#> [1] 100   6   3   2   8   9\n\n# assign the value 1 to slots 5 to 6 of a\na[5:6] <- 1\na\n#> [1] 100   6   3   2   1   1"},{"path":"r-basics.html","id":"growing-a-vector","chapter":"1 R Basics","heading":"1.6.6 Growing a vector","text":"upcoming labs use vectors store information. Sometimes know advance many slots need vector, times might know, instead decide build vector one slot time.begin empty (NULL) vector. use c() command, don’t combine anything together. like starting train cars .can add slot vector combining new element existing variable. combine 1, assign result back , replacing ’s original NULL value.keep , keep adding 1s, end .Consider alternative method growing vector:","code":"\na <- c()\na\n#> NULL\na <- c(a,1)\na\n#> [1] 1\na <- c(a,1)\na\n#> [1] 1 1\na <- c(a,1) # c(1,1,1)\na\n#> [1] 1 1 1\na <- c(a,1)\na\n#> [1] 1 1 1 1\na <- c(a,1)\na\n#> [1] 1 1 1 1 1\na <- c()\na\n#> NULL\n\na[1] <- 1\na\n#> [1] 1\n\na[2] <- 1\na\n#> [1] 1 1\n\na[3] <- 1\na\n#> [1] 1 1 1\n\na[10] <- 1\na\n#>  [1]  1  1  1 NA NA NA NA NA NA  1"},{"path":"r-basics.html","id":"problem-3-writing-a-sum-function-in-r","chapter":"1 R Basics","heading":"1.7 Problem 3: Writing a sum function in R","text":"already used R solve problems Chapter 1 Vokey & Allen (2018). can create sequences numbers, can create custom vectors numbers, can use sum() function find sum. However, haven’t discussed sum() function actually works. R know find sum?example writing sum function R. example involves understanding loops writing custom functions, explained next sections.","code":"\nmy_sum <- function(x) {\n  sum <- 0\n  for(i in x) sum <- sum + i\n  return(sum)\n}\n\nmy_sum(1:100)\n#> [1] 5050"},{"path":"r-basics.html","id":"algorithms","chapter":"1 R Basics","heading":"1.8 Algorithms","text":"understand functions like sum() work R, need understand general concept algorithm. ’ll define algorithm recipe, series steps/actions result particular outcome. scripting language like R, possible define algorithms infallible. , given input, always apply steps arrive answer demanded algorithm.sum series numbers head, say numbers 1 5, probably applying simple algorithm describe like :Take first number add second (1+2 = 3)Take sum (3) add next number (3+3 = 6)Repeat step 2 numbers series6+4 = 1010+5 = 15report final sum (15)Consider look R. one example producing algorithm R. Everytime run script, always end sum 15, answer demanded series steps wrote .","code":"\nsum(1:5)\n#> [1] 15\na <- 1:5\na\n#> [1] 1 2 3 4 5\n\nthe_sum <- a[1]+a[2]\nthe_sum\n#> [1] 3\nthe_sum <- the_sum + a[3]\nthe_sum\n#> [1] 6\nthe_sum <- the_sum + a[4]\nthe_sum\n#> [1] 10\nthe_sum <- the_sum + a[5]\nthe_sum\n#> [1] 15"},{"path":"r-basics.html","id":"loops-1","chapter":"1 R Basics","heading":"1.9 Loops","text":"example shows algorithm written hand R. tiresome write sum sequence many numbers. Fortunately, ways automate repetitive processes R. common method repeating commands R use loop.Check R help Control Flow ?Control.(){}\n(loop control){something iteration}basic syntax loops follows:Loop control defined parentheses. name iterator placed left (can assigned name want, need declared advance). execution loop, iterator takes values inside vector placed right side . Specifically, following happening.Loop steps:\n1. iterator <- vector[1]\n2. iterator <- vector[2]\n3. iterator <- vector[3]\n4. etc.loop automatically stop reaches last item vector. loop can stopped using break command.","code":"\nfor(iterator in vector){\n  #do something\n}\n# Make a loop do something 5 times\n# i is the iterator\n# 1:5 creates a vector with 5 numbers in it, 1, 2, 3, 4, 5\n# the loop will run 5 times, because there are five things to assign to i\nfor(i in 1:5){\n  print(\"hello\")\n}\n#> [1] \"hello\"\n#> [1] \"hello\"\n#> [1] \"hello\"\n#> [1] \"hello\"\n#> [1] \"hello\"\n# show the value of i each step of the loop\nfor(i in 1:5){\n  print(i)\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n# define the vector to loop over in advance\nmy_sequence <- 1:5\nfor(i in my_sequence){\n  print(i)\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n# Reminder that i becomes the next value in the vector\n# your vector can have any order \nmy_sequence <- c(1,5,2,3,4)\nfor(i in my_sequence){\n  print(i)\n}\n#> [1] 1\n#> [1] 5\n#> [1] 2\n#> [1] 3\n#> [1] 4\n# index vector does not need to be numbers\nmy_things <- c(\"A\",\"B\",\"C\",\"D\")\nfor(i in my_things){\n  print(i)\n}\n#> [1] \"A\"\n#> [1] \"B\"\n#> [1] \"C\"\n#> [1] \"D\""},{"path":"r-basics.html","id":"breaking-a-loop-1","chapter":"1 R Basics","heading":"1.9.1 Breaking a loop","text":"break stops loop. Used logical statements define conditions necessary cause break.","code":"\nfor(i in 1:10){\n  if(i <= 5){\n    print(i)\n  } else {\n    break\n  }\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5"},{"path":"r-basics.html","id":"while-loops-1","chapter":"1 R Basics","heading":"1.9.2 While loops","text":"loops run logical condition met. iterator, just logic statement needs met.one prints less 6. soon becomes “less 6”, loop stops. Critically, inside loop, value increases iteration.","code":"\ni <- 1 # create an variable\nwhile (i < 6) {\n  print(i)\n  i = i+1 #add one each step of the loop\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5"},{"path":"r-basics.html","id":"repeat-loops-1","chapter":"1 R Basics","heading":"1.9.3 Repeat loops","text":"Similar , let’s things condition met.","code":"\ni<-0\nrepeat{\n  i<-i+1\n  print(i)\n  if(i==5){\n    break\n  }\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5"},{"path":"r-basics.html","id":"examples-1","chapter":"1 R Basics","heading":"1.9.4 Examples","text":"Braces needed one lineUsing value iterator assign values systematically another variable.Using loop add numbers vector.example shows use loop compute sum numbers vector . example using loop algorithm. end checked custom script sum() function, see arrived answer.final task lab take look R functions, learn write basic functions like sum().","code":"\nfor(i in 1:5) print(i)\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n# put 1 into the first five positions of x\nx <- c() # create empty vector\nfor(i in 1:5){\n  x[i] <- 1  # assign 1 to the ith slot in x\n}\nx\n#> [1] 1 1 1 1 1\n\n\n# put the numbers 1-5 in the first 5 positions of x\nx <-c()\nfor(i in 1:5){\n  x[i] <- i\n}\nx\n#> [1] 1 2 3 4 5\na <- c(10,20,30,40,50) #some numbers\n\nthe_sum <- 0 # initialize a variable that will keep track of the sum\n\nfor (i in a) {\n the_sum <- the_sum + i  \n}\n\nthe_sum\n#> [1] 150\nsum(a) #check against the sum function\n#> [1] 150"},{"path":"r-basics.html","id":"functions-1","chapter":"1 R Basics","heading":"1.10 Functions","text":"Functions re-useable algorithms. example, rather re-writing code necessary compute sum everytime want find sum, instead store necessary code inside named variable called sum(), “call” function writing name providing inputs.fairly straightforward write custom functions R, learning write functions excellent method improve understanding R fundamentals.","code":""},{"path":"r-basics.html","id":"function-syntax-1","chapter":"1 R Basics","heading":"1.10.1 function syntax","text":"general syntax writing functions:","code":"\nfunction_name <- function(input1,input2){\n  #code here\n  return(something)\n}"},{"path":"r-basics.html","id":"example-functions-1","chapter":"1 R Basics","heading":"1.10.2 Example functions","text":"function input (). Whenever run function, simply return whatever placed inside return statement.function simply takes input, returns input without modifying .function takes input, creates internal variable called temp assigns input+1. contents temp returned. Note , checking input, return erro input character (can’t add one character R)function adds input checking. add one input numeric type. Otherwise, use stop() return error message consoleA function three inputs","code":"\n# define the function\nprint_hello_world <- function(){\n  return(print(\"hello world\"))\n}\n\n# use the function\nprint_hello_world()\n#> [1] \"hello world\"\nreturn_input <- function(input){\n  return(input)\n}\n\n# the variable input is assigned a 1\n# then we return(input), which will result in a 1\n# because the function internally assigns 1 to the input\nreturn_input(1)\n#> [1] 1\na <- \"something\"\nreturn_input(a)\n#> [1] \"something\"\nadd_one <- function(input){\n  temp <- input+1\n  return(temp)\n}\nadd_one(1)\n#> [1] 2\nadd_one(\"a\") #this will cause an error\n#> Error in input + 1: non-numeric argument to binary operator\nadd_one <- function(input){\n  if(class(input) == \"numeric\"){\n    temp <- input+1\n    return(temp)\n  } else {\n    return(stop(\"input must be numeric\"))\n  }\n}\nadd_one(1)\n#> [1] 2\nadd_one(\"a\")\n#> Error in add_one(\"a\"): input must be numeric\nadd_multiply <- function(input, x_plus, x_times){\n  temp <- (input+x_plus)*x_times\n  return(temp)\n}\n\n# input is 1\n# x_plus <- 2\n# x_times <- 3\n# will return (1+2)*3 = 9\nadd_multiply(1,2,3)\n#> [1] 9"},{"path":"r-basics.html","id":"lab-1-generalization-assignment","chapter":"1 R Basics","heading":"1.11 Lab 1 Generalization Assignment","text":"Follow instructions complete assignment lab 1 hand due date blackboard. first lab taken extra step pretending student course, completed first lab . next video shows complete lab student. important try solve problems , please use video resource help get stuck.","code":""},{"path":"r-basics.html","id":"instructions","chapter":"1 R Basics","heading":"1.11.1 Instructions","text":"general, labs present discussion problems issues example code like , students tasked completing generalization assignments, showing can work concepts tools independently.assignment instructions following:Make new R project (initialized git repository) called \"StatsLab1’.Create new R Markdown document called “Lab1.Rmd”Upload StatsLab1 R project Github.com using Github DesktopUse Lab1.Rmd show work attempting solve following generalization problems. Commit work regularly appears Github repository.Submit github repository link Lab 1 blackboard.six problems solve, worth 1 point.Refer getting started videos examples creating new R project uploading Github. problems steps resolved first class, please email , create issue course github page https://github.com/CrumpLab/psyc7709Lab/issues","code":""},{"path":"r-basics.html","id":"problems","chapter":"1 R Basics","heading":"1.11.2 Problems","text":"Compute sum sequence 100 1000, going constant value 100 (100,200,300,400,500,600,700,800,900,1000).Compute sum numbers (1,3,2,4,3,5,4,3,4,5,6,5,6,7,6,5,6,5,4,3,4,5)Write custom sequence generator function using loop generates sequence starting integer value ending integer value steps 1. Demonstrate can produce sequence 1 10.Write custom function implement following general equation find sum constant series:\\(X_1 + X_2 + \\ldots + X_n = (\\frac{X_n-X_1}{c}+1)(\\frac{X_1+X_n}{2})\\)Demonstrate function correctly produces sum series :Write custom function generates constant series start end values, constant, finds sum. function output sequence sum. problem, feel free use existing seq() sum() functions custom function. Demonstrate function correctly prints sequence (10 100 steps 10), sum.Use sum() length() functions calculate mean (average) numbers x = c(1,2,3,4,5).","code":"\nseq(10,100,10)\n#>  [1]  10  20  30  40  50  60  70  80  90 100"},{"path":"descriptives.html","id":"descriptives","chapter":"2 Descriptives","heading":"2 Descriptives","text":"“9/2/2020 | Last Compiled: 2020-12-09”","code":""},{"path":"descriptives.html","id":"reading","chapter":"2 Descriptives","heading":"2.1 Reading","text":"(Vokey & Allen, 2018), Chapters 2 & 3 descriptive statistics, including measures central tendency (e.g., means) dispersion (variances); Crump et al. (2018) chapter 2 describing data; /Abdi et al. (2009), appendix .","code":""},{"path":"descriptives.html","id":"overview-1","chapter":"2 Descriptives","heading":"2.2 Overview","text":"General note, trying find consistent way structure lab content. lab adopt structure splits lab conceptual practical parts. conceptual sections use R demonstrate reinforce concepts statistics. practical sections use R data analysis.Conceptual Section : Using R demonstrate properties meanPractical Sections II:\nimporting data\ncalculating means descriptive statistics\ngraphing means ggplot2\nimporting datacalculating means descriptive statisticsgraphing means ggplot2","code":""},{"path":"descriptives.html","id":"means-demo","chapter":"2 Descriptives","heading":"2.3 Means Demo","text":"quick piece example code showing steps calculate graph means data set R using tidyverse. need install tidyverse libraries system can run code :","code":"\ninstall.packages(\"tidyverse\")\n# load libraries\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# chickwts is a built in data set\n# with chick weights by feed\n\n# calculate means for each feed type\nmeans_df <- chickwts %>%\n  group_by(feed) %>%\n  summarize(means = mean(weight))\n\n# print table of means\nknitr::kable(means_df)\n\n# plot the means\nggplot(means_df, aes(x=feed, y=means)) +\n  geom_bar(stat=\"identity\")"},{"path":"descriptives.html","id":"base-r-descriptive-statistics-functions","chapter":"2 Descriptives","heading":"2.3.1 Base R descriptive statistics functions","text":"Base R comes functions many common descriptive statistics. general, functions take vector number input, return statistic output. examples computing statistics sequence integers 1 10.time, base R existing functions every descriptive statistic, custom descriptive statistics might want make . example, mode function. find another package mode function, write .","code":"\na <- 1:10\n\nmean(a) # arithmetic mean\n#> [1] 5.5\nmedian(a) # median\n#> [1] 5.5\nsd(a) # sample standard deviation (n-1)\n#> [1] 3.02765\nvar(a) # sample variance (n-1)\n#> [1] 9.166667"},{"path":"descriptives.html","id":"concepts-i-demonstrating-properties-of-the-arithmetic-mean-in-r","chapter":"2 Descriptives","heading":"2.4 Concepts I: Demonstrating properties of the arithmetic mean in R","text":"section :use built mean() functionwrite mean functionconduct simulation R demonstrate mean number causes sum deviations mean equal zero.can use mean() function calculate arithmetic means R. examples show calculating means different vectors inputted mean function.order calculate means need set numbers start . research context, sets numbers data points research project. , learn throughout course input real data, manipulate , calculate descriptive inferential statistics. However, section, use R create sets numbers, rather input data.","code":"\nmean(1:10)\n#> [1] 5.5\nmean(c(1,2,3))\n#> [1] 2\nmean(chickwts$weight)\n#> [1] 261.3099"},{"path":"descriptives.html","id":"arithmetic-mean","chapter":"2 Descriptives","heading":"2.4.1 Arithmetic Mean","text":"mean sum numbers, divided number numbers:\\(\\bar{X} = \\frac{\\sum_i^n{Xi}}{n}\\)wanted break steps R compute mean sequence 1 10, look like :","code":"\na <- 1:10 # create a vector\nsum_a <- sum(a) # store the sum\nlength_a <- length(a) # store the length (n)\nmean_a <- sum(a)/length(a) # store the sum/n\nmean_a # report the mean\n#> [1] 5.5"},{"path":"descriptives.html","id":"writing-a-custom-mean-function","chapter":"2 Descriptives","heading":"2.4.2 Writing a custom mean function","text":"write custom version mean function? examples:example “long” writes step computing mean line. Sometimes desirable make steps function clear easy follow. also possible sometimes desirable rewrite function accomplishes steps short number lines code. show example systematically rewriting function make take fewer lines code. see return() statement necessary, {} necessary function can written one line.","code":"\n# A long-form mean function that shows each step\nmy_mean <- function(x) {\n  sum_x    <- sum(x) # store the sum\n  length_x <- length(x) # store the length (n)\n  mean_x   <- sum_x/length_x # divide and store mean\n  return(mean_x) # output the mean\n}\n\nmy_mean(1:10)\n#> [1] 5.5\n# return() is not necessary if the function ends with a\n# variable name being printed\nmy_mean <- function(x) {\n  sum_x    <- sum(x) # store the sum\n  length_x <- length(x) # store the length (n)\n  mean_x   <- sum_x/length_x # compute and store mean\n  mean_x # output the mean\n}\n\nmy_mean(1:10)\n#> [1] 5.5\n\n# end with the mean computation\nmy_mean <- function(x) {\n  sum_x <- sum(x) # store the sum\n  length_x <- length(x) # store the length (n)\n  sum_x/length_x # compute and output the mean\n}\n\nmy_mean(1:10)\n#> [1] 5.5\n\n# no intermediate saving of sum or length\nmy_mean <- function(x) {\n  sum(x)/length(x) # compute and output the mean\n}\n\nmy_mean(1:10)\n#> [1] 5.5\n\n# one-liner\nmy_mean <- function(x) sum(x)/length(x)\n\nmy_mean(1:10)\n#> [1] 5.5"},{"path":"descriptives.html","id":"demonstrate-that-the-mean-is-the-point-from-which-the-sum-of-the-deviations-is-0.","chapter":"2 Descriptives","heading":"2.4.3 Demonstrate that the mean is the point from which the sum of the deviations is 0.","text":"learned mean set numbers point sum deviations equal 0. problem use R demonstrate property mean. can ?Let’s break steps. need numbers:need able compute sum deviations. wish compute differences one number (going mean), numbers set. deviations. want add arrive sum deviations.can find deviations numbers scores, number choice? Let’s pick number 5. turns can simply subtract 5 scores. produce vector differences deviationsThen, can find sum:Notice sum deviations (numbers scores 5) equal 0. , Clearly, mean numbers must 5. mean value cause deviations sum 0.","code":"\nscores <- c(1,64,5,4,3,4,5,6,7,8,3)\nscores-5\n#>  [1] -4 59  0 -1 -2 -1  0  1  2  3 -2\nsum(scores-5)\n#> [1] 55"},{"path":"descriptives.html","id":"simulations-to-approximate-the-mean","chapter":"2 Descriptives","heading":"2.4.4 Simulations to approximate the mean","text":"quickly show mean scores causes deviations sum 0. example, mean 10, sum deviations scores mean 0.Instead, let’s use R approximate value mean trying different values, rather computing mean first. example, previously tried 5, sum deviations 0. tried bunch numbers, say lowest number (1) highest number (64)? time compute deviations, sum deviations. record outcome test. look results see numbers comes closest creating sum deviations equals 0. require 64 individual tests, much hand. Fortunately, can use R accomplish goals quickly.Basically, process want …don’t want write 64 lines code either…want repeatedly apply similar computation R, remember can use loop. test integers smallest value largest value. , first create sequence numbers called numbers_to_test. , use loop compute sum deviations scores test numbers.just computed first simulation produced 64 sums deviations, displayed . question approximate mean, finding value produces sum deviations closest 0. final step evaluate results simulation answer question.Let’s discuss three ways get answer. First, look sums see 10th value 0, means number 10 produced sum deviations closest 0 (equaling 0 10 mean).","code":"\nscores # the scores\n#>  [1]  1 64  5  4  3  4  5  6  7  8  3\n\nmean(scores) # the mean\n#> [1] 10\n\nscores-mean(scores) #the vector of deviations from the mean\n#>  [1] -9 54 -5 -6 -7 -6 -5 -4 -3 -2 -7\n\nsum(scores-mean(scores)) # the sum\n#> [1] 0\nsum(scores-1)\n#> [1] 99\nsum(scores-2)\n#> [1] 88\nsum(scores-3)\n#> [1] 77\nsum(scores-4)\n#> [1] 66\nsum(scores-5)\n#> [1] 55\nsum(scores-6)\n#> [1] 44\n## and so on to 64\nmin(scores) \n#> [1] 1\nmax(scores)\n#> [1] 64\nnumbers_to_test <- min(scores):max(scores)\n\nsum_deviations <-c() # create an empty vector to store sums\nfor(i in numbers_to_test) {\n  sum_deviations[i] <- sum(scores-i)\n}\n\nsum_deviations\n#>  [1]   99   88   77   66   55   44   33   22   11    0  -11  -22  -33  -44  -55\n#> [16]  -66  -77  -88  -99 -110 -121 -132 -143 -154 -165 -176 -187 -198 -209 -220\n#> [31] -231 -242 -253 -264 -275 -286 -297 -308 -319 -330 -341 -352 -363 -374 -385\n#> [46] -396 -407 -418 -429 -440 -451 -462 -473 -484 -495 -506 -517 -528 -539 -550\n#> [61] -561 -572 -583 -594"},{"path":"descriptives.html","id":"plotting-the-results","chapter":"2 Descriptives","heading":"2.4.5 Plotting the results","text":"Second, visualize sum deviations. quickly plot() function.looking value x-axis causes sum deviations y-axis closest 0. One way help locate value look absolute values. Absolute values remove negative (-) sign numbers, leaving everything positive. can convert absolute values R using abs()Now, easy see 10 produces sum deviations closest 0 (case produces value 0, 10 also mean).","code":"\nplot(sum_deviations)\nplot(abs(sum_deviations))"},{"path":"descriptives.html","id":"locating-the-result-using-which","chapter":"2 Descriptives","heading":"2.4.6 Locating the result using which()","text":"Finally, use R functions help us compute answer. example, use () function. function can used determine indices position “logically” obtained values vector. long way saying want R tell us position vector contains 0","code":"\n#find the positions in vector that equal 0\nwhich(sum_deviations == 0)\n#> [1] 10\n\n#show the value in position 10\nsum_deviations[10]\n#> [1] 0\n\n#all in one\nsum_deviations[ which(sum_deviations == 0) ]\n#> [1] 0"},{"path":"descriptives.html","id":"minor-details","chapter":"2 Descriptives","heading":"2.4.7 Minor details","text":"approach worked pretty well. simulation process, found 10 produced sum deviations equaled 0. None numbers produced sum deviations equaled 0. However, example code won’t work well sets numbers.example, used set number 1 20, mean 10.5, find none sums deviations ever get 0 (’s testing integers 1 20). , () function never find number exactly equal 0., need modify comparison () function return “approximate” numbers give sums deviations closest zero.","code":"\n\nscores <- 1:20\nnumbers_to_test <- min(scores):max(scores)\n\nsum_deviations <-c() # create an empty vector to store sums\nfor(i in numbers_to_test) {\n  sum_deviations[i] <- sum(scores-i)\n}\n\nsum_deviations\n#>  [1]  190  170  150  130  110   90   70   50   30   10  -10  -30  -50  -70  -90\n#> [16] -110 -130 -150 -170 -190\nwhich(sum_deviations == 0)\n#> integer(0)\nwhich(abs(sum_deviations) == min(abs(sum_deviations)))\n#> [1] 10 11"},{"path":"descriptives.html","id":"advanced-example-writing-a-function-for-our-demonstration","chapter":"2 Descriptives","heading":"2.4.8 Advanced Example: Writing a function for our demonstration","text":"example show simulation written function. function used approximate mean set scores, test values.","code":"\napproximate_mean <- function(scores,test_sequence){\n  sum_deviations <- c()\n  for(i in 1:length(test_sequence)){\n    sum_deviations[i] <- sum(scores-test_sequence[i])\n  }\n  locate_index <- which(abs(sum_deviations) == min(abs(sum_deviations)))\n  test_sequence[locate_index]\n}\n\na <- c(1,4,3,2,4,3,5,4,6,5,7,6,8,7,9,8,7,6,7,6,5)\nb <- seq(0,10,.1)\napproximate_mean(a,b)\n#> [1] 5.4\n\n#actual mean\nmean(a)\n#> [1] 5.380952"},{"path":"descriptives.html","id":"practical-i-inputting-real-data-and-calculating-descriptive-statistics-with-tidyverse","chapter":"2 Descriptives","heading":"2.5 Practical I: Inputting real data and calculating descriptive statistics with tidyverse","text":"practical examples gloss many important details cover throughout semester, example code enough get started. following tidyverse approach, minimally involves\n1. Importing data data.frame similar (tibble, data.table)\n2. “Wrangling” data desired format analysis\n3. Applying calculations data","code":""},{"path":"descriptives.html","id":"importing-data","chapter":"2 Descriptives","heading":"2.5.1 Importing Data","text":"First, need “real data” import. Download zip file. contains folder open_data, several data files taken published psychology papers (whose authors made data publicly available).order follow along example, unzip file, copy move open_data folder R project folder. open_data folder R project folder .Rmd document using lab.use gapminder data set, includes measures life expectancy, population, gdp per capita, function year, country, continent. First, load gapminder.csv file (csv stands comma separated value) using read.table() function.many ways accomplish goal importing data R. discuss options throughout course.","code":"\ngapminder_data <- read.table(\"open_data/gapminder.csv\", \n                             sep = \",\",\n                             header = TRUE )"},{"path":"descriptives.html","id":"calculating-means","chapter":"2 Descriptives","heading":"2.5.2 Calculating means","text":"mean measures?","code":"\nmean(gapminder_data$lifeExp)\n#> [1] 59.47444\nmean(gapminder_data$pop)\n#> [1] 29601212\nmean(gapminder_data$gdpPercap)\n#> [1] 7215.327"},{"path":"descriptives.html","id":"dplyr-group_by-then-summarize","chapter":"2 Descriptives","heading":"2.5.3 dplyr (group_by then summarize)","text":"can calculate means separately function factors year, country, continent?use dplyr library (part tidyverse), three things:group data levels factor (case, separate data different continents, using continent variable)summarize data using mean functionoutput table resultsChange name variable inside group_by() change factor want evaluate (e.g., enter year, country). can include multiple factors:Note, group_means now contains large data frame, used head() function printing table, prints first five rows table, useful previewing large tables.","code":"\nlibrary(dplyr)\n\ngroup_means <- gapminder_data %>%\n                group_by(continent) %>%\n                summarize(mean_lifeExp = mean(lifeExp))\n\nknitr::kable(group_means)\ngroup_means <- gapminder_data %>%\n                group_by(continent,country) %>%\n                summarize(mean_lifeExp = mean(lifeExp))\n\nknitr::kable(head(group_means))"},{"path":"descriptives.html","id":"more-dplyr-examples","chapter":"2 Descriptives","heading":"2.5.4 More dplyr examples","text":"possible add multiple functions inside summarize. calculate mean, median, standard deviation, variance Life Expectancy function continent.Note, can even write custom functions use inside summarize.","code":"\ngroup_means <- gapminder_data %>%\n                group_by(continent) %>%\n                summarize(mean_lifeExp = mean(lifeExp),\n                          median_lifeExp = median(lifeExp),\n                          sd_lifeExp = sd(lifeExp),\n                          var_lifeExp = var(lifeExp))"},{"path":"descriptives.html","id":"practical-ii-plotting-the-means-with-ggplot2","chapter":"2 Descriptives","heading":"2.6 Practical II: Plotting the means with ggplot2","text":"ggplot2 powerful library plotting graphing R. many details using ggplot2 learn throughout semester. Today, create bar plots line graphs displaying means error bars.","code":""},{"path":"descriptives.html","id":"bar-graph-1","chapter":"2 Descriptives","heading":"2.6.1 Bar graph","text":"options modifying plot:","code":"\ngroup_means <- gapminder_data %>%\n                group_by(continent) %>%\n                summarize(mean_lifeExp = mean(lifeExp))\n\nggplot(group_means, aes(x = continent, y = mean_lifeExp))+\n  geom_bar(stat=\"identity\")\nggplot(group_means, aes(x = continent, y = mean_lifeExp))+\n  geom_bar(stat=\"identity\")+\n  ylab(\"Mean Life Expectancy\")+\n  xlab(\"Continent\")+\n  theme_classic()+\n  ggtitle(\"Mean Life Expectancy by Continent\")"},{"path":"descriptives.html","id":"line-graph-1","chapter":"2 Descriptives","heading":"2.6.2 Line graph","text":"\nNote get message adjusting group aesthestic, even though asked ggplot draw lines connecting dots, get line graph. good example unexpected behavior often requires quick google. copied message google found setting group=1 produced lines expecting:","code":"\nggplot(group_means, aes(x = continent, y = mean_lifeExp))+\n  geom_point()+\n  geom_line()\n#> geom_path: Each group consists of only one observation. Do you need to adjust\n#> the group aesthetic?\nggplot(group_means, aes(x = continent, \n                        y = mean_lifeExp,\n                        group = 1))+\n  geom_point()+\n  geom_line()"},{"path":"descriptives.html","id":"error-bars","chapter":"2 Descriptives","heading":"2.6.3 Error bars","text":"common present means bar graphs line graphs along error bars indicate variability around mean. ggplot need calculate measures variability condition, use values error bars. example add single standard deviation means error bars.","code":"\ngroup_means <- gapminder_data %>%\n                group_by(continent) %>%\n                summarize(mean_lifeExp = mean(lifeExp),\n                          sd_lifeExp = sd(lifeExp))\n\nggplot(group_means, aes(x = continent, y = mean_lifeExp))+\n  geom_bar(stat=\"identity\") +\n  geom_errorbar(aes(ymin = mean_lifeExp - sd_lifeExp,\n                    ymax = mean_lifeExp + sd_lifeExp),\n                width = .25)\n\nggplot(group_means, aes(x = continent, \n                        y = mean_lifeExp,\n                        group = 1))+\n  geom_point() +\n  geom_line() +\n  geom_errorbar(aes(ymin = mean_lifeExp - sd_lifeExp,\n                    ymax = mean_lifeExp + sd_lifeExp),\n                width = .25)"},{"path":"descriptives.html","id":"lab-2-generalization-assignment","chapter":"2 Descriptives","heading":"2.7 Lab 2 Generalization Assignment","text":"","code":""},{"path":"descriptives.html","id":"instructions-1","chapter":"2 Descriptives","heading":"2.7.1 Instructions","text":"general, labs present discussion problems issues example code like , students tasked completing generalization assignments, showing can work concepts tools independently.assignment instructions following:Work inside R project “StatsLab1” made lab 1.Create new R Markdown document called “Lab2.Rmd”Use Lab2.Rmd show work attempting solve following generalization problems. Commit work regularly appears Github repository.problem, make note much problem believe can solve independently without help. example, needed watch help video unable solve problem without copying answers, note 0. confident can complete problem scratch completely , note 100. OK 0s 100s anything .Submit github repository link Lab 2 blackboard.six problems solve, worth 1 point.","code":""},{"path":"descriptives.html","id":"problems-1","chapter":"2 Descriptives","heading":"2.7.2 Problems","text":"Use R demonstrate mean minimizes sum squared deviations mean. Accomplish following steps:Produce sample least 10 different numbersProduce simulation following example concepts sectionUse simulation test range numbers smaller larger mean show mean minimizes sum squared deviations mean.Plot results.Write custom R function one following descriptive statistics: median, mode, standard deviation, variance. Demonstrate produces value base R function given set numbers.Write custom R function one following descriptive statistics: median, mode, standard deviation, variance. Demonstrate produces value base R function given set numbers.Imagine instructor taught morning, afternoon, evening section course. , average scores section midterm 85% morning, 90% afternoon, 93% evening sections. Create data.frame representing means section. , use ggplot2 plot means bar graph. (hint need one vector class sections, one vector means. can combine data.frame plotting )Imagine instructor taught morning, afternoon, evening section course. , average scores section midterm 85% morning, 90% afternoon, 93% evening sections. Create data.frame representing means section. , use ggplot2 plot means bar graph. (hint need one vector class sections, one vector means. can combine data.frame plotting )Imagine two instructors, taught different sections morning, afternoon evening. midterm averages instructor 1 75%, 78%, 80% morning, afternoon, evening. midterm averages instructor 2 88%, 76%, 63% morning, afternoon, evening. Create data.frame representing means, time day, instructors (three columns). plot data.frame using ggplot2 bar graph.Imagine two instructors, taught different sections morning, afternoon evening. midterm averages instructor 1 75%, 78%, 80% morning, afternoon, evening. midterm averages instructor 2 88%, 76%, 63% morning, afternoon, evening. Create data.frame representing means, time day, instructors (three columns). plot data.frame using ggplot2 bar graph.Import WHR2018.csv data file, containing measure World Happiness report 2018. years 2010 2015, mean “healthy life expectancy birth” year (find mean year across countries). Show results table graph using ggplot.Import WHR2018.csv data file, containing measure World Happiness report 2018. years 2010 2015, mean “healthy life expectancy birth” year (find mean year across countries). Show results table graph using ggplot.Repeat , except addition calculating mean year, also calculate standard deviation “healthy life expectancy birth” year. , add error bars graph using +1 -1 standard deviations means year.Repeat , except addition calculating mean year, also calculate standard deviation “healthy life expectancy birth” year. , add error bars graph using +1 -1 standard deviations means year.","code":""},{"path":"descriptives.html","id":"advanced","chapter":"2 Descriptives","heading":"2.7.3 Advanced","text":"problem officially assigned points. ’m placing consideration.mean minimizes sum squared deviations. median minimizes sum absolute deviations. Demonstrate properties simulation R.Create set numbers mean median different. show plot values around mean median showing mean minimizes sum squared deviations. Finally, create plot values around mean median showing median minimizes sum absolute deviations.","code":""},{"path":"distributions-i.html","id":"distributions-i","chapter":"3 Distributions I","heading":"3 Distributions I","text":"“9/2/2020 | Last Compiled: 2020-12-09”","code":""},{"path":"distributions-i.html","id":"reading-1","chapter":"3 Distributions I","heading":"3.1 Reading","text":"Vokey & Allen (2018), Chapters 5 & 6 additional descriptive statistics, recovering distribution; Abdi et al. (2009), Appendices C & D.","code":""},{"path":"distributions-i.html","id":"overview-2","chapter":"3 Distributions I","heading":"3.2 Overview","text":"spend three entire labs devoted understanding working distributions. cover topics closely relate main statistics lecture, also take advantage R examine distributions direct hands manner possible without programming environment.lab one practical section two conceptual sections.Practical \n- Sampling distributions RConceptual \n- Monte-Carlo simulationIn research context data collected form measurements various conditions. data sample, representing outcomes happen. Generally, researchers recognize variability measuring process, sample data different. analyzing data interested happen, happened terms pattern numbers. really understand issues play, need take deep dive distributions understand happens take samples .","code":""},{"path":"distributions-i.html","id":"practical-i-sampling-from-distributions-in-r","chapter":"3 Distributions I","heading":"3.3 Practical I: Sampling from distributions in R","text":"","code":""},{"path":"distributions-i.html","id":"what-is-a-distribution","chapter":"3 Distributions I","heading":"3.3.1 What is a distribution?","text":"take informal approach defining distributions. can think distribution place machine controlling numbers come . words, distributions number creation machines. get define , choices determine kinds numbers can produced distribution.formally, probability distribution defines probabilities particular numbers can drawn sampled distribution.","code":""},{"path":"distributions-i.html","id":"creating-your-own-distributions-in-r-with-sample","chapter":"3 Distributions I","heading":"3.3.2 Creating your own distributions in R with sample()","text":"R several built-functions sampling common distributions (discussed later). look , let’s make using sample().input syntax sample(x, size, replace = FALSE, prob = NULL). x vector one elements, size many samples take elements vector, replace can set TRUE FALSE (controlling whether sampling done without replacement), prob vector probabilities controlling probability sampling element vector x.use sample, can create discrete distributions sample . , default every element equal probability sampled.Create distribution two equally possible numbers, sample twice:Create distribution two equally possible numbers, sample 10 times (note must set replace=TRUE, sampling items exist vector):Create distribution first number probability 90% sampled, second number probability 10% sampled, sample 10 timesCreate distribution model coin flip unbiased coin, flip coin 10 times, distribution return “heads” “tails”.Create distribution numbers 1 1000, allows sampled equal probability. Sample 10 numbers distribution without replacement (sampled one number, allowed sample taken ):","code":"\nsample(x= 1:2, size = 2)\n#> [1] 1 2\nsample(x= 1:2, size = 10, replace = TRUE)\n#>  [1] 1 2 2 2 1 1 1 1 2 1\nsample(x= 1:2, size = 10, replace = TRUE, prob=c(.9,.1))\n#>  [1] 1 1 1 2 1 1 1 1 1 1\nsample(x = c(\"heads\",\"tails\"), size=10, replace= TRUE) \n#>  [1] \"heads\" \"heads\" \"tails\" \"tails\" \"tails\" \"heads\" \"heads\" \"heads\" \"heads\"\n#> [10] \"tails\"\nsample(x= 1:1000, size = 10, replace = FALSE)\n#>  [1] 195 130 884 296 985 967 655 511 667 442"},{"path":"distributions-i.html","id":"normal-distribution","chapter":"3 Distributions I","heading":"3.3.3 Normal distribution","text":"sample random deviates normal distribution, use rnorm(n, mean = 0, sd = 1) function. n number observations sample, mean mean normal distribution, sd standard deviation normal distribution.Two ways sample 10 numbers normal distribution mean = 0, standard deviation = 1.Visualize sample quickly hist()Visualize sample ggplot2 using geom_histogram(). requirement sample data formatted data.frame first. create data frame 100 observations sample_data column, add sample column contains 1s, refer fact numbers sample_data belong sample #1.Visualizing multiple samples individual histograms ggplot2. Let’s say want sample 25 values normal distribution, want repeat process four times. samples 1 4, containing 25 observations. also want generate four histograms quickly look four samples. can setting dataframe represent situation, using facet_wrap().Note: use rep() function new, creates vector repeats numbers 1 4, 25 times . way, first 25 rows dataframe represent 25 observations sample 1, next 25 rows represent observations sample 2, .","code":"\nrnorm(n= 10,mean = 0, sd = 1)\n#>  [1]  0.7507135  1.2885156 -0.1181898 -0.3109193 -2.7237272  0.9839745\n#>  [7] -0.4655029  0.2585130  1.0485176  0.9370757\n\nrnorm(10,0,1)\n#>  [1]  2.3865434  0.4312720 -0.4052384  1.1844978  1.6142325 -0.5250654\n#>  [7] -1.0776366 -0.1900261 -0.9026587  0.3735507\nmy_sample <- rnorm(100,0,1)\nhist(my_sample)\nmy_data <- data.frame(sample_data = rnorm(100,0,1),\n                      sample = 1)\n\nlibrary(ggplot2)\n\nggplot(my_data, aes(x=sample_data))+\n  geom_histogram()\nmy_data <- data.frame(sample_data = rnorm(100,0,1),\n                      sample = rep(1:4, each=25))\n\nggplot(my_data, aes(x=sample_data))+\n  geom_histogram()+\n  facet_wrap(~sample)"},{"path":"distributions-i.html","id":"uniform-distribution-rectangle-distribution","chapter":"3 Distributions I","heading":"3.3.4 Uniform Distribution (rectangle distribution)","text":"uniform distribution equal probability distribution, numbers smallest largest equal probability sampled.Use runif(n, min = 0, max = 1) sample numbers uniform distribution. n number observations, min starting minimum value, max largest value.Sample plot 1000 values uniform distribution 0 1.Sample plot 10000 values uniform distribution 100 1000.Take one sample 100 numbers uniform distribution 0 1. , one sample return count many numbers less value .05.","code":"\nhist(runif(1000,0,1))\nhist(runif(10000,100,1000))\nmy_sample <- runif(100,0,1)\nlength(my_sample[my_sample < .05])\n#> [1] 5"},{"path":"distributions-i.html","id":"other-distributions","chapter":"3 Distributions I","heading":"3.3.5 Other distributions","text":"R contains many distributions sample numbers . list can found ?distributions. examples:Exponential distributionBinomial DistributionWeibull distribution","code":"\nhist(rexp(1000,rate =2))\nhist(rbinom(100,1,prob=c(.5,.5)))\nhist(rweibull(n=1000, shape=2, scale = 1))"},{"path":"distributions-i.html","id":"other-descriptive-statistics","chapter":"3 Distributions I","heading":"3.3.6 Other descriptive statistics","text":"Chapter 5, Vokey Allen discuss skewness kurtosis additional descriptive statistics describe shapes sets numbers. Functions skewness kurtosis can obtained R installing additional packages moments packages.Compute mean, sd, skewness, kurtosis sample 1000 observations normal distribution:","code":"\nlibrary(moments)\nmy_sample <- rnorm(1000,0,1)\nmean(my_sample)\n#> [1] -0.0416809\nsd(my_sample)\n#> [1] 1.001718\nskewness(my_sample)\n#> [1] -0.1607327\nkurtosis(my_sample)\n#> [1] 2.969609\nhist(my_sample)\nmy_sample <- rexp(1000,2)\nmean(my_sample)\n#> [1] 0.4883312\nsd(my_sample)\n#> [1] 0.4653218\nskewness(my_sample)\n#> [1] 1.752688\nkurtosis(my_sample)\n#> [1] 7.173032\nhist(my_sample)"},{"path":"distributions-i.html","id":"conceptual-i-monte-carlo-simulations","chapter":"3 Distributions I","heading":"3.4 Conceptual I: Monte carlo simulations","text":"Many next conceptual sections labs involve process called Monte carlo simulation. short, Monte Carlo simulation one sampling process carried hundreds thousands times order estimate sampling process behaves long run. Monte Carlo simulations can conducted easily R, can write scripts make R repeatedly sample things, can measure assess samples created.Monte-carlo simulations can used tool demonstrate statistical facts concepts, take opportunity use tool many different ways throughout course. purpose conceptual section introduce running Monte-Carlo simulations, show can done different ways.general :Simulate repeated sampling processSave sampled iterationSample many times want (usually thousand)Evaluate simulationAnd, important, identify important statistical concepts use monte-carlo simulations demonstrate understanding concepts.","code":""},{"path":"distributions-i.html","id":"fair-coin","chapter":"3 Distributions I","heading":"3.4.1 Fair coin","text":"coin fair comes heads equally often tails long run. Let’s consider use simulation demonstrate idea. need toHave way sample outcomes binary variableTake several samplesLook get equal number “heads” “tails” long run.one way use R accomplish goals. , use sample function, sample 1s heads, 0s tails. also create loop, repeat sampling process 100 times. iteration flip coin, save result, calculate proportion heads tails far. save everything data.frame, plot proportion heads go 1 100 flips. see proportion get closer .5 increase number flips.","code":"\n#initialize variables\nflip <- c()\noutcome <- c()\nproportion_heads <- c()\nproportion_tails <- c()\n\n# run the simulation\nfor(i in 1:1000){\n  flip[i] <- i\n  outcome[i] <- sample(x = c(1,0), size = 1)\n  proportion_heads[i] <- sum(outcome)/length(outcome)\n  proportion_tails[i] <- 1-proportion_heads[i]\n}\n\n# create a dataframe with saved data\nsim_data <- data.frame(flip,\n                       outcome,\n                       proportion_heads,\n                       proportion_tails)\n\n# plot the simulation results\nggplot(sim_data, aes(x=flip,y=proportion_heads))+\n  geom_point()+\n  geom_line()+\n  geom_hline(yintercept=.5, color=\"red\")"},{"path":"distributions-i.html","id":"samples-become-the-population-as-n-increases","chapter":"3 Distributions I","heading":"3.4.2 Samples become the population as n increases","text":"fundamental concept sampling samples numbers become increasingly like parent population (distribution) size sample (n number observations sample) increases. Let’s demonstrate example phenomena.parent population normal distribution mean =100, sd = 50. want conduct simulation takes sample across different ranges n. sample, calculate sample statistic mean standard deviation. sample statistics become closer closer “true” parent distribution parameters n increases.","code":"\n#initialize variables\nn <- seq(1000,100000,1000)\nsample_mean <- c()\nsample_sd <- c()\n\n#run simulation\nfor(i in 1:length(n)){\n  sim_sample <- rnorm(n[i], mean = 100, sd = 50)\n  sample_mean[i] <- mean(sim_sample)\n  sample_sd[i] <- sd(sim_sample)\n}\n\n# organize results in dataframe\nsim_data <- data.frame(n,\n                       sample_mean,\n                       sample_sd)\n\n# graph results\nggplot(sim_data,aes(x=n,y=sample_mean))+\n  geom_point()+\n  geom_line()+\n  geom_hline(yintercept=100, color=\"red\")\n\nggplot(sim_data,aes(x=n,y=sample_sd))+\n  geom_point()+\n  geom_line()+\n  geom_hline(yintercept=50, color=\"red\")"},{"path":"distributions-i.html","id":"lab-3-generalization-assignment","chapter":"3 Distributions I","heading":"3.5 Lab 3 Generalization Assignment","text":"","code":""},{"path":"distributions-i.html","id":"instructions-2","chapter":"3 Distributions I","heading":"3.5.1 Instructions","text":"general, labs present discussion problems issues example code like , students tasked completing generalization assignments, showing can work concepts tools independently.assignment instructions following:Work inside R project “StatsLab1” usingCreate new R Markdown document called “Lab3.Rmd”Use Lab3.Rmd show work attempting solve following generalization problems. Commit work regularly appears Github repository.problem, make note much problem believe can solve independently without help. example, needed watch help video unable solve problem without copying answers, note 0. confident can complete problem scratch completely , note 100. OK 0s 100s anything .Submit github repository link Lab 3 blackboard.four problems solve","code":""},{"path":"distributions-i.html","id":"problems-2","chapter":"3 Distributions I","heading":"3.5.2 Problems","text":"Create five samples 25 observations normal distribution mean 200, standard deviation 100. Compute mean sample, plot means graph using ggplot2. (1 point)Create five samples 25 observations normal distribution mean 200, standard deviation 100. Compute mean sample, plot means graph using ggplot2. (1 point)Additionally calculate standard deviation sample . Use standard deviations error bars, produce another graph means along error bars using ggplot2. (1 point)Additionally calculate standard deviation sample . Use standard deviations error bars, produce another graph means along error bars using ggplot2. (1 point)last two problems concern concept using sample estimate property population distribution sample came . example, know mean sample, can confident population mean? trying guess population mean, statistics sample use?sample statistics “biased”, may systematically overestimate population parameter. Others “unbiased”, case sample statistic tends correctly estimate population parameter long run.Demonstrate sample mean across range n, unbiased estimator population mean using monte-carlo simulation. (2 points).population normal distribution mean = 10, standard deviation = 5.Test variety n (sample size), including n = 2, 5, 10, 50, 100For sample size n, task draw 10,000 samples size, sample, calculate sample mean. mean unbiased, expect “average” sample means population mean. determine true, compute mean sample means produce see close population mean.Show mean sample means sample size.Use monte carlo simulation compare standard deviation formulas (divide N vs N-1), show N-1 formula better unbiased estimate population standard deviation, especially small n. (2 points)Use normal distribution samples sizes aboveRather computing mean sample, compute forms standard deviation formula, including sample standard deviation divides N-1, regular standard deviation divides NYou 10,000 samples sample size, 10,000 standard deviations sample regular standard deviation. task find average , sample-size.standard deviations systematically biased? , one systematically worse estimating population standard deviation?","code":""},{"path":"distributions-ii.html","id":"distributions-ii","chapter":"4 Distributions II","heading":"4 Distributions II","text":"“9/17/2020 | Last Compiled: 2020-12-09”","code":""},{"path":"distributions-ii.html","id":"reading-2","chapter":"4 Distributions II","heading":"4.1 Reading","text":"Vokey & Allen (2018), Chapter 16; Crump et al. (2018), 4.1 - 4.7; Abdi et al. (2009), Appendix C.","code":""},{"path":"distributions-ii.html","id":"overview-3","chapter":"4 Distributions II","heading":"4.2 Overview","text":"lecture learning basic probability. lab continue learn working distributions R, examine issues relating basic probability.look three conceptual issues probability, gain practical skills R organizing managing simulation data useful rest course. examples generate events particular distributions examine .Concept : Probabilistic event generationConcept II: Experiencing probabilityConcept III: Subjective Probability","code":""},{"path":"distributions-ii.html","id":"concept-i-probabilisitic-event-generation","chapter":"4 Distributions II","heading":"4.3 Concept I: Probabilisitic event generation","text":"concept section use R generate events specified probabilities. mainly use sample() function, already familiar . concept section explores probabilistic event generation different ways examining probability problems:","code":""},{"path":"distributions-ii.html","id":"dice-problems","chapter":"4 Distributions II","heading":"4.3.1 Dice Problems","text":"Use R roll fair six-sided die, show number comes equally frequently long run. Roll die 10,000 times, report many times number (1-6) rolled.number come 10000/6 = 1666.667 times.pair six-sided dice possible roll numbers 2 12. Use simulation 10000 rolls (pair dice) R calculate probability rolling possible numbers.Let’s compare result simulation known probabilities. First, need determine number ways number can obtained rolling pair dice. can use R well:","code":"\nrolls <- sample(1:6,1000, replace=TRUE)\ntable(rolls)\n#> rolls\n#>   1   2   3   4   5   6 \n#> 185 158 155 163 164 175\none <- sample(1:6,1000, replace=TRUE)\ntwo <- sample(1:6,1000, replace=TRUE)\ncombined <- one+two\ntable(combined)/1000\n#> combined\n#>     2     3     4     5     6     7     8     9    10    11    12 \n#> 0.025 0.058 0.084 0.086 0.137 0.180 0.155 0.109 0.081 0.060 0.025\nfirst <- rep(x= 1:6, each = 6)\nsecond <- rep(x= 1:6, times = 6)\nsum_rolls <- first+second\ntable(sum_rolls)/length(sum_rolls)\n#> sum_rolls\n#>          2          3          4          5          6          7          8 \n#> 0.02777778 0.05555556 0.08333333 0.11111111 0.13888889 0.16666667 0.13888889 \n#>          9         10         11         12 \n#> 0.11111111 0.08333333 0.05555556 0.02777778\n\n## compare\nsim_result <- table(combined)/1000\ntrue_probs <- table(sum_rolls)/length(sum_rolls)\n\n## Difference\ntrue_probs-sim_result\n#> sum_rolls\n#>             2             3             4             5             6 \n#>  0.0027777778 -0.0024444444 -0.0006666667  0.0251111111  0.0018888889 \n#>             7             8             9            10            11 \n#> -0.0133333333 -0.0161111111  0.0021111111  0.0023333333 -0.0044444444 \n#>            12 \n#>  0.0027777778"},{"path":"distributions-ii.html","id":"event-generators","chapter":"4 Distributions II","heading":"4.3.2 Event generators","text":"Remember can use sample() generate events specific probabilities:Generate P(“”) = .8, P(“B”) =.2, run generator 20 times.Generate letters alphabet letter occur equal probability. Generate 50 letters:Note, conveniently, R contains variable called letters, vector lowercase letters (uppercase one called LETTERS)Create random string generator creates strings random letters. example string 5 random letters look like “fjwud”. Generate 50 random letter strings, 5 random letters .","code":"\nsample(c(\"A\",\"B\"), 20, replace = TRUE, prob = c(.8, .2))\n#>  [1] \"A\" \"A\" \"B\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"B\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"A\" \"B\"\n#> [20] \"A\"\nletters\n#>  [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n#> [20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\"\n\nLETTERS\n#>  [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n#> [20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\nsample(letters,50,replace=TRUE)\n#>  [1] \"r\" \"d\" \"m\" \"g\" \"p\" \"k\" \"q\" \"o\" \"d\" \"k\" \"v\" \"d\" \"y\" \"x\" \"g\" \"u\" \"f\" \"j\" \"d\"\n#> [20] \"z\" \"z\" \"t\" \"h\" \"f\" \"c\" \"g\" \"j\" \"m\" \"g\" \"e\" \"q\" \"p\" \"o\" \"m\" \"v\" \"l\" \"r\" \"u\"\n#> [39] \"f\" \"h\" \"s\" \"k\" \"w\" \"l\" \"q\" \"s\" \"z\" \"w\" \"w\" \"k\"\nmy_letters <- sample(letters,50*5,replace=TRUE)\n\n# turn the vector into a matrix with 5 columns\nmy_strings <- matrix(my_letters, ncol=5)\n\n# each row is a word, need to collapse the column to create a string\npaste(my_strings[1,], collapse=\"\")\n#> [1] \"deqpd\"\n\n# loop to collapse all of the rows into words\nrandom_strings <-c()\nfor(i in 1:dim(my_strings)[1]){\n  random_strings[i] <- paste(my_strings[i,], collapse=\"\")\n}\n\nrandom_strings\n#>  [1] \"deqpd\" \"zrrfj\" \"ghaoj\" \"xwemf\" \"qxtvu\" \"pygmr\" \"hbqka\" \"vhzoi\" \"zwvfd\"\n#> [10] \"atlqy\" \"fcbjy\" \"xrdms\" \"quqgb\" \"uuxrw\" \"svlao\" \"ojtcr\" \"pbxzn\" \"yshvl\"\n#> [19] \"oxynn\" \"aygqi\" \"bsrau\" \"xruqy\" \"rukxd\" \"jztop\" \"cjhiu\" \"bpgtx\" \"egwbs\"\n#> [28] \"eqeol\" \"upswv\" \"cndnz\" \"ttpvw\" \"gylcw\" \"jrekt\" \"hbono\" \"xevpm\" \"pqivb\"\n#> [37] \"tlhtk\" \"oblzq\" \"sarqw\" \"lpjfh\" \"kgauv\" \"zvgcy\" \"vyzfv\" \"qtwwj\" \"gisgy\"\n#> [46] \"jwtfv\" \"hgsgi\" \"bepid\" \"lhvjj\" \"zpnzv\""},{"path":"distributions-ii.html","id":"concept-ii-experiencing-probability","chapter":"4 Distributions II","heading":"4.4 Concept II: Experiencing probability","text":"People talk probabilities time. example, tomorrow might 10% chance rain, fair coin 50% chance landing heads tails, common examples. already begun look probabilities behave lab 3, used R flip coin demonstrate coin fair long run. expand demonstration .One takeaway point coin flipping example P(heads) = .5 (probability getting heads equals 50%), true “long run”. short run, get bunch tails.","code":""},{"path":"distributions-ii.html","id":"short-run-coin-flipping","chapter":"4 Distributions II","heading":"4.4.1 Short-run coin flipping","text":"Consider flipping fair coin ten times. possible outcomes? probability outcomes? Let’s answer question simulation R.possible outcomes 10 Tails 10 Heads, combination heads tails , can described 0 heads 10 heads.flipped coin 10000 times, find many different kinds short-run sequences. example, HH, HT, TH, TT. probability kinds sequences?","code":"\nsim_results <- replicate(10000,\n                         sample( c(1,0), 10, replace=TRUE)\n                         )\nnumber_of_heads <- colSums(sim_results)\ntable(number_of_heads)/10000\n#> number_of_heads\n#>      0      1      2      3      4      5      6      7      8      9     10 \n#> 0.0007 0.0096 0.0423 0.1208 0.2032 0.2453 0.2100 0.1143 0.0428 0.0100 0.0010\n\n# alternative solution using rbinom\n\nnumber_of_heads <- rbinom(10000,10,prob=.5)\ntable(number_of_heads)/10000\n#> number_of_heads\n#>      0      1      2      3      4      5      6      7      8      9     10 \n#> 0.0007 0.0102 0.0458 0.1115 0.2045 0.2480 0.2119 0.1142 0.0428 0.0089 0.0015\nflips <- sample(c(\"H\",\"T\"), 10000, replace=TRUE)\n\nsequence <- c()\nfor(i in 2:length(flips)){\n  first_element <- flips[i-1]\n  second_element <- flips[i]\n  sequence[i-1] <- paste0(first_element,second_element)\n}\n\ntable(sequence)/sum(table(sequence))\n#> sequence\n#>        HH        HT        TH        TT \n#> 0.2499250 0.2528253 0.2528253 0.2444244\n\n## 3 element sequences\n\nflips <- sample(c(\"H\",\"T\"), 10000, replace=TRUE)\n\nsequence <- c()\nfor(i in 3:length(flips)){\n  first_element <- flips[i-2]\n  second_element <- flips[i-1]\n  third_element <- flips[i]\n  sequence[i-1] <- paste0(first_element,\n                          second_element,\n                          third_element)\n}\n\ntable(sequence)/sum(table(sequence))\n#> sequence\n#>       HHH       HHT       HTH       HTT       THH       THT       TTH       TTT \n#> 0.1297259 0.1245249 0.1236247 0.1263253 0.1246249 0.1254251 0.1263253 0.1194239"},{"path":"distributions-ii.html","id":"concept-iii-subjective-probability","chapter":"4 Distributions II","heading":"4.5 Concept III: Subjective Probability","text":"Vokey & Allen discuss Bayesian concept subjective probability, practice assigning probabilities beliefs, updating probabilities belief data-gathering process.concept section use R demonstrate basic example belief updating.First, create sequence events. stick coin flips. Let’s create situation event probability changes point, task collect data determine can update beliefs world., flip fair coin 100 times, flip biased coin 100 times. biased coin likely come heads (60%).Next, imagine idea kind coins flipped, sequence flips. start first coin flip, go , time use data update belief coin.beliefs probability getting heads look like allow remember last 20 coin flips?confident correct belief probability getting heads?","code":"\nsimulated_sequence <- c(rbinom(100,1,.5),\n                        rbinom(100,1,.6))\nmy_knowledge <- c()\nmy_belief <- c()\nfor(i in 1:length(simulated_sequence)){\n  \n    my_knowledge[i] <- simulated_sequence[i]\n    my_belief[i] <- sum(my_knowledge)/length(my_knowledge)\n    \n}\n\nplot(my_belief)\n\nsimulated_sequence <- c(rbinom(100,1,.5),\n                        rbinom(100,1,.6))\n\nmy_knowledge <- c()\nmy_belief <- c()\nfor(i in 1:length(simulated_sequence)){\n  \n    my_knowledge[i] <- simulated_sequence[i]\n    if(i <= 20){\n      my_belief[i] <- sum(my_knowledge)/length(my_knowledge)\n    }else{\n      my_belief[i] <- sum(my_knowledge[i:(i-20)])/length(my_knowledge[i:(i-20)])\n    }\n    \n}\n\nplot(my_belief)"},{"path":"distributions-ii.html","id":"lab-4-generalization-assignment","chapter":"4 Distributions II","heading":"4.6 Lab 4 Generalization Assignment","text":"","code":""},{"path":"distributions-ii.html","id":"instructions-3","chapter":"4 Distributions II","heading":"4.6.1 Instructions","text":"general, labs present discussion problems issues example code like , students tasked completing generalization assignments, showing can work concepts tools independently.assignment instructions following:Work inside R project “StatsLab1” usingCreate new R Markdown document called “Lab4.Rmd”Use Lab4.Rmd show work attempting solve following generalization problems. Commit work regularly appears Github repository.problem, make note much problem believe can solve independently without help. example, needed watch help video unable solve problem without copying answers, note 0. confident can complete problem scratch completely , note 100. OK 0s 100s anything .Submit github repository link Lab 4 blackboard.five problems solve","code":""},{"path":"distributions-ii.html","id":"problems-3","chapter":"4 Distributions II","heading":"4.6.2 Problems","text":"Estimate letter occurrence probabilities 26 letters English measuring paragraph English text wikipedia. (hint use strsplit() split paragraph individual letters) (1 point).Generate “random” strings letters sampled distribution letter occurrence probability natural English. Use probabilities letter wikipedia article, use estimates previous question (2 points).Generate “random” strings letters sampled distribution letter occurrence probability natural English. Use probabilities letter wikipedia article, use estimates previous question (2 points).Generate random walk 10,000 steps. random walk, simulating process randomly taking step , infinite staircase. step flip coin. get heads go one step, get tails go one step. Start step 0, simulate random walk 10,000 steps. vector preserve step number step. example, first three steps heads, vector begin 0,1,2,3, indicates single step time. Plot first 1,000 steps. (1 point)Generate random walk 10,000 steps. random walk, simulating process randomly taking step , infinite staircase. step flip coin. get heads go one step, get tails go one step. Start step 0, simulate random walk 10,000 steps. vector preserve step number step. example, first three steps heads, vector begin 0,1,2,3, indicates single step time. Plot first 1,000 steps. (1 point)positive negative step reached 10,000? (1 point)positive negative step reached 10,000? (1 point)longest run steps steps positive numbers. example, sequence: 1,2,3,2,1,0,-1,-2,-1,-2,-1,0,1,2,3; answer 5 first five values positive, longest sequence positive values. (1 point).longest run steps steps positive numbers. example, sequence: 1,2,3,2,1,0,-1,-2,-1,-2,-1,0,1,2,3; answer 5 first five values positive, longest sequence positive values. (1 point).","code":"\nmy_paragraph <- \"This is a paragraph, with some stuff in it. This is another sentence in the paragraph\"\nthe_letters <- unlist(strsplit(my_paragraph, split=\"\"))\nthe_letters\n#>  [1] \"T\" \"h\" \"i\" \"s\" \" \" \"i\" \"s\" \" \" \"a\" \" \" \"p\" \"a\" \"r\" \"a\" \"g\" \"r\" \"a\" \"p\" \"h\"\n#> [20] \",\" \" \" \"w\" \"i\" \"t\" \"h\" \" \" \"s\" \"o\" \"m\" \"e\" \" \" \"s\" \"t\" \"u\" \"f\" \"f\" \" \" \"i\"\n#> [39] \"n\" \" \" \"i\" \"t\" \".\" \" \" \"T\" \"h\" \"i\" \"s\" \" \" \"i\" \"s\" \" \" \"a\" \"n\" \"o\" \"t\" \"h\"\n#> [58] \"e\" \"r\" \" \" \"s\" \"e\" \"n\" \"t\" \"e\" \"n\" \"c\" \"e\" \" \" \"i\" \"n\" \" \" \"t\" \"h\" \"e\" \" \"\n#> [77] \"p\" \"a\" \"r\" \"a\" \"g\" \"r\" \"a\" \"p\" \"h\""},{"path":"sampling-distributions.html","id":"sampling-distributions","chapter":"5 Sampling Distributions","heading":"5 Sampling Distributions","text":"“10/2/2020 | Last Compiled: 2020-12-09”","code":""},{"path":"sampling-distributions.html","id":"readings","chapter":"5 Sampling Distributions","heading":"5.1 Readings","text":"Crump et al. (2018), 4.8 - 4.10","code":""},{"path":"sampling-distributions.html","id":"review","chapter":"5 Sampling Distributions","heading":"5.2 Review","text":"last two labs begun explore distributions, used R create sample distributions. continue exploration many following labs.continue want point major conceptual goal . nuanced understanding one statement one question:Chance can thingsWhat can chance ?put concrete terms previous labs. know ‘chance’ can produce different outcomes flip coin. sense chance things. 50% chance process can sometimes make heads, sometimes tails. Also, started ask “can chance ?” prior labs. example, asked often chance produces 10 heads row, flip coin. found chance doesn’t often, compared say 5 heads 5 tails.using next labs find different ways use R experience 1) chance can things, 2) likely things happen chance. working toward third question (next lab), 3) chance ?…run experiment, possible chance alone produced data collected?","code":""},{"path":"sampling-distributions.html","id":"overview-4","chapter":"5 Sampling Distributions","heading":"5.3 Overview","text":"lab following modules:Conceptual Review : Probability Distributionswe review sampling probability distributions using R examine additional aspects base R distribution functionsConceptual II: Sampling Distributionswe use R create new kind distribution, called sampling distribution. prepare future statistics lectures concepts fundamentally depend sampling distributions.Understanding sampling distributions may well fundamental thing understand statistics (’s just opinion).","code":""},{"path":"sampling-distributions.html","id":"probability-distributions","chapter":"5 Sampling Distributions","heading":"5.4 Probability Distributions","text":"previous labs learned possible sample numbers particular distributions R.","code":"#see all the distribution functions\n?distributions"},{"path":"sampling-distributions.html","id":"normal-distribution-1","chapter":"5 Sampling Distributions","heading":"5.4.1 Normal Distribution","text":"use rnorm() sample numbers normal distribution:can ‘see’ distribution sampling large number observations, plotting histogram:can see example using random chance sample distribution caused numbers observed. , can see “chance something”. can also see chance things others. Values close 0 sampled much often values larger 2.5.often sample value larger 2.5? probability chance produce value larger 2.5? value distribution? answer questions, need get specific exactly chance situation, distribution, capable .can answer question like observation. can look sample generated, see many numbers total larger particular value:also compute probability directly using analytical formulas. , formulas also exist R. Specifically, distribution formulas begin d, p, q, r, dnorm, pnorm, qnorm, rnorm functions normal distribution (distributions).","code":"\nrnorm(n=10, mean = 0, sd = 1)\n#>  [1] -1.0019349 -1.0519557 -0.3011568  1.2220209  0.1025381  1.0983615\n#>  [7]  0.1640728  1.4291822  0.7122542  0.8019979\nlibrary(ggplot2)\nsome_data <- data.frame(observations = rnorm(n=10000, mean = 0, sd = 1),\n                        type = \"A\")\n\nggplot(some_data, aes(x=observations)) +\n  geom_histogram(bins=100, color=\"black\", \n                 fill= 'orange')\nsome_data$observations[some_data$observations > 2.5]\n#>  [1] 2.928525 2.781648 2.868732 2.552076 2.727173 3.154145 2.681787 2.864008\n#>  [9] 3.191691 2.624065 2.646727 2.731566 2.739447 2.679715 2.521466 2.834034\n#> [17] 2.863045 2.810554 3.516797 2.799241 2.791296 2.572595 2.778810 2.850113\n#> [25] 2.681773 3.034754 2.805372 2.990966 2.674465 3.102878 2.736407 2.669546\n#> [33] 2.579411 3.141679 3.025064 2.563732 3.372532 2.810153 2.657164 2.673537\n#> [41] 3.866567 2.764349 2.612303 3.414172 2.897619 5.325133 2.632761 2.512114\n#> [49] 2.625397 3.020722 2.757451 2.633909 2.694776 3.115221 2.814079 3.009813\n#> [57] 2.799929 2.660804 2.977252 2.979958 2.627102 3.367223 2.630621 2.502218\n#> [65] 2.685564 2.621895 2.511339 3.141363 2.614251 2.651630 2.568692 2.571659\n#> [73] 3.451340\nlength(some_data$observations[some_data$observations > 2.5])\n#> [1] 73\nlength(some_data$observations[some_data$observations > 2.5])/10000\n#> [1] 0.0073"},{"path":"sampling-distributions.html","id":"rnorm","chapter":"5 Sampling Distributions","heading":"5.4.1.1 rnorm()","text":"rnorm(n, mean = 0, sd = 1) samples observations (random deviates) normal distribution specified mean standard deviation.","code":"\nrnorm(n=10, mean = 0, sd = 1)\n#>  [1]  1.6196756  0.6847015 -0.2484228 -0.8445940 -0.8467085 -0.7368235\n#>  [7] -0.8444813 -1.4188080 -0.4046103  1.4017983"},{"path":"sampling-distributions.html","id":"dnorm","chapter":"5 Sampling Distributions","heading":"5.4.1.2 dnorm()","text":"dnorm(x, mean = 0, sd = 1, log = FALSE) probability density function. returns probability density distribution value can obtained distribution.example, histogram, can see distribution produces values roughly -3 3, perhaps -4 4. also see values approach 0, happen often. , probability density changes across distribution. can plot directly using dorm(), supplying sequence value, say -4 4.pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) takes given value distribution produce input called q quantile. function returns proportional area curve value.example, area curve starting left (e.g., negative infinity) way 2.5?“complement” question. 99.37903% values drawn distribution expected less 2.5. just determined probability getting number smaller 2.5, otherwise known lower tail.\ndefault, pnorm calculates lower tail, area curve q value point left side plot.calculate probability getting number larger particular value can take complement, set lower.tail=FALSE","code":"\nlibrary(ggplot2)\nsome_data <- data.frame(density = dnorm(-4:4, mean = 0, sd = 1),\n                        x = -4:4)\n\nknitr::kable(some_data)\n\nggplot(some_data, aes(x=x, y=density)) +\n  geom_point()\nsome_data <- data.frame(density = dnorm(seq(-4,4,.001), mean = 0, sd = 1),\n                        x = seq(-4,4,.001))\n\nggplot(some_data, aes(x=x, y=density)) +\n  geom_line()\nlibrary(dplyr)\nsome_data <- data.frame(density = dnorm(seq(-4,4,.001), mean = 0, sd = 1),\n                        x = seq(-4,4,.001))\n\nregion_data <- some_data %>%\n  filter(x > 2.5)\n\nggplot(some_data, aes(x=x, y=density)) +\n  geom_line()+\n  geom_ribbon(data = region_data, \n              fill = \"red\",\n              aes(ymin=0,ymax=density))\npnorm(2.5, mean=0, sd = 1)\n#> [1] 0.9937903\nsome_data <- data.frame(density = dnorm(seq(-4,4,.001), mean = 0, sd = 1),\n                        x = seq(-4,4,.001))\nregion_data <- some_data %>%\n  filter(x < 2.5)\n\nggplot(some_data, aes(x=x, y=density)) +\n  geom_line()+\n  geom_ribbon(data = region_data, \n              fill = \"red\",\n              aes(ymin=0,ymax=density))\n1 - pnorm(2.5, mean=0, sd = 1)\n#> [1] 0.006209665\n\npnorm(2.5, mean=0, sd = 1, lower.tail=FALSE)\n#> [1] 0.006209665"},{"path":"sampling-distributions.html","id":"qnorm","chapter":"5 Sampling Distributions","heading":"5.4.1.3 qnorm","text":"qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) similar pnorm, takes probability input, returns specific point value (quantile) x-axis. formally, specify proportional area curve starting left, function tells number area corresponds .remaining assume mean=0 sd =1.number x-axis location 25% values smaller value?number x-axis location 50% values smaller value?number 95% values larger number?","code":"\nqnorm(.25, mean= 0, sd =1)\n#> [1] -0.6744898\nqnorm(.5, mean= 0, sd =1)\n#> [1] 0\nqnorm(.95, mean= 0, sd =1, lower.tail = FALSE)\n#> [1] -1.644854\n\nqnorm(.05, mean = 0 , sd =1, lower.tail = FALSE)\n#> [1] 1.644854"},{"path":"sampling-distributions.html","id":"summary","chapter":"5 Sampling Distributions","heading":"5.4.2 Summary","text":"Focusing normal distribution functions, learned chance can produce different kinds numbers normal distribution. , can use dnorm, qnorm, pnorm functions exactly compute specific probabilities certain ranges values occur.","code":""},{"path":"sampling-distributions.html","id":"conceptual-sampling-distributions","chapter":"5 Sampling Distributions","heading":"5.5 Conceptual: Sampling Distributions","text":"collect data assume come “distribution”, “causes” numbers occur others. data collect “sample” portion “distribution”.know sample distributions chance can play role. Specifically, chance alone one sample observations look different another sample, even came distribution. words, recognize process sampling distribution involves variability uncertainty.can use sampling distributions tool help us understand predict sampling process behave. way can information variable uncertain samples .","code":""},{"path":"sampling-distributions.html","id":"confusing-jargon","chapter":"5 Sampling Distributions","heading":"5.5.1 Confusing jargon","text":"Throughout course come across terms like, “sampling distributions”, “sampling distribution sample mean”, “sampling distribution sample statistic”, “standard deviation sampling distribution sample mean standard error mean”. Although sentence hard parse opinion jargony, represent important ideas need distinguished well understood. going work things lab.","code":""},{"path":"sampling-distributions.html","id":"the-sample-mean","chapter":"5 Sampling Distributions","heading":"5.5.2 The sample mean","text":"remaining examples use normal distribution mean = 0 sd =1.already know sample mean calculate R. example calculating sample mean, number observations (n) sample 10.","code":"\nmean(rnorm(10, mean=0, sd =1))\n#> [1] 0.3376038"},{"path":"sampling-distributions.html","id":"multiple-sample-means","chapter":"5 Sampling Distributions","heading":"5.5.3 Multiple sample means","text":"can repeat process many times like, time creating sample 10 observations computing mean.example creating 5 sample means 5 sets 10 observations.Notice sample means different, variability introduced randomly choosing values normal distribution.mean distribution samples come 0, expect mean samples ? general, expect 0, can see sample means exactly 0.much variability can expect sample mean? words, going obtain sample 10 numbers distribution, kinds sample means get?.","code":"\nmean(rnorm(10, mean=0, sd =1))\n#> [1] -0.139616\nmean(rnorm(10, mean=0, sd =1))\n#> [1] -0.6549391\nmean(rnorm(10, mean=0, sd =1))\n#> [1] -0.1269689\nmean(rnorm(10, mean=0, sd =1))\n#> [1] -0.06684122\nmean(rnorm(10, mean=0, sd =1))\n#> [1] 0.3020679"},{"path":"sampling-distributions.html","id":"the-sampling-distribution-of-the-sample-means","chapter":"5 Sampling Distributions","heading":"5.5.4 The sampling distribution of the sample means","text":"answer question kinds sample means get? “sampling distribution sample means”. words, work actually find create bunch samples, find means, bunch sample means, numbers form distribution. distribution effectively showing different ways random chance can produce particular sample means.Let’s make distribution sample means. create 10,000 samples, 10 observations, compute mean . save look means histogram.wanted know expect single sample mean (knew taking values normal distribution), look sampling distribution.Sample means close 0 happen . , time, take sample distribution, mean sample 0. rare sample mean larger .5. rare sample mean larger 1.","code":"\nsample_means <- replicate(10000, mean(rnorm(10,0,1)))\nhist(sample_means)"},{"path":"sampling-distributions.html","id":"the-standard-error-the-mean","chapter":"5 Sampling Distributions","heading":"5.5.5 The standard error the mean","text":"discussed concept definition standard error mean lecture portion class. However, seen mean sample taken distribution expected variability, specifically fact distribution different sample means shows variability.descriptive statistic already discussed provides measures variability? One option standard deviation. example, following measure variability associated distribution sample means.Generate distribution sample meansCalculate standard deviation sample meansThe standard deviation sample means give us idea much variability expect sample mean. quickly R like :value calculated standardized unit, describes amount error expect general sample mean. Specifically, true population mean 0, obtain samples, expect sample means error, average 0, plus minus standard deviation calculated.necessarily generate distribution sample means calculate standard error. know population standard deviation (\\(\\sigma\\)), can use formula standard error mean (SEM) :\\(\\text{SEM} = \\frac{\\sigma}{\\sqrt{N}}\\)\\(\\sigma\\) population standard deviation, \\(N\\) sample size.can also compare SEM formula one obtained simulation, find similar.","code":"\nsample_means <- replicate(10000, mean(rnorm(10,0,1)))\nsd(sample_means)\n#> [1] 0.3177668\n# simulation SEM\nsample_means <- replicate(10000, mean(rnorm(10,0,1)))\nsd(sample_means)\n#> [1] 0.3172985\n\n# analytic SEM\n\n1/sqrt(10)\n#> [1] 0.3162278"},{"path":"sampling-distributions.html","id":"lab-5-generalization-assignment","chapter":"5 Sampling Distributions","heading":"5.6 Lab 5 Generalization Assignment","text":"","code":""},{"path":"sampling-distributions.html","id":"instructions-4","chapter":"5 Sampling Distributions","heading":"5.6.1 Instructions","text":"general, labs present discussion problems issues example code like , students tasked completing generalization assignments, showing can work concepts tools independently.assignment instructions following:Work inside R project “StatsLab1” usingCreate new R Markdown document called “Lab5.Rmd”Use Lab5.Rmd show work attempting solve following generalization problems. Commit work regularly appears Github repository.problem, make note much problem believe can solve independently without help. example, needed watch help video unable solve problem without copying answers, note 0. confident can complete problem scratch completely , note 100. OK 0s 100s anything .Submit github repository link Lab 5 blackboard.five problems solve","code":""},{"path":"sampling-distributions.html","id":"problems-4","chapter":"5 Sampling Distributions","heading":"5.6.2 Problems","text":"Trust verify. trust rnorm() generate random deviates accordance definition normal distribution. example, learned lab, normal distribution mean = 0, sd =1 , produce values larger 2.5 specific small probability, P(x>2.5) = 0.006209665. Verify approximately case randomly sampling 1 million numbers distribution, calculate proportion numbers larger 2.5. (1 point)Trust verify. trust rnorm() generate random deviates accordance definition normal distribution. example, learned lab, normal distribution mean = 0, sd =1 , produce values larger 2.5 specific small probability, P(x>2.5) = 0.006209665. Verify approximately case randomly sampling 1 million numbers distribution, calculate proportion numbers larger 2.5. (1 point)performance standardized test known follow normal distribution mean 100 standard deviation 10, 10,000 people took test, many people expected achieve score higher 3 standard deviations mean? (1 point)performance standardized test known follow normal distribution mean 100 standard deviation 10, 10,000 people took test, many people expected achieve score higher 3 standard deviations mean? (1 point)randomly sample 25 numbers normal distribution mean = 10 standard deviation = 20. obtain sample mean 12. want know probability received sample mean 12 larger.randomly sample 25 numbers normal distribution mean = 10 standard deviation = 20. obtain sample mean 12. want know probability received sample mean 12 larger.Create sampling distribution mean scenario least 10,000 sample means (1 point). , calculate proportion sample means 12 larger (1 point).randomly sample 100 numbers normal distribution mean = 10 standard deviation = 20. obtain sample mean 12. want know probability received sample mean 12 larger.Create sampling distribution mean scenario least 10,000 sample means. , calculate proportion sample means 12 larger. proportion different question 3, ? (1 point).randomly sample 25 numbers normal distribution mean = 10 standard deviation = 20. obtain sample standard deviation 15. want know probability received sample standard deviation 15 less.Create sampling distribution standard deviations scenario least 10,000 sample standard deviations. , calculate proportion sample standard deviations 15 less. (1 point)","code":""},{"path":"statistical-inference.html","id":"statistical-inference","chapter":"6 Statistical Inference","heading":"6 Statistical Inference","text":"“10/8/2020 | Last Compiled: 2020-12-09”","code":""},{"path":"statistical-inference.html","id":"readings-and-review","chapter":"6 Statistical Inference","heading":"6.1 Readings and Review","text":"Vokey & Allen (2018), Chapter 10; Crump et al. (2018), Chapter 5This lab marks departure land statistical inference. working toward concepts using R help us understand basic aspects distributions sampling distributions. concepts applied throughout remainder course discuss many different tools tests statistical inference.instructor (Matt Crump), know many “feelings” statistical inference. , many perspectives, sometimes competing even inconsistent ones, value, goals, practice “statistical inference”. partly many well-founded opinions approaches statistical inference try , also partly many known issues flawed practices researchers sometimes engage , also many limitations kinds inferences can made depending .take one example, researcher might want “X test” data, even though don’t really know “X test” , know can put data program press button, program X test, can report results X test paper. view kind behavior irresponsible. view , general, researcher extremely well thought reasons justifications motivations advance collecting data analysis. able describe X test works, ’s assumptions , appropriate use case, well ’s limitations , exactly can concluded test.Another example line view. researcher understands general principles statistical inference works, collect data particular experiment designed, make use custom test completely justifiable issue addressing.","code":""},{"path":"statistical-inference.html","id":"be-able-to-justify-your-statistical-inference","chapter":"6 Statistical Inference","heading":"6.1.1 Be able to justify your statistical inference","text":"examples kind extreme cases. However, whether use well-known test, common canned approach, roll--statistics, strongly believe able justify approach. means able present argument process statistical inference minimally suitable task hand., think able justify statistical inferences important, designed following labs help learn fundamental principles statistical inference, can use understand justify even create process statistical inference appropriate research .","code":""},{"path":"statistical-inference.html","id":"foundations-for-statistical-inference-and-the-crump-test","chapter":"6 Statistical Inference","heading":"6.1.2 Foundations for Statistical Inference and the Crump test","text":"new concept tests statistical inference, /want slightly unconventional take statistical inference, ’ll forward chapter undergraduate statistics textbook (Crump et al., 2018): https://crumplab.github.io/statistics/foundations--inference.html. chapter discusses basic ideas behind statistical inference, also provides test “made ” called Crump test, doesn’t use formulas, tries highlight process ideas behind statistical inference.","code":""},{"path":"statistical-inference.html","id":"a-parting-metaphor","chapter":"6 Statistical Inference","heading":"6.1.3 A parting metaphor","text":"Imagine detective scene crime. want know committed crime. Another detective says, hypothesis, crime scene consistent believe Mickey Mouse committed crime. puzzled, Mickey Mouse fictional cartoon character, impossible Mickey Mouse committed crime. ask clarification. Detective says, “mean , Mickey Mouse real, think committed crime”. Also, several detectives say think Donald Duck , mean, crime scene inconsistent Donald Duck done crime Donald Duck real.might wondering metaphor? imagine detective finds strange even consider hypotheses fictional cartoon characters may may committed crime. view, strangeness different researcher considers statistical hypotheses data collect. see throughout rest course, statistical hypotheses sometimes different fictional characters, although can immensely useful tasks data analysis interpretation, without clear limitations explanatory power.","code":""},{"path":"statistical-inference.html","id":"overview-5","chapter":"6 Statistical Inference","heading":"6.2 Overview","text":"begin discussion statistical tests Permutation Randomization tests.Concepts : Permutation testConcepts II: Randomization testPractical : Randomization test real data","code":""},{"path":"statistical-inference.html","id":"why-are-these-tests-not-very-common","chapter":"6 Statistical Inference","heading":"6.2.1 Why are these tests not very common?","text":"read many research papers psychology, might see many permutation randomization tests reported. Specific disciplines sub-disciplines tend adopt specific tests various reasons, inertia can set . tests used good enough, use different ones?Permutation randomization tests good examples tests “easy” computer , “hard” person . conducting process permuting /random sampling hand can take long time. manual labor involved probably one reason tests become popular computers invented. , use specific tests discipline already firmly established computers widely available, seems permutation randomization tests fell wayside. computers available earlier , guess test used commonly today.Fortunately, computers R, can now use create evaluate permutation randomization tests.","code":""},{"path":"statistical-inference.html","id":"c1-permutation-test","chapter":"6 Statistical Inference","heading":"6.3 C1: Permutation Test","text":"","code":""},{"path":"statistical-inference.html","id":"what-is-a-permutation","chapter":"6 Statistical Inference","heading":"6.3.1 What is a permutation?","text":"permutation reordering sequence. example, can easily re-order sequence using sample() function.number permutations (unique re-orderings) n distinct items \\(n!\\)Therefore, take 5 numbers distinct values 1, 2, 3, 4, 5, able form 120 distinct orders permutations numbers.put numbers 1, 2, 3, 4, 5 basket, randomly take , chances take order 1,2,3,4,5?Well, 1 order 120, 1/120 =Let’s quickly test :quick summary. Permutations different ways order numbers. given set numbers, always total number possible orders. assume orders obtained chance, can calculate chances getting particular order.","code":"\na <- c(1,2,3,4,5)\nsample(a)\n#> [1] 3 4 2 1 5\n5*4*3*2*1\n#> [1] 120\n1/120\n#> [1] 0.008333333\n# generate 10000 random samples\nmy_samples <- replicate(10000,sample(c(1,2,3,4,5)))\n\ncount_examples <- 0 \nfor(i in 1:10000){\n  if( sum( my_samples[,i] == c(1,2,3,4,5) ) == 5) {\n    count_examples <- count_examples+1\n  } \n}\n\ncount_examples/10000\n#> [1] 0.0081"},{"path":"statistical-inference.html","id":"a-permutation-test-example","chapter":"6 Statistical Inference","heading":"6.3.2 A permutation test example","text":"8 people, assign 4 group , 4 group B. basket contains 8 balls, number , just like lottery. balls numbered 1 8, completely identical. Everybody puts blindfold goes one time take one ball.possible outcomes situation? First, \\(8! = 8*7*6*5*4*3*2*1 = 40,320\\) possible permutations, number different ways person group randomly choose ball.also means chances getting highly specific outcome, like \\(1/40320\\), 2.4801587^{-5}.chances sum balls Group different sum balls chosen Group B? figure kinds questions access permutations. Let’s make matrix possible permutations.First, install package ‘combinat’, contains permn() function. can use function create matrix permutations sequence 1 8. Note, sequence much larger, number permutations becomes large, wouldn’t recommend using function generate permutations large sequences.matrix can assume first four columns choices persons 1 4 group made, last four columns choices persons 5 8 made.Let’s now determine various sums obtained permutation. , sum ball numbers Group group B, can learn different possible outcomes actually .Now, let’s determine possible differences sums Group B.possible differences look like? Let’s make histogram.Let’s sanity check. biggest possible difference obtained? occur one group chose 4 smallest numbers (1,2,3,4), sums 10; group chose 4 biggest numbers (5,6,7,8), sums 26. Therefore, largest possible difference 26-10 = 16.largest difference observed possible_differences vector? Checks , ’s good.Let’s now answer specific questions. probability difference group sums larger 16? just determined impossible, can confidently say 0.probability absolute value difference group sums larger 10?First, convert differences positive values:figure many differences larger 10, divide total possible outcomes:","code":"\nexample_outcome <- data.frame(group = rep(c(\"A\",\"B\"),each=4),\n                              person = c(1,2,3,4,1,2,3,4),\n                              ball = sample(1:8)\n)\nknitr::kable(example_outcome)\nlibrary(combinat)\npermutation_matrix <- matrix(unlist(permn(1:8)), ncol=8, byrow=TRUE)\ngroup_A_sums <- rowSums(permutation_matrix[,1:4])\ngroup_B_sums <- rowSums(permutation_matrix[,5:8])\npossible_differences <- group_A_sums - group_B_sums\nhist(possible_differences)\nmax(possible_differences)\n#> [1] 16\npossible_differences[possible_differences > 16]\n#> numeric(0)\nabsolute_differences <- abs(possible_differences)\nlength(absolute_differences[absolute_differences > 10])/length(absolute_differences)\n#> [1] 0.1142857"},{"path":"statistical-inference.html","id":"interim-summary-general-principles","chapter":"6 Statistical Inference","heading":"6.3.3 Interim Summary: General Principles","text":"permutation test :obtain data different conditionspermute data across conditions produce possible outcomes, ways data obtained across conditionsCalculate odds specific data patterns (subset permutations) occurred relative possible permutations.generally, obtain data specific case example. “happen”. interested “happened”, generate possible outcomes. compare summary happen, happened. learn exercise? current example, learn chance can produce differences various sizes.","code":""},{"path":"statistical-inference.html","id":"permutation-test-on-experimental-data.","chapter":"6 Statistical Inference","heading":"6.3.4 Permutation test on experimental data.","text":"Consider experiment conducted two groups B. 8 total participants, randomly assigned groups. Group received 1 million dollars motivation well midterm. Group B received 0 dollars. groups took midterm. mean performance subject group 85, 75, 76, 89. mean performance subject Group B 90, 65, 68, 69.Overall mean group :, mean group B :, group , got million dollars, average better midterm group B. difference 81.25 - 73 = 8.25.","code":"\ngroup_A <- c(85,75,76,89)\ngroup_B <- c(90,65,68,69)\nmean(group_A)\n#> [1] 81.25\nmean(group_B)\n#> [1] 73\nmean(group_A) - mean(group_B)\n#> [1] 8.25"},{"path":"statistical-inference.html","id":"what-caused-the-difference","chapter":"6 Statistical Inference","heading":"6.3.4.1 What caused the difference?","text":"experimental manipulation cause difference? giving group one million dollars cause somehow better test? consider one possibility.possibilities? kind process caused pattern numbers observed? Another possible explanation random sampling, assigned participants groups. possible group randomly participants prepared test.","code":""},{"path":"statistical-inference.html","id":"assessing-chance-with-a-permutation-test","chapter":"6 Statistical Inference","heading":"6.3.4.2 Assessing chance with a permutation test","text":"can use permutation test assess possible ways participants scores assigned groups. can calculate possible group differences observed. can compare group difference observe (8.25), group differences observed. let us know random sampling process likely unlikely produce difference.possible_differences vector contains possible mean differences produced random sampling. Let’s compare observed. two ways.histogram shows possible differences obtained randomly sampling participants different groups. red line shows difference obtained. facts example.like think “distribution possible differences” window opportunity chance. , looking differences data produced chance. also see values occur often others. example, red line, observed difference 8.25 1) inside distribution, means chance produced difference, 2) kind far left, seems chance doesn’t produce difference big often.precise calculate odds getting difference 8.25 larger, find 11.4%.…return cartoon character metaphor, dunnit question. Mickey Mouse million dollars caused difference 8.25? Donald Duck random chance accidentally produced difference 8.25? know Mr. Duck produces difference 8.25 larger 10% time…enough say Mr. Duck ? don’t think . clearly done . Can absolutely certain million dollar manipulation? . learned anything useful ? think , seems got result irregular perspective chance. might give confidence experimental manipulation actually caused difference, act randomly assigning participants groups.just chance, expect experiment wouldn’t replicate, average wouldn’t big differences groups. hand, replications showed big difference , confident manipulation caused difference.","code":"\n# put all means in a variable\nall_scores <- c(group_A,group_B) \n\n# generate permutation matrix\npermutation_matrix <- matrix(unlist(permn(all_scores)), ncol=8, byrow=TRUE)\n\n# calculate overall group means for each permutation\ngroup_A_means <- rowSums(permutation_matrix[,1:4])/4\ngroup_B_means <- rowSums(permutation_matrix[,5:8])/4\n\n# generate all possible differences\npossible_differences <- group_A_means - group_B_means\n# visualize the analysis\n\nlibrary(ggplot2)\n\nqplot(possible_differences)+\n  geom_histogram(color=\"orange\")+\n  geom_vline(xintercept=mean(group_A) - mean(group_B), color =\"red\")+\n  theme_classic()\nlength(possible_differences[possible_differences >= 8.25]) / length(possible_differences)\n#> [1] 0.1142857"},{"path":"statistical-inference.html","id":"c2-randomization-test","chapter":"6 Statistical Inference","heading":"6.4 C2: Randomization test","text":"randomization test version permutation test can used number permutations large impractical generate. example, previous toy example 8 means, permuting across two groups required generating 40320 sequences. hundreds thousands subjects, computer quickly loose memory capacity generate possible permutations. Instead, randomly sample possible permutations, create sampling distribution, use become informed happened chance.Imagine 50 subjects group B. Let’s generate fake scores participant. Let’s also imagine experiment manipulation actually WORK. , pretend scores participant coming distribution, let’s say normal distribution mean = 65 sd = 10.can calculate mean group, look difference.general sense manipulation works, causes difference, expect see non-zero difference. manipulation ineffective nothing, expect average difference, however recognize obtain differences just chance alone, randomly sampling participants different groups.now want calculate sampling distribution possible mean differences. , take values Group B, randomly re-assign across groups, recalculate means mean difference. , multiple times, monte-carlo simulation.Now can plot mean differences get sense kinds differences chance produced, red line shows particular mean difference observed toy example.histogram “sampling distribution mean differences”, shows kinds differences group group B obtained purely randomly assigning people different groups.terms detective novel, chances alibi, shows chance capable . situation, chance alone easily produce differences group B large 4 -4. Notice, chance never produces difference large 20. information example, researcher attempt rule possibility chance involved producing difference observed.can also use distribution calculate specific probabilities concerning chance. example, probability getting 4 larger chance alone?","code":"\ngroup_A <- rnorm(50,65,10)\ngroup_B <- rnorm(50,65,10)\nmean(group_A)\n#> [1] 63.80599\nmean(group_B)\n#> [1] 65.03299\nmean(group_A)-mean(group_B)\n#> [1] -1.226997\n# creating one random permutation\nall_scores <- c(group_A,group_B)\nresample <- sample(all_scores)\nnew_A_mean <- mean(resample[1:50])\nnew_B_mean <- mean(resample[51:100])\nnew_difference <- new_A_mean-new_B_mean\nnew_difference\n#> [1] -1.647882\n\n# Simulate the above process 10000 times\nmean_differences <- c()\nfor(i in 1:10000){\n  resample <- sample(all_scores)\n  new_A_mean <- mean(resample[1:50])\n  new_B_mean <- mean(resample[51:100])\n  mean_differences[i] <- new_A_mean-new_B_mean\n}\nqplot(mean_differences)+\n  geom_histogram(color=\"orange\")+\n  geom_vline(xintercept=mean(group_A) - mean(group_B), color =\"red\")+\n  theme_classic()\nlength(mean_differences[mean_differences >=4 ])/length(mean_differences)\n#> [1] 0.0258"},{"path":"statistical-inference.html","id":"p1-randomization-test-with-real-data","chapter":"6 Statistical Inference","heading":"6.5 P1: Randomization test with real data","text":"Randomization tests flexible can constructed experiments. simply involve:randomizing data across conditionscalculating statistic interestDo thousands times create sampling distribution statistic interestCompare observed statistic interest (e.g., difference group means) sampling distribution determine observed statistic ) likely produced random sampling, B) unlikely produced random samplingHere construct randomization test experiment asking question…come across smarter (interview) evaluators get hear say, get read say.can learn experiment : https://crumplab.github.io/statisticsLab/lab-7-t-test-independent-sample.html. link lab manual gives example conducting t-test, something discuss later labs. use data experiment, contained ‘open_data’ folder, titled, SchroederEpley2015data.csv, conduct randomization test.Note condition code 1 refers audio group, 0 refers reading group.can see audio group (1) received higher intellect ratings (5.63) read group (0), 3.64. difference, effect 2.difference result occurred randomly assigning people different groups? Let’s randomization test create sampling distribution possible mean differences.Now look sampling distribution possible differences, compare observed difference 2, happened:can concluded exercise? conclude experimental manipulation actually caused difference Intellect ratings? conclude chance produce difference?’m bit conservative can concluded. say exercise producing sampling distribution differences useful. gives pretty good sense kinds differences chance alone produce. shows difference 2 rarely produced chance alone. gives confidence rule chance candidate. words, really think chance great alibi, wouldn’t produced pattern data often. time, , just often…, can confident, completely sure chance didn’t .experimental manipulation…wasn’t chance caused difference, necessarily case manipulation caused difference? like saying Donald Duck cause difference, therefore manipulation cause difference. makes sense. Instead, sure, manipulation caused difference, also maybe confounds addressed caused difference. Ruling chance doesn’t tell caused difference, just suggests difference wasn’t caused chance.","code":"\n#load the data\nthe_data <- read.csv(\"open_data/SchroederEpley2015data.csv\", header = TRUE)\n\n# compute the group means\nlibrary(dplyr)\n\nthe_data %>% \n  group_by(CONDITION) %>%\n  summarize(group_means = mean(Intellect_Rating))\n#> # A tibble: 2 x 2\n#>   CONDITION group_means\n#>       <int>       <dbl>\n#> 1         0        3.65\n#> 2         1        5.63\n# restrict the dataset to the columns of interest\nsimulation_data <- the_data %>%\n  select(CONDITION,Intellect_Rating)\n\n# example of randomizing the scores across conditions\nsimulation_data %>%\n  mutate(Intellect_Rating = sample(Intellect_Rating))\n#>    CONDITION Intellect_Rating\n#> 1          1        4.6666667\n#> 2          1        3.3333333\n#> 3          1        5.6666667\n#> 4          0        6.0000000\n#> 5          0        9.0000000\n#> 6          0        5.6666667\n#> 7          1        5.0000000\n#> 8          0        6.0000000\n#> 9          1        1.6666667\n#> 10         0        3.6666667\n#> 11         0        6.6666667\n#> 12         1        6.0000000\n#> 13         1        5.6666667\n#> 14         0        3.6666667\n#> 15         0        5.0000000\n#> 16         1        4.6666667\n#> 17         1        5.6666667\n#> 18         1        7.0000000\n#> 19         0        2.3333333\n#> 20         0        4.6666667\n#> 21         0        3.6666667\n#> 22         0        3.3333333\n#> 23         0        6.3333333\n#> 24         1        6.6666667\n#> 25         1        5.0000000\n#> 26         1        9.0000000\n#> 27         0        3.6666667\n#> 28         1        1.0000000\n#> 29         1        3.3333333\n#> 30         1        1.6666667\n#> 31         0        4.6666667\n#> 32         0        6.0000000\n#> 33         1        7.6666667\n#> 34         1        3.6666667\n#> 35         0        0.6666667\n#> 36         1        2.3333333\n#> 37         0        2.0000000\n#> 38         1        5.3333333\n#> 39         1        6.0000000\n\n# example of calculating a new mean difference\n\nnew_data <- simulation_data %>%\n  mutate(Intellect_Rating = sample(Intellect_Rating)) %>%\n  group_by(CONDITION) %>%\n  summarize(new_means = mean(Intellect_Rating), .groups=\"drop\")\n\nnew_data\n#> # A tibble: 2 x 2\n#>   CONDITION new_means\n#>       <int>     <dbl>\n#> 1         0      5.13\n#> 2         1      4.37\nnew_data[new_data$CONDITION == 0,]$new_means\n#> [1] 5.12963\nnew_data[new_data$CONDITION == 1,]$new_means\n#> [1] 4.365079\nnew_difference <- new_data[new_data$CONDITION == 1,]$new_means-new_data[new_data$CONDITION == 0,]$new_means\n\n# Run a randomization test\n\npossible_differences <-c()\nfor(i in 1:1000){\n  # permute the data and calculate new means\n  new_data <- simulation_data %>%\n    mutate(Intellect_Rating = sample(Intellect_Rating)) %>%\n    group_by(CONDITION) %>%\n    summarize(new_means = mean(Intellect_Rating), .groups='drop')\n  \n  # calculate and save mean difference\n  possible_differences[i] <- new_data[new_data$CONDITION == 1,]$new_means-new_data[new_data$CONDITION == 0,]$new_means\n}\nqplot(possible_differences)+\n  geom_histogram(color=\"orange\")+\n  geom_vline(xintercept=2, color =\"red\")+\n  theme_classic()\nlength(possible_differences[possible_differences >= 2]) / length(possible_differences)\n#> [1] 0.001"},{"path":"statistical-inference.html","id":"some-coding-alternatives","chapter":"6 Statistical Inference","heading":"6.5.1 Some coding alternatives","text":"script randomization test written many different ways. additional example:","code":"\n#load the data\nthe_data <- read.csv(\"open_data/SchroederEpley2015data.csv\", header = TRUE)\n\n# compute the group means\nthe_data %>% \n  group_by(CONDITION) %>%\n  summarize(group_means = mean(Intellect_Rating))\n#> # A tibble: 2 x 2\n#>   CONDITION group_means\n#>       <int>       <dbl>\n#> 1         0        3.65\n#> 2         1        5.63\n\n# how many participants per group?\ntable(the_data$CONDITION)\n#> \n#>  0  1 \n#> 18 21\n\n# create permutations\nmean_differences <- c()\nfor(i in 1:10000){\n  resample <- sample(the_data$Intellect_Rating)\n  new_1_mean <- mean(resample[1:18])\n  new_0_mean <- mean(resample[19:39])\n  mean_differences[i] <- new_1_mean-new_0_mean\n}\n\n#plot\nqplot(mean_differences)+\n  geom_histogram(color=\"orange\")+\n  geom_vline(xintercept=2, color =\"red\")+\n  theme_classic()"},{"path":"statistical-inference.html","id":"lab-6-generalization-assignment","chapter":"6 Statistical Inference","heading":"6.6 Lab 6 Generalization Assignment","text":"","code":""},{"path":"statistical-inference.html","id":"instructions-5","chapter":"6 Statistical Inference","heading":"6.6.1 Instructions","text":"general, labs present discussion problems issues example code like , students tasked completing generalization assignments, showing can work concepts tools independently.assignment instructions following:Work inside R project “StatsLab1” usingCreate new R Markdown document called “Lab6.Rmd”Use Lab6.Rmd show work attempting solve following generalization problems. Commit work regularly appears Github repository.problem, make note much problem believe can solve independently without help. example, needed watch help video unable solve problem without copying answers, note 0. confident can complete problem scratch completely , note 100. OK 0s 100s anything .Submit github repository link Lab 6 blackboard.one problem solve","code":""},{"path":"statistical-inference.html","id":"problems-5","chapter":"6 Statistical Inference","heading":"6.6.2 Problems","text":"Write function conducts randomization test mean difference two groups, show works. Specifically, using function, conduct randomization test data used example lab. Report results briefly discuss results randomization tell . (6 points). Extra: observed mean difference experiment found .5, concluded randomization test?Inputs:inputs include vector group 1, vector group 2, number permutations/re-samplings data create.Outputs:output group mean, difference group meansoutput histogram sampling distribution possible mean differences produced randomization processoutput probability odds obtaining observed mean difference larger.Optional:include ability calculate probability obtaining mean difference largerdeal negative difference scores appropriatelyadd one two-tailed test options","code":""},{"path":"binomial-test.html","id":"binomial-test","chapter":"7 Binomial Test","heading":"7 Binomial Test","text":"“10/8/2020 | Last Compiled: 2020-12-09”Extraordinary claims require extraordinary evidence (ECREE) - Carl Sagan","code":""},{"path":"binomial-test.html","id":"readings-1","chapter":"7 Binomial Test","heading":"7.1 Readings","text":"Vokey & Allen (2018), Chapter 11; Abdi et al. (2009), appendix D E binomial test.Imagine wise pigeon can ask Yes question. ask question. pigeon responds pecking Yes . many answers pigeon need get correct row willing believe pigeon knew correct answer every question?someone claimed magical wise pigeon knew answer every Yes question, put test? many questions ask, satisfied extraordinary claim TRUE FALSE?can consider kinds questions perspective binomial test. , happens, binomial tests often used pigeons real research. example, pigeons excellent classifying visual patterns different categories, binomial tests often used part process establishing pigeon actually possesses visual skill/ability make discrimination, simply getting lucky.","code":""},{"path":"binomial-test.html","id":"overview-6","chapter":"7 Binomial Test","heading":"7.2 Overview","text":"Practical : Conducting binomial test RConcepts : Binomial model foundationsConcepts II: Task design binomial models","code":""},{"path":"binomial-test.html","id":"practical-i-conducting-a-binomial-test-in-r","chapter":"7 Binomial Test","heading":"7.3 Practical I: Conducting a binomial test in R","text":"already conducted binomial tests R previous labs discussed coin flipping examples. However, use language binomial test. practical example, go couple different ways conduct binomial test R.","code":""},{"path":"binomial-test.html","id":"classification-performance-example","chapter":"7 Binomial Test","heading":"7.3.1 Classification performance example","text":"Binomial tests commonly used situations researcher wants know whether subject guessing, truly able perform task. example, comparative cognition, pigeon researcher might ask whether pigeon can discriminate different classes visual stimuli, red vs. green, circles vs. squares, buildings vs. trees.Imagine pigeon given 2AFC task (two-alternative forced-choice task) discriminate pictures circular shapes angular shapes. trial pigeon shown two pictures, one circular one angular. rewarded correctly peck circular shape.Pigeon received 100 trials, pecked correct circular shape 65% trials. can conduct report binomial test follows, using binom.test() function.researcher might report results binomial test way:Pigeon 65% correct (p < .05, binomial test).Pigeon 65% (p <= .0018, binomial test).also possible embed results binomial test text .Rmd document. First, save results variable:, now possible write:Pigeon 65% correct (p <= 0.0017588)","code":"\n?binom.test\nbinom.test(x = 65,\n           n = 100,\n           p = .5,\n           alternative='greater')\n#> \n#>  Exact binomial test\n#> \n#> data:  65 and 100\n#> number of successes = 65, number of trials = 100, p-value = 0.001759\n#> alternative hypothesis: true probability of success is greater than 0.5\n#> 95 percent confidence interval:\n#>  0.5639164 1.0000000\n#> sample estimates:\n#> probability of success \n#>                   0.65\ntest_results <- binom.test(x = 65,\n           n = 100,\n           p =.5,\n           alternative='greater')\n\ntest_results$p.value\n#> [1] 0.001758821\n\n# values can embedded using `r test_results$p.value`"},{"path":"binomial-test.html","id":"examining-the-report","chapter":"7 Binomial Test","heading":"7.3.2 Examining the report:","text":"binom.test() function returns printout inputs (number successes, number trials), importantly, returns p-value. p-value refers probability. However, precise meaning p-value depends alternative = c(\"two.sided\", \"less\", \"greater\") input.focus “less”, “greater” options, “two.sided” contentious (multiple interpretations /whether two-sided tests done).now, also ignore alternative hypothesis confidence interval sections. view neither outputs part binomial test.","code":"Exact binomial test\n\ndata:  65 and 100\nnumber of successes = 65, number of trials = 100,\np-value = 0.001759\nalternative hypothesis: true probability of success is greater than 0.5\n95 percent confidence interval:\n 0.5639164 1.0000000\nsample estimates:\nprobability of success \n                  0.65 "},{"path":"binomial-test.html","id":"what-can-we-conclude","chapter":"7 Binomial Test","heading":"7.3.3 What can we conclude?","text":"example, chose alternative= \"greater\", found p-value 0.001759. mean?Officially, probability 50/50 binomial process produce 65 successes 100 chance p = .001759. specifically, 50/50 binomial process one 50% chance success, 50% chance failure. just like coin flipping examples, except using success failure two possible outcomes instead heads tails.","code":""},{"path":"binomial-test.html","id":"what-does-this-have-to-do-with-the-pigeon","chapter":"7 Binomial Test","heading":"7.3.4 What does this have to do with the pigeon","text":"Remember research example. pigeon chose correct shape 65/100 times. can say pigeon? ability classify circular shapes angular shapes? “answer” question binomial test, using “compared ” strategy. Clearly pigeon perfectly good discrimination, otherwise pigeon got 100%. compared chance?chance ? Imagine removed pigeon entirely, replaced pigeon coin. trial flip coin choose one two shapes. Clearly, coin “knows nothing shapes”, coins “choices” “random guesses”. coin flip capable ? coin get 65/100 correct?binomial test tells us something coin done. answer pigeon. learned binomial process (coin), capable producing 65/100 greater small probability (.001759).","code":""},{"path":"binomial-test.html","id":"facts-and-inferences","chapter":"7 Binomial Test","heading":"7.3.5 Facts and Inferences","text":"example facts. pigeon got 65/100 correct. coin-flipping process get 65 heads 100 small probability .001759.facts, engage inferences attempting relate behavior pigeon coin. example, say unlikely 65% correct explained chance. gives confidence pigeon wasn’t just guessing. Just guessing wouldn’t well pigeon often. information go , probably also bet pigeon similar level performance, even better given another 100 trials.","code":""},{"path":"binomial-test.html","id":"concepts-i-binomial-model-foundations","chapter":"7 Binomial Test","heading":"7.4 Concepts I: Binomial model foundations","text":"Although can use binom.test() function conduct binomial test, can also use family binom functions already come across occasionally.example, 100 trials, limited number possible outcomes. 0 successes way 100 successes. ’s . model terms 50% success/failure, histogram shows binomial distribution situation:return example, probability getting 65 successes?probability binom.test() returned.","code":"\nlibrary(ggplot2)\nqplot(y=dbinom(0:100,100,.5))+\n  geom_bar(stat='identity',position=\"dodge\")+\n  ylab('density')+\n  xlab('# of successes')\nsum(dbinom(0:100,100,.5))\n#> [1] 1\nsum(dbinom(65:100,100,.5))\n#> [1] 0.001758821"},{"path":"binomial-test.html","id":"the-test-and-the-model","chapter":"7 Binomial Test","heading":"7.4.1 The test and the model","text":"binomial test often conducted make inferences data point. , example, flipped coin 10 times got 7 heads 10. binomial test :, p-value :worth recognizing example scratches surface full binomial model. example, 11 possible outcomes, 0 heads 10 heads. outcomes ’s probability. table shows probabilities possible outcomes:consider value thinking full model next section.","code":"\nsum(dbinom(7:10,10,.5))\n#> [1] 0.171875\nbinom.test(x=7,n=10,alternative=\"greater\")\n#> \n#>  Exact binomial test\n#> \n#> data:  7 and 10\n#> number of successes = 7, number of trials = 10, p-value = 0.1719\n#> alternative hypothesis: true probability of success is greater than 0.5\n#> 95 percent confidence interval:\n#>  0.3933758 1.0000000\n#> sample estimates:\n#> probability of success \n#>                    0.7\ncoin_flips <- data.frame( number_of_heads = 0:10,\n                          probability = dbinom(x=0:10,size=10,prob= .5),\n                          cumulative = pbinom(0:10, size = 10, prob = .5),\n                          rev_cumulative = pbinom(-1:9, 10, .5, lower.tail=FALSE))\nknitr::kable(coin_flips)"},{"path":"binomial-test.html","id":"concepts-ii-task-design-and-binomial-models","chapter":"7 Binomial Test","heading":"7.5 Concepts II: Task design and binomial models","text":"Consider . appropriate conduct binomial test, situation consideration can described binomial process. words, possible describe possible outcomes experiment conducting .example, pigeon experiment, 100 trials. trial involved decision correct incorrect. , 101 total possible outcomes (0/100 100/100 correct). possibilities defined design task. 10 trials experiment, 11 possible outcomes.matter? relationship task design statistical model can greatly influence kinds inferences researcher comfortable making data. , recognizing connection allows researcher design experiment allow strong inferences first place.example, showed pigeon truck car told peck truck. correctly pecked truck. 1 trial experiment, 50% chance correct. claim pigeon can tell difference cars trucks based evidence? , 100% correct.point 100% correct good enough evidence 1 trial experiment. obvious chance get 100% correct 50% time, pigeon easily “guessing”.pigeon correctly chose truck 100% time 10 different choices, start think maybe pigeon “knows” something. know unlikely get “10---row” chance.","code":""},{"path":"binomial-test.html","id":"setting-task-parameters","chapter":"7 Binomial Test","heading":"7.5.1 Setting task parameters","text":"costs benefits changing task design. costs include longer experiment takes time resources run. benefits include confident measuring “non-chance” phenomena.designing task evaluate subject making correct incorrect decisions, many trials want experiment? possibilities:keep listing tables increasing number trials 1 time. , time generate another binomial model. tables represent possible outcomes different designs, well probabilities outcomes occur chance. general rule thumb number trials increase, range possible outcomes chance narrows toward 50% successes 50% failures.Consider value close 50%, like 51%. found participant performed 51% might want say level performance easily obtained chance. However, inference strongly depends number trials.example, 100 trials, probability getting 51% correct greater pretty good.However, 1000 trials…10,000 trials…","code":"\n# 1 trial\ntask_designs <- data.frame( number_of_heads = 0:1,\n                          probability = dbinom(x=0:1,size=1,prob= .5),\n                          cumulative = pbinom(0:1, size = 1, prob = .5),\n                          rev_cumulative = pbinom(-1:0, 1, .5, lower.tail=FALSE))\nknitr::kable(task_designs)\n\n# 2 trials\ntask_designs <- data.frame( number_of_heads = 0:2,\n                          probability = dbinom(x=0:2,size=2,prob= .5),\n                          cumulative = pbinom(0:2, size = 2, prob = .5),\n                          rev_cumulative = pbinom(-1:1, 2, .5, lower.tail=FALSE))\nknitr::kable(task_designs)\n\n# 3 trials\ntask_designs <- data.frame( number_of_heads = 0:3,\n                          probability = dbinom(x=0:3,size=3,prob= .5),\n                          cumulative = pbinom(0:3, size = 3, prob = .5),\n                          rev_cumulative = pbinom(-1:2, 2, .5, lower.tail=FALSE))\nknitr::kable(task_designs)\n\n# etc...\nbinom.test(51,100,.5,alternative=\"greater\")\n#> \n#>  Exact binomial test\n#> \n#> data:  51 and 100\n#> number of successes = 51, number of trials = 100, p-value = 0.4602\n#> alternative hypothesis: true probability of success is greater than 0.5\n#> 95 percent confidence interval:\n#>  0.4234107 1.0000000\n#> sample estimates:\n#> probability of success \n#>                   0.51\nbinom.test(510,1000,.5,alternative=\"greater\")\n#> \n#>  Exact binomial test\n#> \n#> data:  510 and 1000\n#> number of successes = 510, number of trials = 1000, p-value = 0.274\n#> alternative hypothesis: true probability of success is greater than 0.5\n#> 95 percent confidence interval:\n#>  0.4835011 1.0000000\n#> sample estimates:\n#> probability of success \n#>                   0.51\nbinom.test(5100,10000,.5,alternative=\"greater\")\n#> \n#>  Exact binomial test\n#> \n#> data:  5100 and 10000\n#> number of successes = 5100, number of trials = 10000, p-value = 0.02329\n#> alternative hypothesis: true probability of success is greater than 0.5\n#> 95 percent confidence interval:\n#>  0.501726 1.000000\n#> sample estimates:\n#> probability of success \n#>                   0.51"},{"path":"binomial-test.html","id":"lab-7-generalization-assignment","chapter":"7 Binomial Test","heading":"7.6 Lab 7 Generalization Assignment","text":"","code":""},{"path":"binomial-test.html","id":"instructions-6","chapter":"7 Binomial Test","heading":"7.6.1 Instructions","text":"general, labs present discussion problems issues example code like , students tasked completing generalization assignments, showing can work concepts tools independently.assignment instructions following:Work inside R project “StatsLab1” usingCreate new R Markdown document called “Lab7.Rmd”Use Lab7.Rmd show work attempting solve following generalization problems. Commit work regularly appears Github repository.problem, make note much problem believe can solve independently without help. example, needed watch help video unable solve problem without copying answers, note 0. confident can complete problem scratch completely , note 100. OK 0s 100s anything .Submit github repository link Lab 7 blackboard.","code":""},{"path":"binomial-test.html","id":"problems-6","chapter":"7 Binomial Test","heading":"7.6.2 Problems","text":"test-taker answered 50 true/false questions received score 60% correct. Report results binomial test explain whether think test-score produced test-taker randomly guessing question. (2 points)test-taker answered 50 true/false questions received score 60% correct. Report results binomial test explain whether think test-score produced test-taker randomly guessing question. (2 points)examiner wants make TRUE/FALSE test, still deciding many questions include. want make sure difficult simply randomly guess able score higher 55% percent. many questions examiner need use confident scores 55% higher produced chance? (2 points)examiner wants make TRUE/FALSE test, still deciding many questions include. want make sure difficult simply randomly guess able score higher 55% percent. many questions examiner need use confident scores 55% higher produced chance? (2 points)test 5 TRUE/FALSE questions (one right answer) 5 multiple choice questions four choices (one right answer).test 5 TRUE/FALSE questions (one right answer) 5 multiple choice questions four choices (one right answer).create sampling distribution probability distribution illustrate random chance process perform test. (1 point)probability randomly guessing question allow person receive 75% greater test? (1 point)","code":""},{"path":"z-tests.html","id":"z-tests","chapter":"8 Z tests","heading":"8 Z tests","text":"“10/8/2020 | Last Compiled: 2020-12-09”","code":""},{"path":"z-tests.html","id":"reading-3","chapter":"8 Z tests","heading":"8.1 Reading","text":"Vokey & Allen (2018), Chapter 12; Abdi et al. (2009) Appendix D","code":""},{"path":"z-tests.html","id":"overview-7","chapter":"8 Z tests","heading":"8.2 Overview","text":"ReviewPractical : Z-scoresConcept : Central Limit TheoremPractical II: Z-tests","code":""},{"path":"z-tests.html","id":"review-and-reminder","chapter":"8 Z tests","heading":"8.3 Review and Reminder","text":"previous labs introduced concepts 1) normal distribution 2) sampling distributions. relate concepts . Specifically, central limit theorem shows sampling distributions mean generally shape normal distribution. result, properties normal distributions can substituted properties sampling distributions process statistical inference.Normal distributions assumptions routinely appear across many remaining statistical tests (e.g., t-tests, ANOVAs, linear regression, etc.) discussed across course. , important comfortable basic properties normal distribution.example, reminder, normal distribution two parameters, mean standard deviation. example, formula normal distribution (probability density function) :\\(f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-u}{\\sigma})^2}\\), two free parameters \\(u\\) (mean), \\(sigma\\) (standard deviation). calculating probability density particular score using formula R, show answer dnorm().second reminder normal distributions shape. important understand “shape” means. Let’s look two different normal distributions. first one mean = 0, sd = 1. second mean = 25, sd = 5. two graphs appear show different shapes, first taller narrower second.However, x-axes different graphs. allow x-axes vary freely, can “zoom” distribution way, now see:, distributions similar shape, “seemingly” exactly shape…second one shorter spread . Nevertheless, shape still EXACTLY , one important way. Specifically, probability getting scores particular ranges, expressed standard deviations, .probability distribution functions, area curve represents possible outcomes. , area curve range values (relative total area), represents probability observing values range. crucial point look comparable ranges standard deviations normal distribution, always get probabilities.example, consider range 1 2 first graph (mean = 0, sd = 1). comparable range 30 35 second graph (mean = 25, sd =5). represent interval 1 2 standard deviations. interval shaded red .\ncalculate area shaded regions relative total area properly perform integration. However, let’s skip part, something quick R. example, sum numbers two vectors first_one second_one, approximate “total area”. , vector, sum numbers (probability density values) range. divide sums approximate probability, check see .values approximate values pnorm() function.","code":"\nx <- 1\nu <- 0\nsigma <- 1\n\n1/(sigma*sqrt(2*pi)) * exp(1)^(-.5*((x-u)/sigma)^2)\n#> [1] 0.2419707\n\ndnorm(1,0,1)\n#> [1] 0.2419707\nfirst_one <- dnorm(seq(-4,4,length.out=100),0,1)\nsecond_one <- dnorm(seq(5,45,length.out=100),25,5) \n\nplot_df <- data.frame(score=c(first_one,second_one),\n                      x = c(seq(-4,4,length.out=100),seq(5,45,length.out=100)),\n                      zscore = c(seq(-4,4,length.out=100),(seq(5,45,length.out=100)-25)/5),\n                      dist = rep(c(\"first\",\"second\"),each=100))\n  \nlibrary(ggplot2)\n\nggplot(plot_df, aes(y=score,x=x))+\n  geom_line()+\n  facet_wrap(~dist)\nggplot(plot_df, aes(y=score,x=x))+\n  geom_line()+\n  facet_wrap(~dist, scales=\"free_x\")\nlibrary(dplyr)\nggplot(plot_df, aes(y=score,x=x))+\n  geom_line()+\n  facet_wrap(~dist, scales=\"free_x\")+\n  geom_ribbon(data = plot_df %>%filter(zscore >= 1,\n                                       zscore <= 2),\n              fill = \"red\",\n              aes(ymin=0,ymax=score))\nlibrary(dplyr)\n\nplot_df %>%\n  filter(dist == \"first\",\n         x > 1,\n         x <= 2) %>%\n  select(score) %>%\n  sum()/sum(first_one)\n#> [1] 0.1443879\n\nplot_df %>%\n  filter(dist == \"second\",\n         x > 30,\n         x <= 35) %>%\n  select(score) %>%\n  sum()/sum(second_one)\n#> [1] 0.1443879\npnorm(2,0,1) - pnorm(1,0,1)\n#> [1] 0.1359051\n\npnorm(35,25,5)- pnorm(30,25,5)\n#> [1] 0.1359051"},{"path":"z-tests.html","id":"convenience","chapter":"8 Z tests","heading":"8.3.1 Convenience","text":"heading main part lab ’ll suggest convenience often important statistics. real life, uncommon people use tools convenient use. normal distribution number conveniences, one reason widely used. can use concept convenience gauge understanding normal distributions. example, understand normal distributions able explain least reasons distributions convenient use.one convenience. described normal distributions shape. also looked “special” version normal, called unit normal, also called standard normal, z-distribution. defined normal distribution mean = 0 , sd = 1. unit normal can convenient quick estimation. see , let’s turn first practical section lab, z-scores.","code":""},{"path":"z-tests.html","id":"practical-i-z-scores","chapter":"8 Z tests","heading":"8.4 Practical I: z-scores","text":"Let admit often confused metric system imperial system, partly grew Canada live USA, also systems used inconsistently personal experience. example, even though grew metric system, know weight pounds, kilograms. Also, know height feet inches, meters. Temperature even confusing. ’m good cold temperatures celsius, use Fahrenheit hot temperatures. ’m still better kilometers miles. Oh well.","code":""},{"path":"z-tests.html","id":"linear-transformation","chapter":"8 Z tests","heading":"8.4.1 Linear Transformation","text":"bring issues differences metric imperial essentially inconsequential. matter whether use Celsius Fahrenheit, temperature measured . Similarly, distance two cities matter whether use miles kilometers. difference measurement scale. case, differences linear transformations , means one scale shifted constant amount relative scale.example, formula translate celsius fahrenheit :\\(F = C * 9/5 + 32\\)can use formula draw graph relating different values Celsius, different values Fahrenheit. “transform” Celsius values multiplying constant (9/5), adding constant (32), therefore relationship linear.Z-scores express raw scores normal distribution terms far away mean standard deviation units.Z-scores linear transformations. convert raw values normal distribution “unit normal” distribution. conversion like transformation Celsius Fahrenheit, nothing lost conversion, values refer underlying quantity.z-score transformation :\\(z_i = \\frac{x_i - u}{\\sigma}\\) \\(z_i = \\frac{\\text{score} - \\text{mean}}{\\text{standard deviation}}\\)two important transformations formula. subtraction centers scores mean. division expresses scores terms common unit (sometimes z-scores also called standard scores, “standardized”, case “standard deviation”).elaborate, top part formula centers scores around mean. mean normal distribution 25, sampled score 25, z-score 0 (25-25 = 0). indicates score deviate mean, score case mean (deviates 0 mean).score 30? score 30 5 mean (30-25 = 5). score 10 -15 mean. centering transformation causes values mean receive negative z-score, values mean positive z-score.next step formula divide. already centered scores using mean, division allows centered value brought common frame reference, unit. process also commonly termed “standardizing” “normalizing”. example, example, score 30, know 5 mean 25. However, said nothing standard deviation. 5 mean large deviation? small deviation? depends much spread normal distribution, controlled standard deviation \\(\\sigma\\) parameter normal distribution. standard deviation 1, far away score 30 mean (25)? five standard deviations, far away values distribution. standard deviation 10, far away score 30 mean (25)? .5 standard deviation, fairly close many numbers distribution.Let’s say normal distribution mean = 25, standard deviation = 5. score distribution can converted unit normal distribution 1) subtracting mean, dividing standard deviation. graph x-axis top representing scores raw distribution (centered 25), x axis bottom representing scores unit normal z-distribution.Z-scores convenient know interpret . example, find Fahrenheit convenient use hot temperatures. know 109 degrees Fahrenheit outside, know really hot. honest, don’t good intuitive feeling really hot Celsius. , don’t find Celsius convenient hot temperatures. become convenient got used practice. , already something works, stick (convenience inertia strong forces…).Z-scores can become convenient get used represent. example, statistics textbooks commonly present graph table like following:spend time unit normal distribution, learn basic properties, 95% scores fall -2 +2 standard deviations; 99% scores fall -3 3 standard deviations, 34% scores fall mean one standard deviation. memorized details, whenever three things future…1) score normal distribution, 2) mean, 3) standard deviation…can good intuitions whether score common rare…can convenient (happen interacting normal distributions regular basis).","code":"\n\ncelsius <- seq(-50,50,1)\nfahrenheit <- seq(-50,50,1) * (9/5) + 32\n\nplot_df <- data.frame(celsius,\n                       fahrenheit)\n\nggplot(plot_df, aes(x=celsius,y=fahrenheit))+\n  geom_line()+\n  scale_y_continuous(breaks=seq(-60,140,10))+\n  scale_x_continuous(breaks=seq(-50,50,10))\npdf <- dnorm(seq(-4,4,length.out=100),0,1)\nzscores <- seq(-4,4,length.out=100)\nraw <- zscores*10+100\nplot_df <- data.frame(pdf,\n                      zscores,\n                      raw)\n\nggplot(plot_df,aes(x=zscores,y=pdf))+\n  geom_line()+\n  scale_x_continuous(breaks=c(-4:4), \n                     sec.axis = sec_axis(~ .*5+25, name=\"Raw Scores\",breaks=seq(5,50,5)))\nknitr::include_graphics(\"imgs/norm_zscores.png\")"},{"path":"z-tests.html","id":"conceptual-i-central-limit-theorem","chapter":"8 Z tests","heading":"8.5 Conceptual I: Central Limit Theorem","text":"turns many common statistics rely upon normal distributions, common statistics, frequently use normal distributions. one good reason become familiar basic properties.normal distributions commonly used statistics? think multiple reasons, including convenience (math can done hand), inertia (normals can convenient work , people use , keep using ). However, also fundamental reason stemming central limit theorem.present central limit theorem terms one thing already learned , make grand claim .","code":""},{"path":"z-tests.html","id":"we-already-learned-about-sampling-distributions","chapter":"8 Z tests","heading":"8.5.1 We already learned about sampling distributions","text":"Remember, sampling distribution 1) take multiple samples, 2) calculate statistic like mean sample, 3) look distribution sample statistic, sample statistics look like. important remember statistic compute sample descriptive statistic, like mean, standard deviation, median, whatever want.","code":""},{"path":"z-tests.html","id":"claim-sampling-distributions-of-the-mean-are-normally-distributed","chapter":"8 Z tests","heading":"8.5.2 Claim: sampling distributions of the mean are normally distributed","text":"central limit theorem roughly two parts. main part sampling distributions mean normally distributed. second part “time”. central limit theorem therefore mostly let’s treat sampling distributions mean normal distributions. sampling distributions, especially sampling distributions mean, extremely common fundamental statistical inference, math behind normal distributions well understood, can blame central limit theorem frequency deal normal distributions statistics.","code":""},{"path":"z-tests.html","id":"implication","chapter":"8 Z tests","heading":"8.5.3 Implication","text":"major implication central limit theorem 1) even scores come non-normal distribution, 2) sampling distribution sample means approximately normally distributed.Let’s use R illustrate implication.First, imagine measurement involves taking scores uniform distribution (flat, definitely normal).histogram (sample means) much normal looking compared flat distribution individual scores came . course, done simulation, wonder simulated distribution sample means really approximate normal distribution? raises general question…distribution numbers, suspect normal distribution, can know distribution normal?Instead developing test normality, let’s try something pretty straightforward quick “gut check”. Based learned z-scores, know normal distributions shape. , probability getting score 0 1 standard deviations normal distributions.ask find proportion numbers falling 0 1 standard deviations sampling distribution created…see value pretty close.’ve just done rough checking found sampling distribution mean seems approximately normal (based minimal comparison). relationship often holds, common use math normal distributions work sampling distributions mean.see later, sampling distributions create normal distributions, special property sampling distributions sample means. later tests, look sampling distributions statistics t-statistic, F-statistic. distributed normally, different distributions (t F distributions) used place normal.","code":"\n# parent distribution is a uniform\nraw_scores <- runif(10000,min = 0,100)\nhist(raw_scores)\nsample_means <- replicate(10000,mean(runif(5,0,100)))\nhist(sample_means)\npnorm(1,0,1) - pnorm(0,0,1)\n#> [1] 0.3413447\nto_z <- (sample_means-mean(sample_means))/sd(sample_means)\nlength(to_z[to_z > 0 & to_z < 1])/10000\n#> [1] 0.3361"},{"path":"z-tests.html","id":"conceptual-ii-z-tests","chapter":"8 Z tests","heading":"8.6 Conceptual II: z-tests","text":"central limit theorem, long run, large enough sample-size, many statistical tests converge z-test. see later discussing t-test.z-test can used statistical inference population parameters set sample means 1) known normal, 2) mean standard deviation also known. WARNING: assumptions rarely met, facts rarely known. , z-tests commonly used compared statistical tests, especially psychological research usually impossible know properties “true” distribution measurements come .","code":""},{"path":"z-tests.html","id":"n1-example","chapter":"8 Z tests","heading":"8.6.1 N=1 example","text":"“z-test” “z-scores” N 1. example, know measurement involves sampling score normal distribution, know mean standard deviation distribution. can use knowledge normal distributions determine probability obtaining specified ranges scores.probability obtaining score larger 5 normal distribution mean = 1, sd = 3?","code":"\n# one-tailed\npnorm(5,1,3, lower.tail=FALSE)\n#> [1] 0.09121122\n\n# using zscores\npnorm((5-1)/3,0,1, lower.tail=FALSE)\n#> [1] 0.09121122\n\n# two-tailed\npnorm(5,1,3, lower.tail=FALSE)*2\n#> [1] 0.1824224"},{"path":"z-tests.html","id":"n-1-example","chapter":"8 Z tests","heading":"8.6.2 N > 1 example","text":"Z-tests become complicated sample-size greater 1. example, imagine take 10 scores (n=10) normal distribution mean = 55, sd = 5. kinds things happen ?Let’s focus question sample mean. sample n=10, sample mean ? sample mean 60 strange? can randomly sampling numbers case?first need compute sampling distribution mean, tell us kinds sample means (n=10) observed randomly sampling normal mean =55 sd =5.can estimate simulation:, use analytic formulas “know” (least long). example, expect likely sample mean mean population (remember sample mean unbiased estimator population mean). , mean sampling distribution expected 55.Remember previous lab sampling distributions mentioned “standard deviation sampling distribution sample means standard error mean”. case, standard error mean can computed directly:\\(\\text{SEM} = \\frac{\\sigma}{\\sqrt{N}}\\)\\(\\sigma\\) standard deviation parent population (5), N number observations sample (10). calculate directly, find value similar one found simulation., now found parameters normal distribution actually interested , sampling distribution sample means particular situation. , can z-tests want (using mean sd sampling distribution).probability getting sample mean higher 60, sample n=10, individual scores came normal distribution mean = 55 sd = 5.","code":"\nsample_means <- replicate(10000,mean(rnorm(10,55,5)))\nhist(sample_means)\nmean(sample_means)\n#> [1] 55.00716\nsd(sample_means)\n#> [1] 1.591821\n5/sqrt(10)\n#> [1] 1.581139\n# use mean and sd in pnorm\npnorm(60, 55, 5/sqrt(10), lower.tail=FALSE )\n#> [1] 0.0007827011\n\n# OR, convert to a zscore first\nzscore <- (60-55)/(5/sqrt(10))\npnorm(zscore,0,1, lower.tail = FALSE)\n#> [1] 0.0007827011\n\n# this is similar to what the simulation showed:\nlength(sample_means[sample_means > 60])/10000\n#> [1] 6e-04"},{"path":"z-tests.html","id":"example-3-differences-between-groups","chapter":"8 Z tests","heading":"8.6.3 Example 3: differences between groups","text":"standardized educational test known distributional properties. Average test performance distributed normally. mean normal distribution 55, standard deviation 5.experimenter want determine “special training” can improve test performance. create two groups randomly assign 10 participants group. One group gets TRAINING (control group), another group gets TRAINING.training works expect TRAINING group better TRAINING group averageYou recognize people can get different means test just chance alone.can set standards determine evaluate data? kind evidence convince training worked…caused difference BEYOND CHANCE PRODUCED?answer, least insight question, can answered z-test even conduct experiment.first consider question, “chance ?”. two groups, B, NEITHER received training. experiment, random assignment groups, manipulation plausibly change test scores. randomly put 10 people group , 10 people group B, make take test, measure mean difference group B, can happen chance alone?Let’s simulate sampling distribution mean differences situationWhen assume sample means group B come exact distribution, subtract means group B create sampling distribution mean differences, create null-distribution, null-hypothesis, shows kinds mean differences observed due random sampling. chance experiment. Without getting specific, thought “special training” improve test scores scenario 30%, way outside window, way chance alone (30% BEYOND chance can ). hand, ran experiment found training improved test performance 3%…well, often get difference 3% better chance? answer can found evaluating distribution:According simulation, scores 3% greater occur p <= 0.0899. “one-tailed” test. wanted know often get score large 3% away mean either direction, two-tailed test:two p-values close estimates p-values get z-test. little bit simulation slightly imperfect.z-test real, need observed mean difference two groups. Let’s say 3% difference test. also need mean standard deviation normal distribution 3% difference came . can calculate probability obtaining 3% difference larger chance. IMPORTANTLY, mean standard deviation need null-distribution specific difference two sample means, original parent distribution scores come .know individuals take test, test means come normal distribution mean = 55, sd =5.put 10 people group 10 group B, assume difference groups, expect test scores random samples parent distribution 1.result, expect chance alone, difference mean group mean group (sample size 10), variability.central limit theorem, sampling distribution mean differences shape normal distributionThe mean sampling distribution mean differences 0, average difference two samples taken population 0.standard deviation distribution mean differences? knew value, perform z-test.estimate value simulation calculating standard deviation:turns slightly different analytic formula standard error mean situation:\\(\\text{SEM} = \\frac{\\sqrt{2}\\sigma}{\\sqrt{N}}\\)formula required distribution mean differences subtraction mean group B, n=10. , expected variation changes little bit, account added \\(\\sqrt{2}\\) formula.","code":"\nmean_differences <- replicate(10000,mean(rnorm(10,55,5))-mean(rnorm(10,55,5)))\nhist(mean_differences)\nlength(mean_differences[mean_differences > 3])/10000\n#> [1] 0.0899\nlength(mean_differences[mean_differences > 3 | mean_differences < -3])/10000\n#> [1] 0.1754\nsd(mean_differences)\n#> [1] 2.213127\n(sqrt(2)*5)/sqrt(10)\n#> [1] 2.236068"},{"path":"z-tests.html","id":"doing-the-z-test","chapter":"8 Z tests","heading":"8.6.4 doing the z-test","text":", better 3%, showing group difference least 3% something happens often chance?can see, p-value found z-test basically one found simulation approach.","code":"\n#one-tailed test\nzscore <- (58-55)/((sqrt(2)*5)/sqrt(10))\npnorm(zscore,0,1, lower.tail = FALSE)\n#> [1] 0.08985625"},{"path":"z-tests.html","id":"lab-8-generalization-assignment","chapter":"8 Z tests","heading":"8.7 Lab 8 Generalization Assignment","text":"","code":""},{"path":"z-tests.html","id":"instructions-7","chapter":"8 Z tests","heading":"8.7.1 Instructions","text":"general, labs present discussion problems issues example code like , students tasked completing generalization assignments, showing can work concepts tools independently.assignment instructions following:Work inside R project “StatsLab1” usingCreate new R Markdown document called “Lab8.Rmd”Use Lab8.Rmd show work attempting solve following generalization problems. Commit work regularly appears Github repository.problem, make note much problem believe can solve independently without help. example, needed watch help video unable solve problem without copying answers, note 0. confident can complete problem scratch completely , note 100. OK 0s 100s anything .Submit github repository link Lab 8 blackboard.","code":""},{"path":"z-tests.html","id":"problems-7","chapter":"8 Z tests","heading":"8.7.2 Problems","text":"Write function convert vector raw-scores z-scores. function inputs vector, mean sd normal distribution, return vector zscores. (1 point). Also, demonstrate function works correctly (1 point). make demonstration .Advanced: option function convert raw scores zscores one two ways:using user provided mean standard deviationusing calculated mean standard deviation raw scoresBase R function z-test. Write function accomplish one-sample z-test. Remember, one-sample z test used compare probability obtaining sample mean (larger smaller) came known normal distribution. (2 points).Use z-test function conduct test following. sample 25 scores taken. mean sample 50. sample assumed taken normal distribution mean 40 standard deviation 7. Report one-tailed z-test, examining probability obtaining sample greater 50 situation. Report results, give brief sentence explaining result inference make (2 points).","code":""},{"path":"chi-square.html","id":"chi-square","chapter":"9 Chi Square","heading":"9 Chi Square","text":"“10/8/2020 | Last Compiled: 2020-12-09”","code":""},{"path":"chi-square.html","id":"reading-4","chapter":"9 Chi Square","heading":"9.1 Reading","text":"Vokey & Allen (2018), Chapter 13.","code":""},{"path":"chi-square.html","id":"overview-8","chapter":"9 Chi Square","heading":"9.2 Overview","text":"lab provides conceptual foundation understanding chi square test using R.","code":""},{"path":"chi-square.html","id":"background","chapter":"9 Chi Square","heading":"9.3 Background","text":"","code":""},{"path":"chi-square.html","id":"a-brief-history","chapter":"9 Chi Square","heading":"9.3.1 A brief history","text":"Karl Pearson described chi-square test 1900 (Pearson, 1900). Also see Plackett (1983) additional context development test. Relatedly, Pearson undeniably large impact discipline statistics; although socio-historical account beyond scope lab, worth pointing Pearson (like many contemporaries) heavily involved eugenics movement (Semmel, 1958), developed statistical techniques, also applied causes (interested readers see examples Pearson’s publications eugenics journals).","code":""},{"path":"chi-square.html","id":"chi-square-distributions-have-fundamental-properties-that-make-them-widespread-in-statistics","chapter":"9 Chi Square","heading":"9.3.2 Chi-square distributions have fundamental properties that make them widespread in statistics","text":"chi-square (\\(\\chi^2\\)) test, statistic, associated distribution fundamental many aspects statistics. full accounting many connections mathematical relationships beyond scope lab (see wikipedia articles chi-square test, chi-square distribution ).","code":""},{"path":"chi-square.html","id":"debate-about-correct-usage","chapter":"9 Chi Square","heading":"9.3.3 Debate about correct usage","text":"chi-square test multiple uses psychology, including tests independence goodness fit. “correct” usage chi-square tests without debate. example, roughly 50 years Pearson, Lewis & Burke (1949) wrote lengthy paper describing “uses misuses” chi-square tests psychology. several replies authors identified “misusing” chi-square test. recently, suggestions Lewis & Burke (1949) revisited Delucchi (1983). papers scratch surface many uses misuses chi-square tests psychology. ongoing goal labs develop conceptual understanding statistics use can justify usage appropriate analysis.","code":""},{"path":"chi-square.html","id":"connection-to-previous-lab-concepts","chapter":"9 Chi Square","heading":"9.3.4 Connection to previous lab concepts","text":"previous labs conducted statistical inference adopting similar general procedures. obtain sample data. consider sample arisen random sampling, construct sampling distribution. compare sample data sampling distribution see likely unlikely produced chance. Sometimes simulated sampling distribution, times used formulas compute precise probabilities.chi-square test another specific example general procedure described . can obtain sample data, compute \\(\\chi^2\\) statistic sample data, compare statistic reference null distribution determine probability obtaining value chance.","code":""},{"path":"chi-square.html","id":"practical-i-chisq.test-in-r","chapter":"9 Chi Square","heading":"9.4 Practical I: chisq.test() in R","text":"Base R comes several functions chi-square tests, including chisq.test() family \\(\\chi^2\\) distribution functions: dchisqu(), pchisqu(), qchisqu(), rchisqu().","code":""},{"path":"chi-square.html","id":"chisq.test","chapter":"9 Chi Square","heading":"9.4.1 chisq.test()","text":"chisq.test() function performs basic tests independence vectors contingency tables.","code":"\n?chisq.test"},{"path":"chi-square.html","id":"test-for-a-frequency-vector","chapter":"9 Chi Square","heading":"9.4.1.1 Test for a frequency vector","text":"Inputting single vector values conducts chi-square test N-1 degrees freedom. test assumes equal probability outcome default, reports chi-square sample statistic, well p-value associated \\(\\chi^2\\) distribution N-1 degrees freedom.Toss coin 50 times receive 20 heads 30 tails. Conduct chi-square test independence, assume theoretically expected frequencies 25 25.possible specify different theoretical probabilities:vector can length, e.g., roll dice 120 times count number times number 1 6 occurs, conduct chi-square test independence:","code":"\nmy_vals <- c(20,30)\n(xsq <- chisq.test(my_vals))\n#> \n#>  Chi-squared test for given probabilities\n#> \n#> data:  my_vals\n#> X-squared = 2, df = 1, p-value = 0.1573\n\nxsq$statistic\n#> X-squared \n#>         2\nxsq$observed\n#> [1] 20 30\nxsq$expected\n#> [1] 25 25\nxsq$residuals\n#> [1] -1  1\n\n\nsum(((xsq$observed - xsq$expected)^2) / xsq$expected)\n#> [1] 2\nmy_vals <- c(20,30)\nchisq.test(my_vals, p = c(.25,.75))\n#> \n#>  Chi-squared test for given probabilities\n#> \n#> data:  my_vals\n#> X-squared = 6, df = 1, p-value = 0.01431\nmy_vals <- c(20,30,10,10,30,30)\nchisq.test(my_vals)\n#> \n#>  Chi-squared test for given probabilities\n#> \n#> data:  my_vals\n#> X-squared = 22.308, df = 5, p-value = 0.0004576"},{"path":"chi-square.html","id":"independence-test-for-a-contingency-table","chapter":"9 Chi Square","heading":"9.4.2 Independence test for a contingency table","text":"matrix describing contingency table positive values rows columns can also inputted directly function. , null hypothesis “joint distribution cell counts contingency table product row column marginals”. degrees freedom defined \\((r-1)(c-1)\\), \\(r\\) number rows \\(c\\) number columns.following example help file:","code":"\nM <- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))\ndimnames(M) <- list(gender = c(\"F\", \"M\"),\n                    party = c(\"Democrat\",\"Independent\", \"Republican\"))\n(Xsq <- chisq.test(M))  # Prints test summary\n#> \n#>  Pearson's Chi-squared test\n#> \n#> data:  M\n#> X-squared = 30.07, df = 2, p-value = 2.954e-07\nXsq$observed   # observed counts (same as M)\n#>       party\n#> gender Democrat Independent Republican\n#>      F      762         327        468\n#>      M      484         239        477\nXsq$expected   # expected counts under the null\n#>       party\n#> gender Democrat Independent Republican\n#>      F 703.6714    319.6453   533.6834\n#>      M 542.3286    246.3547   411.3166\nXsq$residuals  # Pearson residuals\n#>       party\n#> gender   Democrat Independent Republican\n#>      F  2.1988558   0.4113702 -2.8432397\n#>      M -2.5046695  -0.4685829  3.2386734\nXsq$stdres     # standardized residuals\n#>       party\n#> gender   Democrat Independent Republican\n#>      F  4.5020535   0.6994517 -5.3159455\n#>      M -4.5020535  -0.6994517  5.3159455\nXsq$p.value\n#> [1] 2.953589e-07\nXsq$statistic\n#> X-squared \n#>  30.07015"},{"path":"chi-square.html","id":"conceptual-i-chi2-distribution-sample-statistic-and-test","chapter":"9 Chi Square","heading":"9.5 Conceptual I: \\(\\chi^2\\) distribution, sample statistic, and test","text":"Chi-square (\\(\\chi^2\\)) statistics can confusing \\(\\chi^2\\) can refer distributions, sample statistic, statistical inference tests.\\(\\chi^2\\) distribution family distributions arise sum squared values random samples unit normal distribution:\\(\\chi^2 = \\sum_{=1}^k Z_i^2\\), \\(Z_i^2\\) random deviate unit normal distribution (mean = 0, sd =1), \\(k\\) number random samples (also known degrees freedom, number samples free independently vary). \\(k=1\\), \\(\\chi^2\\) distribution unit normal distribution squared.\\(\\chi^2\\) sample statistic formula can applied frequency data summarize amount observed frequencies differ theoretically expected frequencies.\\(\\chi^2 = \\sum{\\frac{(\\text{Observed} - \\text{Expected})^2}{\\text{Expected}}}\\)\\(\\chi^2 = \\sum_{=1}^n{\\frac{(\\text{O}_i - \\text{E}_i)^2}{\\text{E}_i}}\\)\\(\\chi^2\\) statistical tests (test independence, goodness fit) used inference role chance producing observed frequency data. process involves computing \\(\\chi^2\\) sample statistic observed frequency data, comparing obtained value \\(\\chi^2\\) distribution degrees freedom sample. probability obtaining \\(\\chi^2\\) sample statistic larger generally approximates probability independent random sampling process produced deviations expected frequencies large larger found sample.","code":""},{"path":"chi-square.html","id":"the-chi2-sample-statistic","chapter":"9 Chi Square","heading":"9.5.1 The \\(\\chi^2\\) sample statistic","text":"two ways writing formula \\(\\chi^2\\) sample statistic.\\(\\chi^2 = \\sum{\\frac{(\\text{Observed} - \\text{Expected})^2}{\\text{Expected}}}\\)\\(\\chi^2 = \\sum_{=1}^n{\\frac{(\\text{O}_i - \\text{E}_i)^2}{\\text{E}_i}}\\)\\(\\chi^2\\) sample statistic used summarize obtained frequency data, specifically way relates obtained frequencies theoretically expected frequencies.example, tossed coin 50 times, found following observed frequencies heads tails, compare expected frequencies coin fair.Thus, outcome observed value (\\(O_i\\)) expected value (\\(E_i\\)), \\(\\chi^2\\) can computed:shows two ways compute \\(\\chi^2\\) example, including using base R function \\(chisq.test()\\). obtained value .32 case fairly small differences obtained expected frequencies fairly small. differences larger, \\(\\chi^2\\) sample statistic much larger, e.g:times base R function returned \\(\\chi^2\\) sample statistic (computed data assumed theoretical frequencies). function also return information degrees freedom (df), p-value. additional values refer information \\(\\chi^2\\) distribution. appropriate conditions, \\(\\chi^2\\) sample statistic can compared \\(\\chi^2\\) distribution purposes statistical inference.","code":"\ncoin_toss <- data.frame(outcome = c(\"H\",\"T\"),\n                        O = c(23,27),\n                        E = c(25,25))\nknitr::kable(coin_toss)\nlibrary(dplyr)\n\ncoin_toss <- coin_toss %>%\n  mutate(d = O - E) %>%\n  mutate(d_sq = d^2) %>%\n  mutate(div = d_sq/E )\n\nknitr::kable(coin_toss)\n\n# compute chi-square\nsum(coin_toss$div)\n#> [1] 0.32\n\n# compute chi-square \nO <- c(23,27)\nE <- c(25,25)\nsum(((O-E)^2)/E)\n#> [1] 0.32\n\n# compute chi-square\nchisq.test(x=c(23,27))\n#> \n#>  Chi-squared test for given probabilities\n#> \n#> data:  c(23, 27)\n#> X-squared = 0.32, df = 1, p-value = 0.5716\nchisq.test(x=c(47,3))\n#> \n#>  Chi-squared test for given probabilities\n#> \n#> data:  c(47, 3)\n#> X-squared = 38.72, df = 1, p-value = 4.892e-10"},{"path":"chi-square.html","id":"the-chi2-distribution","chapter":"9 Chi Square","heading":"9.5.2 The \\(\\chi^2\\) distribution","text":"shape \\(\\chi^2\\) distribution depends parameter called \\(k\\). , \\(k = 1\\), \\(\\chi^2\\) distribution defined unit normal distribution squared.R distribution functions \\(\\chi^2\\), including dchisq(), pchisq(), qchisq(), rchisq(). , sampled random deviates using rchisq(), k = 1 (equivalent df = 1), get histogram :, simplest, \\(\\chi^2\\) just normal distribution squared.\\(k > 1\\), \\(\\chi^2\\) distribution defined :\\(\\chi^2 = \\sum_{=1}^k Z_i^2\\), \\(Z_i\\) independent samples unit normal distribution. words, \\(\\chi^2\\) distribution sum squared values unit normal distribution, \\(k\\) number independent samples squared sum.clarify, let’s use R:can get glimpse \\(\\chi^2\\) distribution looks like across range \\(k\\) plotting pdf (probability density function), using dchisq().\n### Developing intuitions \\(\\chi^2\\)Let’s say randomly sampled 5 numbers unit normal distribution (mean = 0 sd =1), squared numbers, added . expect number ?answer number distributed \\(\\chi^2\\) \\(k=5\\), referring situation summing squares 5 samples unit normal distribution.\\(\\chi^2\\) distribution change shape \\(k\\) increases? \\(k\\) big number like 60, kind shape expect? know \\(k\\), expect mean \\(\\chi^2\\) distribution ? Answering questions requires building intuition \\(\\chi^2\\).following, take random samples unit normal distribution:expected mean unit normal distribution?square values sample unit normal distribution (equivalent \\(\\chi^2\\) \\(k=1\\)), mean squared values ?turns answer 1. negative values squaring everything. 68% values unit normal -1 1, squaring make values 0 1, rest values get increasingly bigger 1. balance 1, mean squared normal distribution. words, mean \\(\\chi^2\\) \\(k\\) parameter, also called degrees freedom.example, mean 10,000 numbers drawn \\(\\chi^2\\) k = 10, :Another way think recognize expected value (mean) squared unit normal distribution 1. , take 10 values distribution (.e., k = 10), planning sum 10 values get, expected value 1…summing 10 ones, gives 10. expectations can applied \\(\\chi^2\\) distributions \\(k\\).","code":"\n# normal histogram\nhist(rnorm(10000,0,1), breaks = 100)\n\n# chi-squared with k = 1\nhist(rnorm(10000,0,1)^2, breaks = 100)\nhist(rchisq(10000,1), breaks=100)\n# k = 1\nfrom_normal <- replicate(10000, rnorm(1,0,1)^2)\nfrom_chisq  <- rchisq(10000,1)\nplot_df <- data.frame(values = c(from_normal,\n                                 from_chisq),\n                      source = c(\"normal^2\",\"chisq\"))\n\nlibrary(ggplot2)\nggplot(plot_df, aes(x=values))+\n  geom_histogram(bins=100)+\n  ggtitle(\"k=1\")+\n  facet_wrap(~source)\n# k = 2\nfrom_normal <- replicate(10000, sum(rnorm(2,0,1)^2))\nfrom_chisq  <- rchisq(10000,2)\nplot_df <- data.frame(values = c(from_normal,\n                                 from_chisq),\n                      source = c(\"normal^2\",\"chisq\"))\n\nlibrary(ggplot2)\nggplot(plot_df, aes(x=values))+\n  geom_histogram(bins=100)+\n  ggtitle(\"k=2\")+\n  facet_wrap(~source)\n# k = 3\nfrom_normal <- replicate(10000, sum(rnorm(3,0,1)^2))\nfrom_chisq  <- rchisq(10000,3)\nplot_df <- data.frame(values = c(from_normal,\n                                 from_chisq),\n                      source = c(\"normal^2\",\"chisq\"))\n\nlibrary(ggplot2)\nggplot(plot_df, aes(x=values))+\n  geom_histogram(bins=100)+\n  ggtitle(\"k=3\")+\n  facet_wrap(~source)\n# k = 5\nfrom_normal <- replicate(10000, sum(rnorm(5,0,1)^2))\nfrom_chisq  <- rchisq(10000,5)\nplot_df <- data.frame(values = c(from_normal,\n                                 from_chisq),\n                      source = c(\"normal^2\",\"chisq\"))\n\nlibrary(ggplot2)\nggplot(plot_df, aes(x=values))+\n  geom_histogram(bins=100)+\n  ggtitle(\"k=5\")+\n  facet_wrap(~source)\n\nplot_df <- data.frame(values = c(dchisq(x=seq(0,20,length.out = 100), df=1),\n                                 dchisq(x=seq(0,20,length.out = 100), df=3),\n                                 dchisq(x=seq(0,20,length.out = 100), df=5),\n                                 dchisq(x=seq(0,20,length.out = 100), df=9),\n                                 dchisq(x=seq(0,20,length.out = 100), df=11)\n                                 ),\n                      x = rep(seq(0,20,length.out = 100),5),\n                      k = as.factor(rep(c(1,3,5,9,11), each = 100))\n                      )\n\nggplot(plot_df, aes(x = x, y=values, color=k, group=k))+\n  geom_line()+\n  ylab(\"density\")+\n  xlab(\"chi-squared\")+\n  scale_x_continuous(breaks=0:20)\na<- replicate(10000,sum(rnorm(5,0,1)^2))\nhist(a)\nmean(rnorm(10000,0,1))\n#> [1] -0.003677052\nmean(rnorm(10000,0,1)^2)\n#> [1] 1.007915\nmean(rchisq(10000,10))\n#> [1] 9.991172"},{"path":"chi-square.html","id":"conceptual-ii-examining-the-approximation","chapter":"9 Chi Square","heading":"9.6 Conceptual II: Examining the approximation","text":"lecture discussed binomial distribution converges normal distribution long run. one properties allows \\(\\chi^2\\) distribution approximate properties binomial distribution.First, can visually see binomial distribution becomes normally distributed long run simulation. simulation involves 10,000 sets coin flips. first histogram involves set 10 coin flips, displays frequency possible outcome (# heads)s. second histogram shows sets 100 coin flips. , range possible outcomes increases, appear distributed normally. number flips set increases, distribution possible outcomes approaches normal distribution.\nSecond, let’s develop sense idea \\(\\chi^2\\) test approximation binomial test.Consider another coin flipping scenario. Let’s say coin flipped 10 times, 2 heads. p-value two-tailed test, specifically probabiltiy getting 2 less heads, 8 heads.?use binomial test, compute exact probability.also use \\(\\chi^2\\) test approximation:case wouldn’t good reason use \\(\\chi^2\\) test, binomial test provides exact probability. Also, expected frequencies small , p-value \\(\\chi^2\\) test half small .However, consider sets coin flips much larger 10, increase expected frequencies (allows closer convergence normal distribution), \\(\\chi^2\\) binomial tests return p-values increasingly similar.","code":"\n# flip a coin 10 times\nhist(rbinom(10000,10,.5), breaks=seq(0,10,1))\n\n# flip a coin 100 times\nhist(rbinom(10000,100,.5), breaks=seq(20,80,1))\npbinom(2,10,.5, lower.tail = TRUE)*2\n#> [1] 0.109375\nchisq.test(c(2,8))\n#> \n#>  Chi-squared test for given probabilities\n#> \n#> data:  c(2, 8)\n#> X-squared = 3.6, df = 1, p-value = 0.05778\npbinom(40,100,.5, lower.tail = TRUE)*2\n#> [1] 0.05688793\nchisq.test(c(40,60))\n#> \n#>  Chi-squared test for given probabilities\n#> \n#> data:  c(40, 60)\n#> X-squared = 4, df = 1, p-value = 0.0455\npbinom(450,1000,.5, lower.tail = TRUE)*2\n#> [1] 0.001730536\nchisq.test(c(450,550))\n#> \n#>  Chi-squared test for given probabilities\n#> \n#> data:  c(450, 550)\n#> X-squared = 10, df = 1, p-value = 0.001565\npbinom(4900,10000,.5, lower.tail = TRUE)*2\n#> [1] 0.04658553\nchisq.test(c(4900,5100))\n#> \n#>  Chi-squared test for given probabilities\n#> \n#> data:  c(4900, 5100)\n#> X-squared = 4, df = 1, p-value = 0.0455"},{"path":"chi-square.html","id":"lab-9-generalization-assignment","chapter":"9 Chi Square","heading":"9.7 Lab 9 Generalization Assignment","text":"","code":""},{"path":"chi-square.html","id":"instructions-8","chapter":"9 Chi Square","heading":"9.7.1 Instructions","text":"general, labs present discussion problems issues example code like , students tasked completing generalization assignments, showing can work concepts tools independently.assignment instructions following:Work inside R project “StatsLab1” usingCreate new R Markdown document called “Lab9.Rmd”Use Lab9.Rmd show work attempting solve following generalization problems. Commit work regularly appears Github repository.problem, make note much problem believe can solve independently without help. example, needed watch help video unable solve problem without copying answers, note 0. confident can complete problem scratch completely , note 100. OK 0s 100s anything .Submit github repository link Lab 9 blackboard.","code":""},{"path":"chi-square.html","id":"problems-8","chapter":"9 Chi Square","heading":"9.7.2 Problems","text":"following paper links open data, describes design two chi-square tests performed Experiment 1 (copy paper made available).Silver, . M., Stahl, . E., Loiotile, R., Smith-Flores, . S., & Feigenson, L. (2020). Choosing Leads Liking: Choice-Induced Preference Infancy. Psychological Science, 0956797620954491.Obtain data online repository, show code loading R, conduct tests reported Experiment 1 authors conducted. include one binomial test, two chi-square tests. Briefly report re-analysis, discuss whether obtained values authors (6 points).Important Note: re-analysis able obtain values authors provided results section. However, view authors also misused chi-square test, especially test independence involving age. , ok unable reproduce analysis. However, instructive try reproduce authors form opinion whether test applied sound manner.Solution script: also providing .rmd lab 9 wrote solution video https://github.com/CrumpLab/psyc7709Lab/blob/master/lab_solutions/Lab9.Rmd.Update misuse chi-square test paper. discussed class solution video, appears accidentally found example recent literature chi-square test used incorrectly. solution video didn’t provide clear reason demonstrate chi-square test misused. , thought write addendum lab.recap, authors measured choice made 21 infants. age infant measured months (two decimal places). reported chi-square test independence determine whether age independent choice. example, reported: \\(\\chi^2\\) (19,N=21) =18.24,p=.506. values sense correct. example:However, appears authors treated infant’s ages, measured continuous variable, categorical variable. , happened, two infants happened exactly 11.66 months old. result, 21 infants, 20 different age categories. contingency table constructed represent 20 age categories, 2 choice options, get 20x2 table. table (20-1)(2-1) = 19 degrees freedom. solution video showed example authors might constructed table data, able obtain chi-square value reported, suggesting construct table.several problems . One problems focus conversion continuous age variable categorical variable. expecting authors bin ages, say two categories: younger vs. older. Instead, used infant’s age category level. happened case two infants exactly age (11.66 months), hadn’t happened, table 21 levels age (21 infants).Consider occurs treat subject unique level contingency table, especially experiment involves subject making single choice two alternatives. see answer , always get chi-square value. matter subjects .example contingency table 5 subjects. case, column represents subject. Row 1 represents choice , row 2 choice 2. subject makes choice, choice counted appropriate row.contingency table, possible compute chi-square test table.However, look happens. obtain chi-squared value 5. , always happen, matter choices subject makes:Every time function runs, choices made simulated subject randomized. However, matter happens, chi-square value always five.effectively authors . example, consider happen authors data excluded two infants exact age. table choices 19 infants.can simulate possible outcome way:matter choices infants make (either B), always make one , . , observed chi-square value always number subjects. , test confirm number infants used experiment assess independence age choices.Finally, create contingency table subject category level…conduct chi-square test independence see subjects independent choices made, think major problem subjects couldn’t independent choices made, ones making choices.","code":"\npchisq(18.24, 19, lower.tail = FALSE)\n#> [1] 0.5064639\nreplicate(5,sample(c(1,0),2))\n#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]    1    1    0    1    0\n#> [2,]    0    0    1    0    1\nchisq.test(replicate(5,sample(c(1,0),2)))\n#> \n#>  Pearson's Chi-squared test\n#> \n#> data:  replicate(5, sample(c(1, 0), 2))\n#> X-squared = 5, df = 4, p-value = 0.2873\nchisq.test(replicate(5,sample(c(1,0),2)))\n#> \n#>  Pearson's Chi-squared test\n#> \n#> data:  replicate(5, sample(c(1, 0), 2))\n#> X-squared = 5, df = 4, p-value = 0.2873\nchisq.test(replicate(19,sample(c(1,0),2)))\n#> \n#>  Pearson's Chi-squared test\n#> \n#> data:  replicate(19, sample(c(1, 0), 2))\n#> X-squared = 19, df = 18, p-value = 0.3918"},{"path":"t-tests.html","id":"t-tests","chapter":"10 T-tests","heading":"10 T-tests","text":"“10/8/2020 | Last Compiled: 2020-12-09”","code":""},{"path":"t-tests.html","id":"reading-5","chapter":"10 T-tests","heading":"10.1 Reading","text":"Vokey & Allen (2018), Chapter 14; Crump et al. (2018), Chapter 6","code":""},{"path":"t-tests.html","id":"overview-9","chapter":"10 T-tests","heading":"10.2 Overview","text":"lab demonstrates conduct one sample, paired sample, independent sample t-tests R, uses R tool develop insight conceptual foundations t-test.","code":""},{"path":"t-tests.html","id":"historical-background","chapter":"10 T-tests","heading":"10.3 Historical Background","text":"William Sealy Gosset published t-test pseudonym “Student”, test sometimes called “Student’s t-test” (Student, 1908). dispute origin meaning \\(t\\). One hypothesis \\(s\\) commonly used time refer sample statistics, Gosset chose \\(t\\) next letter, perhaps indicating “step-” thinking sample statistics? Gosset published pseudonym employee Guinness Breweries time, hired examine issues making inferences small samples brewing beer. test developed intellectual property Guinness, Gosset thought test broadly used, published pseudonym protect job. Pearson (1939) provides biography Gosset. Sawilowsky & Blair (1992) conduct simulations examine robust t-test violations assumptions.","code":""},{"path":"t-tests.html","id":"practical-i-t.test","chapter":"10 T-tests","heading":"10.4 Practical I: t.test()","text":"Base R includes t.test() function computes several forms t-tests.three quick examples computing one sample, paired sample independent sample t-tests using R.","code":"\n?t.test"},{"path":"t-tests.html","id":"one-sample-t-test","chapter":"10 T-tests","heading":"10.4.1 One-sample t-test","text":"","code":"\nsome_random_means <- rnorm(10,0,1)\nt.test(some_random_means, mu=0)\n#> \n#>  One Sample t-test\n#> \n#> data:  some_random_means\n#> t = 1.1445, df = 9, p-value = 0.2819\n#> alternative hypothesis: true mean is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.3947402  1.2031553\n#> sample estimates:\n#> mean of x \n#> 0.4042076"},{"path":"t-tests.html","id":"paired-sample-t-test","chapter":"10 T-tests","heading":"10.4.2 Paired-sample t-test","text":"","code":"\nA_means <- rnorm(10,0,1)\nB_means <- rnorm(10,0,1)\n\nt.test(A_means,B_means,paired=TRUE)\n#> \n#>  Paired t-test\n#> \n#> data:  A_means and B_means\n#> t = 0.22548, df = 9, p-value = 0.8266\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.9896233  1.2087485\n#> sample estimates:\n#> mean of the differences \n#>               0.1095626"},{"path":"t-tests.html","id":"independent-sample-t-test","chapter":"10 T-tests","heading":"10.4.3 Independent-sample t-test","text":"","code":"\nA_means <- rnorm(10,0,1)\nB_means <- rnorm(10,0,1)\n\nt.test(A_means,B_means, var.equal=TRUE)\n#> \n#>  Two Sample t-test\n#> \n#> data:  A_means and B_means\n#> t = 0.72818, df = 18, p-value = 0.4759\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.5337639  1.1000357\n#> sample estimates:\n#>   mean of x   mean of y \n#>  0.21170883 -0.07142705"},{"path":"t-tests.html","id":"formula-syntax-for-data-frames","chapter":"10 T-tests","heading":"10.4.4 formula syntax for data frames","text":"examples, t.test() function applied vectors containing sample means. also possible apply t.test() function long data frames using ~ syntax.","code":"\nmy_data <- data.frame(group = rep(c(\"A\",\"B\"), each=10),\n                      means = rnorm(20,0,1))\n\nt.test(means~group, var.equal=TRUE, data=my_data)\n#> \n#>  Two Sample t-test\n#> \n#> data:  means by group\n#> t = -0.20974, df = 18, p-value = 0.8362\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  -1.251444  1.024251\n#> sample estimates:\n#> mean in group A mean in group B \n#>     -0.13271602     -0.01911943"},{"path":"t-tests.html","id":"one-or-two-sided-test","chapter":"10 T-tests","heading":"10.4.5 one or two-sided test","text":"default, t.test() function provides two sided test, options can specified using alternative = c(\"two.sided\", \"less\", \"greater\") input parameter.","code":"\nsome_random_means <- rnorm(10,0,1)\nt.test(some_random_means, mu=0, alternative = \"two.sided\")\n#> \n#>  One Sample t-test\n#> \n#> data:  some_random_means\n#> t = -0.74874, df = 9, p-value = 0.4731\n#> alternative hypothesis: true mean is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.7587637  0.3813899\n#> sample estimates:\n#>  mean of x \n#> -0.1886869\nt.test(some_random_means, mu=0, alternative = \"less\")\n#> \n#>  One Sample t-test\n#> \n#> data:  some_random_means\n#> t = -0.74874, df = 9, p-value = 0.2366\n#> alternative hypothesis: true mean is less than 0\n#> 95 percent confidence interval:\n#>       -Inf 0.2732682\n#> sample estimates:\n#>  mean of x \n#> -0.1886869\nt.test(some_random_means, mu=0, alternative = \"greater\")\n#> \n#>  One Sample t-test\n#> \n#> data:  some_random_means\n#> t = -0.74874, df = 9, p-value = 0.7634\n#> alternative hypothesis: true mean is greater than 0\n#> 95 percent confidence interval:\n#>  -0.650642       Inf\n#> sample estimates:\n#>  mean of x \n#> -0.1886869"},{"path":"t-tests.html","id":"var.equal-and-welchs-correction","chapter":"10 T-tests","heading":"10.4.6 var.equal and Welch’s correction","text":"t.test() function also makes default assumptions indpendent samples test. , default applies correction called Welch’s correction. correction related assumption equal variances samples group.conduct t-test without correction set var.equal=TRUE. applies independent sample case two variances.","code":"\nA <- rnorm(10,0,1)\nB <- rnorm(10,0,1)\nt.test(A,B)\n#> \n#>  Welch Two Sample t-test\n#> \n#> data:  A and B\n#> t = 0.87964, df = 14.526, p-value = 0.3934\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.53283  1.27805\n#> sample estimates:\n#>  mean of x  mean of y \n#> -0.2247527 -0.5973629\nt.test(A,B, var.equal=TRUE)\n#> \n#>  Two Sample t-test\n#> \n#> data:  A and B\n#> t = 0.87964, df = 18, p-value = 0.3906\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.5173251  1.2625455\n#> sample estimates:\n#>  mean of x  mean of y \n#> -0.2247527 -0.5973629"},{"path":"t-tests.html","id":"t.test-contents","chapter":"10 T-tests","heading":"10.4.7 t.test() contents","text":"t.test() function two kinds outputs. First, prints results console (saw ). Second, outputs list containing components test. individual pieces t-test can saved accessed putting results t.test new variable.example:","code":"\n (my_results <- t.test(A,B, var.equal=TRUE))\n#> \n#>  Two Sample t-test\n#> \n#> data:  A and B\n#> t = 0.87964, df = 18, p-value = 0.3906\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.5173251  1.2625455\n#> sample estimates:\n#>  mean of x  mean of y \n#> -0.2247527 -0.5973629\nmy_results$statistic\n#>         t \n#> 0.8796425\nmy_results$parameter\n#> df \n#> 18\nmy_results$p.value\n#> [1] 0.3906458\nmy_results$estimate\n#>  mean of x  mean of y \n#> -0.2247527 -0.5973629"},{"path":"t-tests.html","id":"papaja-reporting-with-apa_print","chapter":"10 T-tests","heading":"10.4.8 papaja reporting with apa_print()","text":"papaja package convenient functions automating writing t-test results.example, t-test result, \\(t(18) = 0.88\\), \\(p = .391\\), printed using r code snippet inserted text .Rmd.","code":"\nlibrary(papaja)\napa_print(my_results)\n#> $estimate\n#> [1] \"$\\\\Delta M = 0.37$, 95\\\\% CI $[-0.52$, $1.26]$\"\n#> \n#> $statistic\n#> [1] \"$t(18) = 0.88$, $p = .391$\"\n#> \n#> $full_result\n#> [1] \"$\\\\Delta M = 0.37$, 95\\\\% CI $[-0.52$, $1.26]$, $t(18) = 0.88$, $p = .391$\"\n#> \n#> $table\n#> NULL\n#> \n#> attr(,\"class\")\n#> [1] \"apa_results\" \"list\""},{"path":"t-tests.html","id":"conceptual-i-simulating-the-t-test","chapter":"10 T-tests","heading":"10.5 Conceptual I: Simulating the t-test","text":"section create simulations various components independent samples t-test. One goal make code general, can simulate wide range designs.simulate experimental situation involving two groups B. assume equal number subjects (N), subject measured similar number times (X times). also simulate null-hypothesis, assumes experimental manipulation ineffective. result, assume subjects B randomly sampled underlying distribution. assume raw scores subject come normal distribution.","code":""},{"path":"t-tests.html","id":"simulating-a-single-experiment","chapter":"10 T-tests","heading":"10.5.1 Simulating a single experiment","text":"assumptions place, possible simulate results single experiment.one alternative, another example one-liner:","code":"\n#subjects per group\nN <- 10\n# measurements per subject\nX <- 2\n\n# distribution assumptions\nA_mean <- 100\nB_mean <- 100\n\nA_sd <- 25\nB_sd <- 25\nA_scores <- rnorm(N*X,A_mean,A_sd)\nB_scores <- rnorm(N*X,B_mean,B_sd)\n\nsim_data <- data.frame(groups = rep(c(\"A\",\"B\"),each = N*X),\n                       subjects = rep(rep(1:N,each = X),2),\n                       scores = c(A_scores,B_scores))\n\nlibrary(dplyr)\n\nsubject_means <- sim_data %>%\n  group_by(groups,subjects) %>%\n  summarize(means = mean(scores), .groups = 'drop')\n\nt.test(means~groups, var.equal =TRUE,data = subject_means)\n#> \n#>  Two Sample t-test\n#> \n#> data:  means by groups\n#> t = -1.9629, df = 18, p-value = 0.0653\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  -30.844333   1.047707\n#> sample estimates:\n#> mean in group A mean in group B \n#>        92.43684       107.33515\nt.test(replicate(N, mean(rnorm(X, A_mean, A_sd))),\n       replicate(N, mean(rnorm(X, B_mean, B_sd))),\n       var.equal = TRUE)\n#> \n#>  Two Sample t-test\n#> \n#> data:  replicate(N, mean(rnorm(X, A_mean, A_sd))) and replicate(N, mean(rnorm(X, B_mean, B_sd)))\n#> t = 0.77914, df = 18, p-value = 0.446\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  -10.37599  22.60860\n#> sample estimates:\n#> mean of x mean of y \n#> 100.08855  93.97224"},{"path":"t-tests.html","id":"simulating-distributions-of-experiments","chapter":"10 T-tests","heading":"10.5.2 Simulating distributions of experiments","text":"“experiment may regarded forming individual ‘population’ experiments might performed conditions. series experiments sample drawn population.” — William Sealy Gossett (Student, 1908).quote first sentence Student’s formative paper t-test. previous section simulated single experiment. conduct simulation several thousand times, can create “population” experiments occurred conditions. general idea create sampling distribution experiments, compare results actual experiment distributions possible experiments.","code":""},{"path":"t-tests.html","id":"the-distribution-of-mean-differences","chapter":"10 T-tests","heading":"10.5.2.1 The distribution of mean differences","text":"experiment repeated 1000 times, time mean difference Group B. Thus, mean difference sample statistic used summarize result experiment, sampling distribution mean differences estimated simulation:","code":"\nsim_mean_diffs <- replicate(1000, mean(replicate(N, mean(rnorm(X, A_mean, A_sd)))) - mean(replicate(N, mean(rnorm(X, B_mean, B_sd)))))\n\nhist(sim_mean_diffs)"},{"path":"t-tests.html","id":"the-distribution-of-t","chapter":"10 T-tests","heading":"10.5.2.2 The distribution of t","text":"Student used \\(t\\) formula, rather mean differences summarize sample data two group experiment. \\(t\\) formula normalizes mean difference estimated standard error mean.\\(t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p\\sqrt{2/n}}\\)\\(s_p = \\sqrt{\\frac{s^2_{X_1} + s^2_{X_2}}{2}}\\)Although already distribution functions t-values, t-distribution constructed simulation. histogram 1000 \\(t\\) values happened.","code":"\nsim_ts <- replicate(1000, t.test(replicate(N, mean(rnorm(X, A_mean, A_sd))),\n                                 replicate(N, mean(rnorm(X, B_mean, B_sd))),\n                                 var.equal = TRUE)$statistic)\nhist(sim_ts)"},{"path":"t-tests.html","id":"t-distribution-functions","chapter":"10 T-tests","heading":"10.5.3 t distribution functions","text":"R comes dt, pt, qt, rt family function t-distributions well.example, rather simulating t values , sample 1000 \\(t\\) values t-distribution df = 18.\ndt function used draw probability density function t-distributions across range degrees freedom.discussed lecture, t-distribution approaches normal distribution degrees freedom increase. example, 95% values normal distribution smaller Z = 1.644854 standard deviations. corresponding 95% values t shown approach 1.644 degrees freedom increase.","code":"\nhist(rt(1000,df=18))\nlibrary(ggplot2)\nplot_df <- data.frame(values = c(dt(x=seq(-5,5,length.out = 100), df=1),\n                                 dt(x=seq(-5,5,length.out = 100), df=3),\n                                 dt(x=seq(-5,5,length.out = 100), df=5),\n                                 dt(x=seq(-5,5,length.out = 100), df=9),\n                                 dt(x=seq(-5,5,length.out = 100), df=11)\n                                 ),\n                      x = rep(seq(-5,5,length.out = 100),5),\n                      df = as.factor(rep(c(1,3,5,9,11), each = 100))\n                      )\n\nggplot(plot_df, aes(x = x, y=values, color=df, group=df))+\n  geom_line()+\n  ylab(\"density\")+\n  xlab(\"t\")+\n  scale_x_continuous(breaks=-5:5)\nqnorm(.95,0,1)\n#> [1] 1.644854\nqt(p=.95,df=c(1,5,10,100,1000))\n#> [1] 6.313752 2.015048 1.812461 1.660234 1.646379"},{"path":"t-tests.html","id":"conceptual-ii-simulating-power-curves","chapter":"10 T-tests","heading":"10.6 Conceptual II: Simulating power curves","text":"simulations assumed experimental manipulation effect, therefore expectation measurements groups taken distribution, differences groups explained random sampling.Another possibility experimental manipulation effective caused difference groups. case expectations measurements group different distributions. Specifically, causal force manipulation assumed change performance, resulting systematic changes scores group received manipulation. experimental manipulation principle change almost property distribution, differences means often focus research interest.","code":""},{"path":"t-tests.html","id":"what-proportion-of-experiments-would-be-significant","chapter":"10 T-tests","heading":"10.6.1 What proportion of experiments would be significant…?","text":"purpose conceptual section use simulation techniques ask proportion experiments significant (alpha level, say p<.05) experimental manipulation worked caused difference group means.First, confident basic answer. set alpha criterion p<.05, proportion experiments significant according null-hypothesis (difference groups)? can conduct simulation, see many experiments 1000 returned p-value less .05. answer , definition, approximately .05.next question something like, proportion experiments significant actually difference means group B. example, assume group mean 0, group B mean .25, distributions standard deviation (sd=1). design, N = 10 group, 5 scores measured per subject, probability getting p < .05 much higher 5%.","code":"\nsim_ps <- replicate(1000, t.test(replicate(10, mean(rnorm(5, 0, 1))),\n                                 replicate(10, mean(rnorm(5, 0, 1))),\n                                 var.equal = TRUE)$p.value)\nhist(sim_ps)\nlength(sim_ps[sim_ps < .05])/1000\n#> [1] 0.047\nsim_ps <- replicate(1000, t.test(replicate(10, mean(rnorm(5, 0, 1))),\n                                 replicate(10, mean(rnorm(5, .25, 1))),\n                                 var.equal = TRUE)$p.value)\nhist(sim_ps)\nlength(sim_ps[sim_ps < .05])/1000\n#> [1] 0.215"},{"path":"t-tests.html","id":"effect-size","chapter":"10 T-tests","heading":"10.6.2 Effect-size","text":"working toward plotting power-curves, show us probability getting significant result function design parameters like number subjects, number scores per subject (observations per cell), well assumed “effect-size” manipulation. Effect size regular meaning, idea experimental manipulation can cause change different amounts, manipulations might big effects (e.g., cause really big change mean), small effects.Effect-size can also refer specific statistical units. example, Cohen proposed effect-sizes mean differences two groups standardized. example, mean difference group B, clear big small difference. underlying distributions unit normal distributions, mean shift 1 large, represents shifting distribution whole standard deviation. underlying distributions large standard deviation, say 100, shifting mean 1 isn’t large respect total variability., Cohen’s effect size can expressed idea normalize mean difference standard deviation.\\(\\text{Cohen's d} = \\frac{\\text{mean difference}}{\\text{standard deviation}}\\)make use ideas power-curve simulations. Specifically, convenience, use unit normal distributions parent distributions group scores. , simulate differences mean groups. result, increase mean difference .25, .5, 1, another number, can interpret differences terms standard deviation units.","code":""},{"path":"t-tests.html","id":"power-curve-as-a-function-of-effect-size","chapter":"10 T-tests","heading":"10.6.3 Power-curve as a function of effect-size","text":"example conduct range simulations assuming effect-size increases 0 1.5, steps .1. simulations design parameters: N=10 subjects per group, X=5 scores taken subject. power curve shows proportion experiments return result p < .05 level effect-size. example, assumed effect-size 1, design detect effect size p<.05 level close 100% time. However, “power” design detect smaller effects decreases following curve.","code":"\neffect_sizes <- seq(0,1.5,.1)\nprop_significant <-c()\n\nfor(i in 1:length(effect_sizes)){\n  sim_ps <- replicate(1000, t.test(replicate(10, mean(rnorm(5, 0, 1))),\n                                   replicate(10, mean(rnorm(5, effect_sizes[i], 1))),\n                                   var.equal = TRUE)$p.value)\n  \n  prop_significant[i] <- length(sim_ps[sim_ps < .05])/1000\n}\n\nplot_df <- data.frame(effect_sizes,\n                      prop_significant)\n\nggplot(plot_df, aes(x=effect_sizes,y=prop_significant))+\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks=seq(0,1.5,.1))+\n  scale_y_continuous(breaks=seq(0,1,.1)) +\n  ylab(\"Proportion Significant\")"},{"path":"t-tests.html","id":"lab-10-generalization-assignment","chapter":"10 T-tests","heading":"10.7 Lab 10 Generalization Assignment","text":"","code":""},{"path":"t-tests.html","id":"instructions-9","chapter":"10 T-tests","heading":"10.7.1 Instructions","text":"general, labs present discussion problems issues example code like , students tasked completing generalization assignments, showing can work concepts tools independently.assignment instructions following:Work inside R project “StatsLab1” usingCreate new R Markdown document called “Lab10.Rmd”Use Lab10.Rmd show work attempting solve following generalization problems. Commit work regularly appears Github repository.problem, make note much problem believe can solve independently without help. example, needed watch help video unable solve problem without copying answers, note 0. confident can complete problem scratch completely , note 100. OK 0s 100s anything .Submit github repository link Lab 10 blackboard.","code":""},{"path":"t-tests.html","id":"problems-9","chapter":"10 T-tests","heading":"10.7.2 Problems","text":"task obtain data following paper conduct reproducible analysis results.Rosenbaum, D., Mama, Y., & Algom, D. (2017). Stand Stroop: Standing Enhances Selective Attention Cognitive Control. Psychological science, 28(12), 1864-1867.Note, paper, data, existing reproducible analysis data available https://crumplab.github.io/statisticsLab/lab-10-factorial-anova.html#important-stuff-4The re-analysis focus Experiment 3. three main goalsReproduce much analysis possible using paired-sample t-tests. Note, authors reported 2x2 repeated measures ANOVA, consider questions answered t-tests (2 points)Reproduce graph means, like shown paper (2 points)Present power-curve analysis design. (2 points)Note copy R markdown document described solution video can found github repository course: https://github.com/CrumpLab/psyc7709Lab/tree/master/lab_solutions","code":""},{"path":"simulation-and-power-analysis.html","id":"simulation-and-power-analysis","chapter":"Simulation and Power Analysis","heading":"Simulation and Power Analysis","text":"“11/8/2020 | Last Compiled: 2020-12-09”","code":""},{"path":"simulation-and-power-analysis.html","id":"reading-6","chapter":"Simulation and Power Analysis","heading":"10.8 Reading","text":"Crump et al. (2018), Chapter 12 Effect size power","code":""},{"path":"simulation-and-power-analysis.html","id":"overview-10","chapter":"Simulation and Power Analysis","heading":"10.9 Overview","text":"Part semester long project conduct simulation-based power-analysis. document provides background power-analyses use simulations sample-size design planning. Attempts made integrate additional examples remaining labs semester next move complicated designs statistical tests.Develop deeper understanding assumptions behind statistical testsSample-size planning power-analysisUnderstand real data behave given assumptions making data.","code":""},{"path":"simulation-and-power-analysis.html","id":"null-hypothesis","chapter":"Simulation and Power Analysis","heading":"10.10 Null-hypothesis","text":"general, null-hypothesis hypothesis experimental manipulation didn’t work. , hypothesis differences.can simulate null-hypotheses R experimental design. following way:Use R generate sample data condition designMake sure sample data comes distribution conditions (ensure differences)Compute test-statistic simulation, save , repeat create sampling distribution test statistic.sampling distribution test-statistic null-distribution. use set alpha criterion, hypothesis testing.","code":""},{"path":"simulation-and-power-analysis.html","id":"null-for-a-t-test","chapter":"Simulation and Power Analysis","heading":"10.10.1 Null for a t-test","text":"ran simulation 1000 times. definition, get approximately 5% simulations returning p-value less .05. increase number simulations, get accurate answer converges 5% every time.","code":"\n# samples A and B come from the same normal distribution\nA <- rnorm(n=10,mean=10, sd=5)\nB <- rnorm(n=10,mean=10, sd=5)\n\n# the pvalue for this one pretend simulation\nt.test(A,B,var.equal=TRUE)$p.value\n#> [1] 0.4465779\n\n# running the simulation\n# everytime we run this function we do one simulated experiment and return the p-value\nsim_null <- function(){\n  A <- rnorm(n=10,mean=10, sd=5)\n  B <- rnorm(n=10,mean=10, sd=5)\n  return(t.test(A,B,var.equal=TRUE)$p.value)\n}\n\n# use replicate to run the sim many times\noutcomes <- replicate(1000,sim_null())\n\n# plot the null-distribution of p-values\nhist(outcomes)\n\n# proportion of simulated experiments had a p-value less than .05\nlength(outcomes[outcomes<.05])/1000\n#> [1] 0.048"},{"path":"simulation-and-power-analysis.html","id":"alternative-hypothesis","chapter":"Simulation and Power Analysis","heading":"10.11 Alternative hypothesis","text":"general alternative null hypothesis (differences), often called alternative hypothesis: manipulation cause difference. specifically, infinite number possible alternative hypotheses, involving difference specific size.Consider . often find p-value less .05 mean difference 5 sample B. Let’s use parameters , except time sample different distributions B.programmed mean difference 5 sample B, found p-values less .05 much higher proportion time. sensible, really difference samples (put ).","code":"\n  A <- rnorm(n=10,mean=10, sd=5)\n  B <- rnorm(n=10,mean=15, sd=5)\n  t.test(A,B,var.equal=TRUE)$p.value\n#> [1] 0.04564235\n\n# make the mean for B 15 (5 more than A)\nsim_alternative <- function(){\n  A <- rnorm(n=10,mean=10, sd=5)\n  B <- rnorm(n=10,mean=15, sd=5)\n  return(t.test(A,B,var.equal=TRUE)$p.value)\n}\n\n# use replicate to run the sim many times\noutcomes <- replicate(1000,sim_alternative())\n\n# plot the distribution of p-values\nhist(outcomes)\n\n# proportion of simulated experiments had a p-value less than .05\nlength(outcomes[outcomes<.05])/1000\n#> [1] 0.556"},{"path":"simulation-and-power-analysis.html","id":"power-and-effect-size","chapter":"Simulation and Power Analysis","heading":"10.12 Power and Effect Size","text":"Power: probability rejecting null-hypothesis, given true effect size.Effect-size: general, ’s assumed size difference. example, assumed difference 5, assumed effect-size 5.many ways define measure effect-size. Perhaps common way Cohen’s D. Cohen’s D expresses mean difference terms standard deviation units. example, distributions standard deviation 5. mean 10, mean B 15. Using Cohen’s D, effect-size 1. 15 1 standard deviation away 10 (standard deviation also 5).calculated proportion simulations returned p-value less .05, found power design detect effect-size 1.Power depends three major things:Sample-sizeEffect-sizeAlpha-criterionPower property design. power design increases sample-size increases. power design increases actual true effect-size increases. power design increases alpha criterion increases (e.g, going .05 .1, making easier reject null).","code":""},{"path":"simulation-and-power-analysis.html","id":"power-analysis-with-r","chapter":"Simulation and Power Analysis","heading":"10.13 Power analysis with R","text":"many packages functions power analysis. Power analysis important planning design. example, can determine many subjects need order high probability detecting true effect (particular size) really .","code":""},{"path":"simulation-and-power-analysis.html","id":"pwr-package","chapter":"Simulation and Power Analysis","heading":"10.13.1 pwr package","text":"example using pwr package find power independent sample t-test, n=10, detect effect-size 1. answer similar simulations answer. simulation converge answer increased number simulations.mentioned many functions directly computing power R. Feel free use . class, learn use simulation conduct power analyses. can redundant approach necessary, given functions can use. Additionally, get exact solutions (approximate ones). Nevertheless, existing power functions can limited may apply design. simulation approach can extended design. Learning run simulations also improve statistical sensibilities, power calculations become less black box.Two things moving onto simulation: power-curves, sample-size planning.","code":"\nlibrary(pwr)\npwr.t.test(n=10,\n           d=1,\n           sig.level=.05,\n           type=\"two.sample\",\n           alternative=\"two.sided\")\n#> \n#>      Two-sample t test power calculation \n#> \n#>               n = 10\n#>               d = 1\n#>       sig.level = 0.05\n#>           power = 0.5620066\n#>     alternative = two.sided\n#> \n#> NOTE: n is number in *each* group"},{"path":"simulation-and-power-analysis.html","id":"power-curves","chapter":"Simulation and Power Analysis","heading":"10.13.2 power-curves","text":"design’s power relation true effect-size. design different levels power detect different sized effects. Let’s make power curve see power t-test independent samples (n=10) detect range effect-sizesThis power curve applies independent-sample t-tests n=10. property, fact designs. Every design ’s power curve. power curve shows us happen (average), true state world involves effects different sizes.know power-curve design, know sensitive design detecting effects particular sizes. might accidentally using powered design, small chance detecting effect size interested .know power-curve design, better position plan experiment, example modifying number subjects run.","code":"\neffect_sizes <- seq(.1,2,.1)\npower <- sapply(effect_sizes, \n          FUN = function(x) {\n            pwr.t.test(n=100,\n            d=x,\n            sig.level=.05,\n            type=\"two.sample\",\n            alternative=\"two.sided\")$power})\nplot_df <- data.frame(effect_sizes,power)\n\nlibrary(ggplot2)\nggplot(plot_df, aes(x=effect_sizes,\n                    y=power))+\n  geom_point()+\n  geom_line()"},{"path":"simulation-and-power-analysis.html","id":"sample-size-planning","chapter":"Simulation and Power Analysis","heading":"10.13.3 Sample-size planning","text":"one way plan number subjects need find effect interest.Establish smallest effect-size interestCreate curve showing power design function number subjects detect smallest effect-size interest.’s clear establish smallest effect-size interest. let’s say interested detecting effect least d = .2. means two conditions differ least .2 standard deviation shift. find something smaller , let’s say wouldn’t care wouldn’t big enough care. many subjects need high powered design, one almost always reject null-hypothesis?independent samples t-test:Well, looks like need many subjects high power. example, want detect effect 95% time, need around 650 subjects. ’s worth kind analysis see design checks . don’t want waste time running experiment designed fail (even true effect real).","code":"\nnum_subjects <- seq(10,1000,10)\npower <- sapply(num_subjects, \n          FUN = function(x) {\n            pwr.t.test(n=x,\n            d=.2,\n            sig.level=.05,\n            type=\"two.sample\",\n            alternative=\"two.sided\")$power})\nplot_df <- data.frame(num_subjects,power)\n\nlibrary(ggplot2)\nggplot(plot_df, aes(x=num_subjects,\n                    y=power))+\n  geom_point()+\n  geom_line()"},{"path":"simulation-and-power-analysis.html","id":"simulation-approach-to-power-calculations","chapter":"Simulation and Power Analysis","heading":"10.14 Simulation approach to power calculations","text":"simulation approach power analysis involves steps:Use R sample numbers condition design.can set properties (e.g., n, mean, sd, kind distribution etc.) sample condition, mimic type expected patternAnalyze simulated data obtain p-value (use analysis appropriate design)Repeat many times, save p-valuesCompute power determining proportion simulated p-values less alpha criterion.simulations, increasing number simulations improve accuracy results. use 1000 simulations throughout. 10,000 better, might take just little bit longer.","code":""},{"path":"simulation-and-power-analysis.html","id":"simulated-power-for-a-t-test","chapter":"Simulation and Power Analysis","heading":"10.14.1 Simulated power for a t-test","text":"power curve n=10.case, obvious benefit computing power-curve simulation. answer get similar answer got using pwr package, simulation answer noisy. bother simulation?One answer bother question can simulate deeper aspects design get refined answers without work math.","code":"\n# function to run a simulated t-test\nsim_power <- function(x){\n  A <- rnorm(n=10,mean=0, sd=1)\n  B <- rnorm(n=10,mean=(0+x), sd=1)\n  return(t.test(A,B,var.equal=TRUE)$p.value)\n}\n\n# vector of effect sizes\neffect_sizes <- seq(.1,2,.1)\n# run simulation for each effect size 1000 times\npower <- sapply(effect_sizes, \n          FUN = function(x) {\n            sims <- replicate(1000,sim_power(x))\n            sim_power <- length(sims[sims<.05])/length(sims)\n            return(sim_power)})\n# combine into dataframe\nplot_df <- data.frame(effect_sizes,power)\n\n# plot the power curve\nggplot(plot_df, aes(x=effect_sizes,\n                    y=power))+\n  geom_point()+\n  geom_line()"},{"path":"simulation-and-power-analysis.html","id":"simulating-cell-size","chapter":"Simulation and Power Analysis","heading":"10.14.2 Simulating cell-size","text":"Many experimental designs involve multiple measurements, trials, subject condition. many trials require subject condition? Traditional power analysis doesn’t make easy answer question. However, power design depend number subjects, also number trials used estimate mean subject condition.Consider simple Stroop experiment. researcher interested measuring Stroop effect least d=.1 (e.g., difference mean congruent trials .1 standard deviations smaller mean incongruent trials). many subjects required? , many trials subject perform congruent incongruent conditions? Let’s use simulation find .eye, looks like 30 subjects 100 trials condition give high power find Stroop effect d=.1.","code":"\n# function to run a simulated t-test\n# nsubs sets number of subjects\n# ntrials to change number of trials\n# d sets effect size\n# this is a paired sample test to model Stroop\nsim_power <- function(nsubs,ntrials,d){\n  A <- replicate(nsubs,mean(rnorm(n=ntrials,mean=0, sd=1)))\n  B <- replicate(nsubs,mean(rnorm(n=ntrials,mean=d, sd=1)))\n  return(t.test(A,B,paired=TRUE)$p.value)\n}\n\n# vectors for number of subjects and trials\nn_subs_vector <- c(10,20,30,50)\nn_trials_vector <- c(10,20,30,50,100)\n\n# a loop to run all simulations\npower <- c()\nsubjects <- c()\ntrials <- c()\ni <- 0 # use this as a counter for indexing\nfor(s in n_subs_vector){\n  for(t in n_trials_vector){\n    i <- i+1\n    sims <- replicate(1000,sim_power(s,t,.1))\n    power[i] <- length(sims[sims<.05])/length(sims)\n    subjects[i] <- s\n    trials[i] <- t\n  }\n}\n\n# combine into dataframe\nplot_df <- data.frame(power,subjects,trials)\n\n# plot the power curve\nggplot(plot_df, aes(x=subjects,\n                    y=power,\n                    group=trials,\n                    color=trials))+\n  geom_point()+\n  geom_line()\n\n# a vectorized version of the loop\n# run simulation for each effect size 1000 times\n\n# power <- outer(n_subs_vector,\n#                n_trials_vector,\n#                FUN = Vectorize(function(x,y) {\n#                   sims <- replicate(100,sim_power(x,y))  \n#                   sim_power <- length(sims[sims<.05])/length(sims)\n#                   return(sim_power)\n#                }))"},{"path":"simulation-and-power-analysis.html","id":"closing-thoughts","chapter":"Simulation and Power Analysis","heading":"10.15 Closing thoughts","text":"simulation approach powerful flexible. can applied whenever can formalize assumptions data. , simulations can highly customized account kinds nuances, like different numbers subjects, different distributions, assumptions noise, etc. wondering design can , maybe simulate .","code":""},{"path":"simulation-and-power-analysis.html","id":"more-examples","chapter":"Simulation and Power Analysis","heading":"10.16 More example(s)","text":"find time try add examples , especially box examples illustrate simulation can applied.","code":""},{"path":"simulation-and-power-analysis.html","id":"one-way-anova","chapter":"Simulation and Power Analysis","heading":"10.16.1 One-Way ANOVA","text":"Let’s extend simulation based approach one-way ANOVA. Let’s assume -subjects design, one factor four levels: , B, C, D. 20 subjects group. power curve design detect effects various size? Immediately, situation becomes complicated, numerous ways means , B, C, D vary. Let’s assume simplest case, three , one different amount standard deviations. compute main effect, report proportion significant experiments increase effect size fourth group.looks like design (1 factor, -subjects, 20 subjects per group) high power detect effect d=1, specifically one groups differs others d=1.However, effects psychology smalls, d=.2 common. , many subjects design require high power (let’s say .95, although people use .8) detect small effect?simulations suggests need 560 subjects group power .95 detect effect (d=.2). ’s total 2240 subjects. Reality can surprising comes power analysis. better surprised design run experiment, .","code":"\n# function to run a simulated t-test\nsim_power_anova <- function(x){\n  A <- rnorm(n=20,mean=0, sd=1)\n  B <- rnorm(n=20,mean=0, sd=1)\n  C <- rnorm(n=20,mean=0, sd=1)\n  D <- rnorm(n=20,mean=(0+x), sd=1)\n  df <- data.frame(condition = as.factor(rep(c(\"A\",\"B\",\"C\",\"D\"),each=20)),\n                   DV = c(A,B,C,D))\n  aov_results <- summary(aov(DV~condition,df))\n  #return the pvalue\n  return(aov_results[[1]]$`Pr(>F)`[1])\n}\n\n# vector of effect sizes\neffect_sizes <- seq(.1,2,.1)\n# run simulation for each effect size 1000 times\npower <- sapply(effect_sizes, \n          FUN = function(x) {\n            sims <- replicate(1000,sim_power_anova(x))\n            sim_power <- length(sims[sims<.05])/length(sims)\n            return(sim_power)})\n# combine into dataframe\nplot_df <- data.frame(effect_sizes,power)\n\n# plot the power curve\nggplot(plot_df, aes(x=effect_sizes,\n                    y=power))+\n  geom_point()+\n  geom_line()\nsim_power_anova <- function(x){\n  A <- rnorm(n=x,mean=0, sd=1)\n  B <- rnorm(n=x,mean=0, sd=1)\n  C <- rnorm(n=x,mean=0, sd=1)\n  D <- rnorm(n=x,mean=.2, sd=1)\n  df <- data.frame(condition = as.factor(rep(c(\"A\",\"B\",\"C\",\"D\"),each=x)),\n                   DV = c(A,B,C,D))\n  aov_results <- summary(aov(DV~condition,df))\n  #return the pvalue\n  return(aov_results[[1]]$`Pr(>F)`[1])\n}\n\n# vector of effect sizes\nsubjects <- seq(10,1000,50)\n# run simulation for each effect size 1000 times\npower <- sapply(subjects, \n          FUN = function(x) {\n            sims <- replicate(1000,sim_power_anova(x))\n            sim_power <- length(sims[sims<.05])/length(sims)\n            return(sim_power)})\n# combine into dataframe\nplot_df <- data.frame(subjects,power)\n\n# plot the power curve\nggplot(plot_df, aes(x=subjects,\n                    y=power))+\n  geom_point()+\n  geom_line()"},{"path":"simulation-and-power-analysis.html","id":"correlation-between-traits-and-behavior","chapter":"Simulation and Power Analysis","heading":"10.16.2 Correlation between traits and behavior","text":"common research strategy measure putative correlations people’s traits behavior. example, researcher might prepare questionnaire several questions. Perhaps questions political views, life satisfaction, anything else. research might ask group people answer questions, also perform task. end experiment, might ask different kinds people (measured questionnaire) perform differently behavioral measure. example, might people answer several questions openness new experiences, might also measure performance working memory task. research question might , people open experience perform better working memory task? answer lie correlation answers questions, performance task. Let’s simulate kind situation, say 20 subjects. subject answers 20 questions, perform behavioral task. end experiment, correlate answers question, performance task. kind correlations expect chance alone? Let’s say participants random robots. answer question randomly, performance behavioral task sampled randomly normal distribution. everything random, shouldn’t expect find correlations?Details:Let’s assume question involves likert scale 1 7. person randomly picks number 1 7 question. Let’s assume performance behavioral task sampled normal distribution mean = 0, sd = 1.histogram shows range correlations individual questions behavior can emerge just chance alone. run code times, see histogram changes bit random chance.Oftentimes researchers might know question questionnaire best question. , one best correlates behavior. Consider researcher computes correlations question behavior, chooses question highest correlation (positive negative) best question. , highest correlation. choosing question, might suggest behavior strongly correlated people answer question.Let’s try find simulation kinds large correlations can occur just chance alone. run many times, time save absolute value largest correlation question behavior. Just large can correlations chance alone?simulation shows chance alone situation can produce large correlations, large .8 .9 (although often).situation changes somewhat many subjects run. Let’s , run 200 subjects, rather 20.Now, chance doesn’t much better .25.","code":"\n# get 20 random answers for all 20 subjects and 20 questions\n# columns will be individual subjects 1 to 20\n# rows will be questions 1 to 20\nquestionnaire <- matrix(sample(1:7,20*20, replace=TRUE),ncol=20)\n# get 20 measures of performance on behavioral task\nbehavioral_task <- rnorm(20,0,1)\n\n# correlate behavior with each question\nsave_correlations <-c()\nfor(i in 1:20){\n  save_correlations[i] <- cor(behavioral_task,questionnaire[i,])\n}\n\n# show histogram of 20 correlations\nhist(save_correlations)\nsave_max <- c()\nfor( j in 1:10000){\n  questionnaire <- matrix(sample(1:7,20*20, replace=TRUE),ncol=20)\n  behavioral_task <- rnorm(20,0,1)\n  \n  save_correlations <-c()\n  for(i in 1:20){\n    save_correlations[i] <- cor(behavioral_task,questionnaire[i,])\n  }\n  save_max[j] <- max(abs(save_correlations))\n}\n\nhist(save_max)\nsave_max <- c()\nfor( j in 1:10000){\n  questionnaire <- matrix(sample(1:7,200*20, replace=TRUE),ncol=200)\n  behavioral_task <- rnorm(200,0,1)\n  \n  save_correlations <-c()\n  for(i in 1:20){\n    save_correlations[i] <- cor(behavioral_task,questionnaire[i,])\n  }\n  save_max[j] <- max(abs(save_correlations))\n}\n\nhist(save_max)"},{"path":"correlation.html","id":"correlation","chapter":"11 Correlation","heading":"11 Correlation","text":"“10/8/2020 | Last Compiled: 2020-12-09”","code":""},{"path":"correlation.html","id":"reading-7","chapter":"11 Correlation","heading":"11.1 Reading","text":"Vokey & Allen (2018), Chapter 7; Abdi et al. (2009), Chapter 2; Crump et al. (2018), Chapter 3","code":""},{"path":"correlation.html","id":"overview-11","chapter":"11 Correlation","heading":"11.2 Overview","text":"lab contains practical section two concept sections correlations R.Practical : compute correlations R using cor() cor.test()Concepts : behavior measures covarianceConcepts II: statistical inference correlation using permutation tests","code":""},{"path":"correlation.html","id":"historical-background-1","chapter":"11 Correlation","heading":"11.3 Historical Background","text":"Sir Francis Galton often credited inventing measures correlation (Galton, 1889, 1890), developed interests eugenics quantifying heritability traits parents offspring (Galton, 1865, 1869). Galton’s protege, Karl Pearson, credited popularizing formalizing measures correlation; example, correlation coefficient, \\(r\\), often referred Pearson’s \\(r\\) (AKA Pearson’s correlation coefficient, Pearson’s product-moment correlation coefficient). Pearson published work brief note Royal Society (Pearson, 1895). Despite recognition Galton Pearson receive, seems August Bravais described correlation coefficients (Bravais, 1844). Pearson recounts history development correlation coefficient, discusses missed Bravais’ work (Pearson, 1920). recently, Stigler discussed history Galton’s account development correlation coefficient (Stigler, 1989). note: papers included class zotero group.Finally, Lee Rodgers & Nicewander (1988) fantastic article thirteen ways conceptualizing correlation coefficient. also begin article brief discussion history development ideas around correlation.","code":""},{"path":"correlation.html","id":"additional-reading","chapter":"11 Correlation","heading":"11.4 Additional Reading","text":"additional reading introductory background concept correlation, see chapter correlation Answering questions data: https://crumplab.github.io/statistics/Correlation.htmlThe animated gif shows examples observing random correlations chance alone. See link example R code generate gifs like one.","code":"\nknitr::include_graphics(\"imgs/corNormFourNs-1.gif\")"},{"path":"correlation.html","id":"practical-i-cor-and-cor.test","chapter":"11 Correlation","heading":"11.5 Practical I: cor() and cor.test()","text":"","code":""},{"path":"correlation.html","id":"cor","chapter":"11 Correlation","heading":"11.5.1 cor()","text":"Base R comes cor() function computing Pearson’s correlation coefficients.cor() function can take vectors x y variables inputs return correlation.x y inputs can also matrices. case, correlation column vector B computedIf x y matrices, correlation column X Y computed.","code":"\n?cor\nA <- c(1,2,3,4,5,6,7,8,9,10) \nB <- c(1,3,2,4,3,5,4,5,6,7)\n\nplot(A,B)\ncor(A,B)  \n#> [1] 0.9246348\nA <- matrix(rnorm(100,0,1),ncol=10,nrow=10) \nB <- c(1,3,2,4,3,5,4,5,6,7)\ncor(A,B)\n#>               [,1]\n#>  [1,]  0.003608347\n#>  [2,] -0.078283572\n#>  [3,] -0.388866519\n#>  [4,]  0.572010311\n#>  [5,] -0.306468442\n#>  [6,]  0.491808612\n#>  [7,] -0.236608937\n#>  [8,]  0.224104176\n#>  [9,]  0.415322381\n#> [10,] -0.347772269\nA <- matrix(rnorm(25,0,1),ncol=5,nrow=5) \nB <- matrix(rnorm(25,0,1),ncol=5,nrow=5) \ncor(A,B)\n#>            [,1]        [,2]        [,3]       [,4]       [,5]\n#> [1,]  0.9274565  0.53291336  0.63002119 -0.5879674 -0.7128238\n#> [2,] -0.1839302 -0.43329264 -0.30701022  0.3671484  0.5783932\n#> [3,]  0.4741766 -0.03726613 -0.02985365 -0.2856831 -0.2155076\n#> [4,] -0.6559865 -0.16264847 -0.10544917  0.2496656  0.3408820\n#> [5,]  0.4630268  0.75290824  0.68851761 -0.1870484 -0.5952092"},{"path":"correlation.html","id":"cor-and-n-1","chapter":"11 Correlation","heading":"11.5.2 cor and n-1","text":"’s worth noting cor() divides n-1, function computing correlation coefficient sample.","code":"\nA <- c(1,2,3,4,5)\nB <- c(5,2,3,1,4)\ncor(A,B)\n#> [1] -0.3\n\n# long-form using z-score method\n\nA_z <- (A-mean(A))/sd(A)\nB_z <- (B-mean(B))/sd(B)\nsum(A_z * B_z) / 4 # n-1, 5-1 = 4\n#> [1] -0.3"},{"path":"correlation.html","id":"additional-cor-functionality","chapter":"11 Correlation","heading":"11.5.3 Additional cor() functionality","text":"review help file cor() shows number uses. example, default method compute Pearson correlation coefficient, function also used compute kendall spearman’s coefficient (yet discussed class).Another advanced feature handling missing values. example, variable B contains NA, missing value fifth position. default, cor() return NA situation.However, use= option can set handle missing data different ways. example, complete.obs option removes fifth pair altogether, compues correlation remaining pairs complete cases.","code":"\nA <- c(1,2,3,4,5)\nB <- c(5,2,3,1,NA)\ncor(A,B)\n#> [1] NA\ncor(A,B,use=\"complete.obs\")\n#> [1] -0.8315218"},{"path":"correlation.html","id":"cor.test","chapter":"11 Correlation","heading":"11.5.4 cor.test()","text":"cor() function returns correlation coefficients, however cor.test() function can used return \\(r\\) value, well \\(p\\)-value.help file cor.test(), “method ”pearson“, test statistic based Pearson’s product moment correlation coefficient cor(x, y) follows t distribution length(x)-2 degrees freedom samples follow independent normal distributions. least 4 complete pairs observation, asymptotic confidence interval given based Fisher’s Z transform.”cor.test() also return list object can saved accessed later point.","code":"\n?cor.test\nA <- c(1,2,3,4,5)\nB <- c(5,2,3,1,4)\ncor.test(A,B)\n#> \n#>  Pearson's product-moment correlation\n#> \n#> data:  A and B\n#> t = -0.5447, df = 3, p-value = 0.6238\n#> alternative hypothesis: true correlation is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.9348345  0.7918544\n#> sample estimates:\n#>  cor \n#> -0.3\nA <- c(1,2,3,4,5)\nB <- c(5,2,3,1,4)\nresults <- cor.test(A,B)\n\nresults$statistic\n#>          t \n#> -0.5447048\nresults$parameter\n#> df \n#>  3\nresults$p.value\n#> [1] 0.6238377\nresults$estimate\n#>  cor \n#> -0.3"},{"path":"correlation.html","id":"conceptual-i-the-simple-cross-product-as-a-measure-of-correlation","chapter":"11 Correlation","heading":"11.6 Conceptual I: The simple cross product as a measure of correlation","text":"","code":""},{"path":"correlation.html","id":"correlation-basics","chapter":"11 Correlation","heading":"11.6.1 Correlation basics","text":"correlation coefficient convenient measure association two variables. One convenient aspect resulting value limited range -1 1, can aid interpreting value. +1 means perfect positive correlation, 0 means correlation, -1 means perfect negative correlation.section use R look basic math behind correlation coefficient, way focus general concept.example, general concept positive correlation pair measures tends go together. value X small, paired value Y usually small. value X large, paired value Y usually large. words, variation X matches well variation Y;, X Y co-vary together way.perfect positive example :negative correlation pair measures tends go opposite directions . value X small, paired value Y usually large. value X large, paired value Y usually small. , X Y co-vary, except opposite ways. perfect negative example :idea zero correlation isn’t association paired values. value X goes , paired value Y whatever wants.Everytime code chunk runs, randomly shuffle Y, resulting correlation average 0 (everytime due chance).","code":"\nX <- 1:10\nY <- 1:10\n\nplot(X,Y)\ncor(X,Y)\n#> [1] 1\nX <- 1:10\nY <- 10:1\n\nplot(X,Y)\ncor(X,Y)\n#> [1] -1\nX <- 1:10\nY <- sample(10:1)\n\nplot(X,Y)\ncor(X,Y)\n#> [1] 0.1151515"},{"path":"correlation.html","id":"crossproducts-and-correlation","chapter":"11 Correlation","heading":"11.6.2 Crossproducts and correlation","text":"Pearson’s \\(r\\) also sometimes called product moment correlation coefficient. refers idea \\(r\\) sum cross products standardized.section look basic cross-product operation. example, cross product involves multiplying values two variables X Y together.sum cross products involves adding values:sum crossproducts also measure correlation association variables X Y. However, range values can take depend values X Y (standardized).Consider questions, assume X contains values 1 10, Y.largest value sum crossproducts X Y can take?Notice arrangement, smallest value X Y (1) paired together, next largest value (2) paired, 10. pairing creates largest sum crossproducts. also represents perfect positive correlation.smallest value sum crossproducts X Y can take?numbers arranged produce perfect negative correlation, sum cross products ’s minimum possible value.X contains number 1 10 order, Y , kinds sums cross-products can occur?","code":"\nX <- 1:10\nY <- 1:10\n\nX*Y\n#>  [1]   1   4   9  16  25  36  49  64  81 100\nsum(X*Y)\n#> [1] 385\nX <- 1:10\nY <- 1:10\nsum(X*Y)\n#> [1] 385\nX <- 1:10\nY <- 10:1\nsum(X*Y)\n#> [1] 220\nsum(sample(1:10)*sample(1:10))\n#> [1] 327\nsim_sums <- replicate(1000,sum(sample(1:10)*sample(1:10)))\nhist(sim_sums)\nmin(sim_sums)\n#> [1] 229\nmax(sim_sums)\n#> [1] 380"},{"path":"correlation.html","id":"conceptual-ii-statistical-inference-for-correlation","chapter":"11 Correlation","heading":"11.7 Conceptual II: Statistical inference for correlation","text":"look concept null-distribution correlation co-efficients two different ways, first randomly samply values normal distributions, second permutation test.","code":""},{"path":"correlation.html","id":"random-correlations","chapter":"11 Correlation","heading":"11.7.1 “Random” correlations","text":"totally possible apply Pearson’s \\(r\\) formula two variables conceptually 100% uncorrelated independent , still find “correlations”, largish values \\(r\\).example, randomly sample 10 values normal distribution X, another 10 values normal distribution Y, expect average 0 correlation X Y. , selected values completely random.happens 10 times?1000 times?sense simulation creates null-distribution sorts, sampling distribution \\(r\\) values expected number paired scores 10, drawn randomly independently unit normal distributions. ’s clear case chance alone possible get wide range correlation coefficients.","code":"\nX <- rnorm(10,0,1)\nY <- rnorm(10,0,1)\ncor(X,Y)\n#> [1] 0.3314112\nreplicate(10,cor(rnorm(10,0,1),rnorm(10,0,1)))\n#>  [1] -0.72904120  0.10020194  0.03293618  0.56556534 -0.56853952  0.14498714\n#>  [7]  0.31301378 -0.22757317 -0.31687271 -0.21953919\nrand_1000 <- replicate(1000,cor(rnorm(10,0,1),rnorm(10,0,1)))\nhist(rand_1000)\nmean(rand_1000)\n#> [1] 0.003693625\nmax(rand_1000)\n#> [1] 0.8023694\nmin(rand_1000)\n#> [1] -0.8333578"},{"path":"correlation.html","id":"sample-size-matters","chapter":"11 Correlation","heading":"11.7.2 Sample-size matters","text":"Briefly, kinds correlations can produced chance limited sample-size. example, consider happens range simulated \\(r\\) values number paired scores increased 10 100.","code":"\nrand_1000 <- replicate(1000,cor(rnorm(100,0,1),rnorm(100,0,1)))\nhist(rand_1000)\nmean(rand_1000)\n#> [1] 0.001979886\nmax(rand_1000)\n#> [1] 0.3201781\nmin(rand_1000)\n#> [1] -0.3079627"},{"path":"correlation.html","id":"permutation-test","chapter":"11 Correlation","heading":"11.7.3 Permutation test","text":"class discussed sample data suggesting length word negatively correlated number meanings word. Example data showing negative correlation shown (taken R workbook Abdi textbook).According cor.test() function, correlation sample data unlikely produced chance alone.Instead using cor.test() function, can use concept permutation test construct null distribution. basic idea imagine values Length Meanings variables randomly repaired, new correlation coefficient measured. procedure several thousand times create null distribution representing kinds \\(r\\) values obtained chance.","code":"\nlibrary(ggplot2)\nlibrary(ggrepel)\nWords  = c('bag','buckle','on','insane','by','monastery',\n'relief','slope','scoundrel','loss','holiday','pretentious',\n'solid','time','gut','tarantula','generality','arise','blot','infectious')\nLength=c(3,6,2,6,2,9,6,5,9,4,7,11,5,4,3,9,10,5,4,10)\nMeanings=c(8,4,10,1,11,1,4,3,1,6,2,1,9,3,4,1,3,3,3,2)\n\nall <- data.frame(Words,Length,Meanings)\nknitr::kable(all)\n\nggplot(all,aes(x=Length,y=Meanings))+\n  geom_point()+\n  geom_text_repel(aes(label=Words))\ncor.test(Length,Meanings)\n#> \n#>  Pearson's product-moment correlation\n#> \n#> data:  Length and Meanings\n#> t = -4.5644, df = 18, p-value = 0.0002403\n#> alternative hypothesis: true correlation is not equal to 0\n#> 95 percent confidence interval:\n#>  -0.8873588 -0.4289759\n#> sample estimates:\n#>        cor \n#> -0.7324543\ncor(sample(Length),sample(Meanings))\n#> [1] 0.05954913\nsim_rs <- replicate(1000,cor(sample(Length),sample(Meanings)))\nhist(sim_rs)\n\nlength(sim_rs[sim_rs <= cor(Length,Meanings)])/1000\n#> [1] 0"},{"path":"correlation.html","id":"lab-11-generalization-assignment","chapter":"11 Correlation","heading":"11.8 Lab 11 Generalization Assignment","text":"","code":""},{"path":"correlation.html","id":"instructions-10","chapter":"11 Correlation","heading":"11.8.1 Instructions","text":"general, labs present discussion problems issues example code like , students tasked completing generalization assignments, showing can work concepts tools independently.assignment instructions following:Work inside R project “StatsLab1” usingCreate new R Markdown document called “Lab11.Rmd”Use Lab11.Rmd show work attempting solve following generalization problems. Commit work regularly appears Github repository.problem, make note much problem believe can solve independently without help. example, needed watch help video unable solve problem without copying answers, note 0. confident can complete problem scratch completely , note 100. OK 0s 100s anything .Submit github repository link Lab 11 blackboard.","code":""},{"path":"correlation.html","id":"problems-10","chapter":"11 Correlation","heading":"11.8.2 Problems","text":"X Y variable contain numbers.\n. Compute Pearson’s \\(r\\) report associated p-value using cor.test() function. (2 points)\nB. Use permutation test create null-distribution, report p-value getting observed correlation larger using simulated null-distribution. (2 points)X Y variable contain numbers.. Compute Pearson’s \\(r\\) report associated p-value using cor.test() function. (2 points)B. Use permutation test create null-distribution, report p-value getting observed correlation larger using simulated null-distribution. (2 points)Using variables X Y , assuming values re-ordered way, report following:\n. smallest possible sum cross-products (1 point)\nB. largest possible sum cross-products (1 point)Using variables X Y , assuming values re-ordered way, report following:. smallest possible sum cross-products (1 point)B. largest possible sum cross-products (1 point)","code":"\nX <- c(1,4,3,2,5,4,3,6,7,8)\nY <- c(1,3,6,7,8,2,8,7,6,9)"},{"path":"semester-1-project.html","id":"semester-1-project","chapter":"Semester 1 project","heading":"Semester 1 project","text":"“11/8/2020 | Last Compiled: 2020-12-09”","code":""},{"path":"semester-1-project.html","id":"overview-12","chapter":"Semester 1 project","heading":"11.9 Overview","text":"semester project assignment due end semester submitted link Blackboard.discuss project across semester. overview, demonstrating can conduct reproducible analysis, analysis data independently verifiable. example, someone else obtain data code independently reproduce analysis.complete three related parts.Reproducible Report: Obtain open-data existing psych paper, load data R, attempt reproduce statistical analysis original authors reported.Reproducible Report: Obtain open-data existing psych paper, load data R, attempt reproduce statistical analysis original authors reported.APA paper: Learn use papaja package allows compile .Rmd files APA style manuscripts pdf form. , write short APA-style research report describes reproducible analysis.APA paper: Learn use papaja package allows compile .Rmd files APA style manuscripts pdf form. , write short APA-style research report describes reproducible analysis.Simulation based power analysis: Include simulation based power analysis end APA paper.Simulation based power analysis: Include simulation based power analysis end APA paper.","code":""},{"path":"semester-1-project.html","id":"part-1-reproducible-report-10-points","chapter":"Semester 1 project","heading":"11.10 Part 1: Reproducible report (10 points)","text":"","code":""},{"path":"semester-1-project.html","id":"finding-a-paper-with-data","chapter":"Semester 1 project","heading":"11.10.1 Finding a paper with data","text":"tips finding psych paper open data. important, assignment need re-analyze data particular paper. Many papers multiple experiments, multiple analyses, including analyses may familiar . can restrict re-analysis portion paper. example, might re-analyze results one experiment, perhaps results relevant one tests reported experiment. can limit re-analyses tests covered lecture lab.https://osf.io open science framework contains many repositories open data part published papersSome journals, including Psychological Science, put badges papers open data. Look blue open-data badge. usually find link open-data paper.https://crumplab.github.io/statisticsLab/ lab manual use teaching R undergraduates. labs (especially 6 11) involve paper Psych science open-data.","code":""},{"path":"semester-1-project.html","id":"loading-the-data-into-r","chapter":"Semester 1 project","heading":"11.10.2 Loading the data into R","text":"data find many different formats. possible load R transform data format/organization need complete analysis.","code":""},{"path":"semester-1-project.html","id":"re-analysis-of-original-data","chapter":"Semester 1 project","heading":"11.10.3 Re-analysis of original data","text":"Focus single analysis relevant one research questions. example, analysis involved several t-tests:Conduct report t-testsReport table meansReport graph means","code":""},{"path":"semester-1-project.html","id":"write-a-reproducible-report","chapter":"Semester 1 project","heading":"11.10.4 Write a reproducible report","text":"concept reproducible report someone else exactly reproduce analysis given report. easy make reproducible reports using R markdown. write report .Rmd file, file includes scripts loading analyzing data, sharing .rmd file, people can exactly reproduce report.report include following (points add 10 part 1).brief description research question experiment (citation paper, link find data) (3 points)brief description research question experiment (citation paper, link find data) (3 points)R code chunks necessary complete re-analysis (3 points).R code chunks necessary complete re-analysis (3 points).write-re-analysis results. (3 points)write-re-analysis results. (3 points)brief discussion whether successful . (1 point)brief discussion whether successful . (1 point)","code":""},{"path":"semester-1-project.html","id":"part-2-apa-paper-in-r-markdown-10-points","chapter":"Semester 1 project","heading":"11.11 Part 2: APA paper in R markdown (10 points)","text":"","code":""},{"path":"semester-1-project.html","id":"papaja-1","chapter":"Semester 1 project","heading":"11.11.1 Papaja","text":"part 2, learn use papaja package create APA style manuscripts using R markdown. discuss use papaja class. create new .rmd file using papaja template, transfer reproducible report format. write brief sections :abstract (50-100 words) (1 point)introduction (1 two paragraphs) (1 point)methods (1 paragraph) (1 point)results (re-analysis results) (3 point)must include R code chunks analysisfull points reporting results also reproducible (hand), example (see ).discussion (brief, 1 paragraph) (1 point)references (cite paper, anything else want cite) (1 point)completed .Rmd file succesfully compiled .pdf using papaja (2 points), purpose write full-length APA paper, get experience using papaja package.","code":""},{"path":"semester-1-project.html","id":"part-3-power-analysis-8-points","chapter":"Semester 1 project","heading":"11.12 Part 3: Power analysis (8 points)","text":"","code":""},{"path":"semester-1-project.html","id":"simulation-based-power-analysis","chapter":"Semester 1 project","heading":"11.12.1 Simulation based power analysis","text":"part 3 add simulation-based power analysis APA-style manuscript. Specifically, report graph showing power-curve design. discuss conduct simulation based power analyses class.following included general discussion APA-paper (part 2).R code chunk conducting power analysis (3 points)paragraph two discussing explaining power analysis reader, well reporting results power analysis. (3 points)graph depicting power-curve design. (2 points)statement design might changed achieve desired preferred amount power. (2 points)","code":""},{"path":"semester-1-project.html","id":"example-of-a-completed-project","chapter":"Semester 1 project","heading":"11.13 Example of a completed project","text":"give better idea looking completed project .source code located github repository https://github.com/CrumpLab/psyc7709Lab/tree/master/semester_project.repository contains:Part 1: .rmd file reproduces analysis Experiment 3 Rosenbaum, Mama, Algom (2017)Part 2: APA-style manuscript version reproducible report using papajaPart 3: section end APA-style manuscript conducts simulation based power-analysis design.","code":""},{"path":"semester-1-project.html","id":"semester-project-submission","chapter":"Semester 1 project","heading":"11.14 Semester Project Submission","text":"Create new git-enabled R project semester project, upload githubWork folder, complete Parts 1 3. finished minimum:folder data obtainedA compiled .Rmd html file part 1A compiled .Rmd .pdf part 2 3a bib file referencesSubmit link github repository Blackboard assignment semester long project","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"Abdi, H., Edelman, B., Dowling, W. J., & Valentin, D. (2009). Experimental design analysis psychology. Oxford University Press.Bravais, . (1844). Analyse mathématique sur les probabilités des erreurs de situation d’un point. Impr. Royale.Crump, M. J. C., Navarro, D., & Suzuki, J. (2018). Answering questions data: Introductory Statistics Psychology Students. https://crumplab.github.io/statistics/Delucchi, K. L. (1983). use misuse chi-square: Lewis Burke revisited. Psychological Bulletin, 94(1), 166.Galton, F. (1865). Hereditary talent character. Macmillan’s Magazine, 12(157-166), 318–327.Galton, F. (1869). Hereditary genius. Macmillan.Galton, F. (1889). . Co-relations measurement, chiefly anthropometric data. Proceedings Royal Society London, 45(273-279), 135–145. https://doi.org/10/dz5sd6Galton, F. (1890). Kinship correlation. North American Review, 150(401), 419–431.Lee Rodgers, J., & Nicewander, W. . (1988). Thirteen ways look correlation coefficient. American Statistician, 42(1), 59–66.Lewis, D., & Burke, C. J. (1949). use misuse chi-square test. Psychological Bulletin, 46(6), 433. https://doi.org/10/frkdqwPearson, E. S. (1939). \"Student\" Statistician. Biometrika, 30(3/4), 210. https://doi.org/10/c2t7mzPearson, K. (1895). Notes Regression Inheritance Case Two Parents Proceedings Royal Society London, 58, 240-242. ed.Pearson, K. (1900). X. criterion given system deviations probable case correlated system variables can reasonably supposed arisen random sampling. London, Edinburgh, Dublin Philosophical Magazine Journal Science, 50(302), 157–175. https://doi.org/10/cpxzh4Pearson, K. (1920). NOTES HISTORY CORRELATION. Biometrika, 13(1), 25–45. https://doi.org/10/c2z3nzPlackett, R. L. (1983). Karl Pearson Chi-Squared Test. International Statistical Review / Revue Internationale de Statistique, 51(1), 59. https://doi.org/10/d55k57Sawilowsky, S. S., & Blair, R. C. (1992). realistic look robustness type II error properties t test departures population normality. Psychological Bulletin, 111(2), 352. https://doi.org/10/bnxbp9Semmel, B. (1958). Karl Pearson: Socialist Darwinist. British Journal Sociology, 9(2), 111. https://doi.org/10/fs4jbbStigler, S. M. (1989). Francis Galton’s account invention correlation. Statistical Science, 73–79. https://doi.org/10/dg8nxjStudent. (1908). probable error mean. Biometrika, 1–25.Vokey, J. R., & Allen, S. W. (2018). Thinking Data (7th Edition - Revised). Psyence Publishing Society. http://people.uleth.ca/~vokey/pdf/thinking.pdfVuorre, M., & Crump, M. J. C. (2020). Sharing organizing research products R packages. Behavior Research Methods. https://doi.org/10/gg9w4c","code":""}]
